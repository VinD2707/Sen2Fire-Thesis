{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14342736,"sourceType":"datasetVersion","datasetId":8507641},{"sourceId":737863,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":562680,"modelId":575268}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, glob, random, json\nfrom dataclasses import dataclass\nfrom typing import List, Tuple\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# ----------------------------\n# Reproducibility\n# ----------------------------\ndef seed_everything(seed: int = 42) -> None:\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nSEED = 24\nseed_everything(SEED)\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", DEVICE)\n\n# ----------------------------\n# Config\n# ----------------------------\n@dataclass\nclass CFG:\n    DATA_ROOT: str = \"/kaggle/input/sen2fire/Sen2Fire/Sen2Fire\"\n    SCENES: Tuple[str, ...] = (\"scene1\", \"scene2\", \"scene3\", \"scene4\")\n    PATCH_EXT: str = \".npz\"\n\n    # Global split (VD default)\n    USE_GLOBAL_SPLIT: bool = True\n    GLOBAL_TRAIN_RATIO: float = 0.80\n    GLOBAL_VAL_RATIO: float = 0.10\n    GLOBAL_TEST_RATIO: float = 0.10\n    KEEP_VAL_TEST_NATURAL: bool = True\n\n    # Keys inside npz\n    X_KEY: str = \"image\"     # (12,512,512)\n    A_KEY: str = \"aerosol\"   # (512,512) -> becomes 1 channel\n    Y_KEY: str = \"label\"     # (512,512)\n\n    # Fire patch definition\n    FIRE_PATCH_MIN_RATIO: float = 0\n\n    # Controlled train pool (VD default)\n    USE_CONTROLLED_POOL: bool = True\n    POOL_KEEP_FIRE: int = -1\n    NONFIRE_PER_FIRE: int = 3\n\n    # Training config (RAM-safe)\n    IN_CHANNELS: int = 13\n    H: int = 512\n    W: int = 512\n    BATCH_SIZE: int = 2\n    NUM_WORKERS: int = 2\n    LR: float = 1e-4\n    EPOCHS: int = 20\n\n    VERBOSE: bool = True\n\ncfg = CFG()\n\nassert abs((cfg.GLOBAL_TRAIN_RATIO + cfg.GLOBAL_VAL_RATIO + cfg.GLOBAL_TEST_RATIO) - 1.0) < 1e-6\nassert os.path.exists(cfg.DATA_ROOT), f\"DATA_ROOT not found: {cfg.DATA_ROOT}\"\nprint(\"DATA_ROOT OK:\", cfg.DATA_ROOT)\n","metadata":{"execution":{"iopub.status.busy":"2026-02-01T13:40:35.256980Z","iopub.execute_input":"2026-02-01T13:40:35.257673Z","iopub.status.idle":"2026-02-01T13:40:39.679347Z","shell.execute_reply.started":"2026-02-01T13:40:35.257641Z","shell.execute_reply":"2026-02-01T13:40:39.678760Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Device: cuda\nDATA_ROOT OK: /kaggle/input/sen2fire/Sen2Fire/Sen2Fire\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"def list_scene_files(data_root: str, scene_name: str, ext: str = \".npz\") -> List[str]:\n    scene_dir = os.path.join(data_root, scene_name)\n    return sorted(glob.glob(os.path.join(scene_dir, f\"*{ext}\")))\n\nscene_to_files = {}\ntotal = 0\nfor s in cfg.SCENES:\n    files = list_scene_files(cfg.DATA_ROOT, s, cfg.PATCH_EXT)\n    scene_to_files[s] = files\n    total += len(files)\n    print(f\"{s}: {len(files)} patches\")\n\nprint(\"Total patches:\", total)\nif total == 0:\n    raise RuntimeError(\"No patch files found. Check DATA_ROOT / PATCH_EXT.\")\n","metadata":{"execution":{"iopub.status.busy":"2026-02-01T13:40:39.680553Z","iopub.execute_input":"2026-02-01T13:40:39.680916Z","iopub.status.idle":"2026-02-01T13:40:39.833886Z","shell.execute_reply.started":"2026-02-01T13:40:39.680891Z","shell.execute_reply":"2026-02-01T13:40:39.833267Z"},"trusted":true},"outputs":[{"name":"stdout","text":"scene1: 864 patches\nscene2: 594 patches\nscene3: 504 patches\nscene4: 504 patches\nTotal patches: 2466\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def inspect_npz(npz_path: str):\n    with np.load(npz_path) as data:\n        return {k: (data[k].shape, str(data[k].dtype)) for k in data.keys()}\n\nsample_path = scene_to_files[cfg.SCENES[0]][0]\nprint(\"Sample file:\", sample_path)\ninfo = inspect_npz(sample_path)\nfor k, (shape, dtype) in info.items():\n    print(f\"  - {k:>10s}: shape={shape}, dtype={dtype}\")\n\nfor rk in [cfg.X_KEY, cfg.A_KEY, cfg.Y_KEY]:\n    if rk not in info:\n        raise KeyError(f\"Missing key '{rk}' in npz. Found keys: {list(info.keys())}\")\n","metadata":{"execution":{"iopub.status.busy":"2026-02-01T13:40:39.834718Z","iopub.execute_input":"2026-02-01T13:40:39.834950Z","iopub.status.idle":"2026-02-01T13:40:39.957166Z","shell.execute_reply.started":"2026-02-01T13:40:39.834930Z","shell.execute_reply":"2026-02-01T13:40:39.956570Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Sample file: /kaggle/input/sen2fire/Sen2Fire/Sen2Fire/scene1/scene_1_patch_10_1.npz\n  -      image: shape=(12, 512, 512), dtype=int16\n  -    aerosol: shape=(512, 512), dtype=float32\n  -      label: shape=(512, 512), dtype=uint8\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"rows = []\nfor s, files in scene_to_files.items():\n    for p in files:\n        rows.append({\"scene\": s, \"path\": p})\nmanifest = pd.DataFrame(rows)\n\ndef fire_ratio_from_path(npz_path: str) -> float:\n    with np.load(npz_path) as data:\n        y = data[cfg.Y_KEY]\n        if y.ndim == 3 and y.shape[-1] == 1:\n            y = y[..., 0]\n        yb = (y > 0).astype(np.uint8)\n        return float(yb.mean())\n\nfire_ratios = []\nhas_fire = []\nfor p in manifest[\"path\"].tolist():\n    r = fire_ratio_from_path(p)\n    fire_ratios.append(r)\n    has_fire.append(1 if r > cfg.FIRE_PATCH_MIN_RATIO else 0)\n\nmanifest[\"fire_ratio\"] = fire_ratios\nmanifest[\"has_fire\"] = has_fire\n\nprint(\"\\nFULL dataset has_fire distribution:\")\nprint(manifest[\"has_fire\"].value_counts().sort_index())\nprint(\"\\nFULL dataset has_fire ratio:\")\nprint(manifest[\"has_fire\"].value_counts(normalize=True).sort_index())\n","metadata":{"execution":{"iopub.status.busy":"2026-02-01T13:40:39.958501Z","iopub.execute_input":"2026-02-01T13:40:39.958739Z","iopub.status.idle":"2026-02-01T13:41:24.053490Z","shell.execute_reply.started":"2026-02-01T13:40:39.958710Z","shell.execute_reply":"2026-02-01T13:41:24.052827Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\nFULL dataset has_fire distribution:\nhas_fire\n0    2117\n1     349\nName: count, dtype: int64\n\nFULL dataset has_fire ratio:\nhas_fire\n0    0.858475\n1    0.141525\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"with np.load(manifest[\"path\"][0]) as data:\n    y = data[cfg.Y_KEY]\n    print(\"y.shape:\", y.shape)\n","metadata":{"execution":{"iopub.status.busy":"2026-02-01T13:41:24.054442Z","iopub.execute_input":"2026-02-01T13:41:24.054724Z","iopub.status.idle":"2026-02-01T13:41:24.062077Z","shell.execute_reply.started":"2026-02-01T13:41:24.054657Z","shell.execute_reply":"2026-02-01T13:41:24.061379Z"},"trusted":true},"outputs":[{"name":"stdout","text":"y.shape: (512, 512)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import numpy as np\n\ny = np.load(manifest[\"path\"][0])[cfg.Y_KEY]\nfire_channel = np.argmax(y.sum(axis=(0,1)))  # channel dengan paling banyak fire\nprint(\"Fire channel:\", fire_channel)","metadata":{"execution":{"iopub.status.busy":"2026-02-01T13:41:24.062983Z","iopub.execute_input":"2026-02-01T13:41:24.063321Z","iopub.status.idle":"2026-02-01T13:41:24.073096Z","shell.execute_reply.started":"2026-02-01T13:41:24.063291Z","shell.execute_reply":"2026-02-01T13:41:24.072334Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Fire channel: 0\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# DATASET PREPARATION","metadata":{}},{"cell_type":"code","source":"def stratified_split(df, train_ratio, val_ratio, seed=42):\n    df = df.sample(frac=1.0, random_state=seed).reset_index(drop=True)\n    parts = []\n    for cls in [0, 1]:\n        sub = df[df[\"has_fire\"] == cls].copy()\n        n = len(sub)\n        n_train = int(round(n * train_ratio))\n        n_val   = int(round(n * val_ratio))\n        sub_train = sub.iloc[:n_train]\n        sub_val   = sub.iloc[n_train:n_train+n_val]\n        sub_test  = sub.iloc[n_train+n_val:]\n        parts.append((sub_train, sub_val, sub_test))\n\n    train_df = pd.concat([parts[0][0], parts[1][0]]).sample(frac=1.0, random_state=seed).reset_index(drop=True)\n    val_df   = pd.concat([parts[0][1], parts[1][1]]).sample(frac=1.0, random_state=seed).reset_index(drop=True)\n    test_df  = pd.concat([parts[0][2], parts[1][2]]).sample(frac=1.0, random_state=seed).reset_index(drop=True)\n    return train_df, val_df, test_df\n\ntrain_pool_df, val_df, test_df = stratified_split(\n    manifest,\n    train_ratio=cfg.GLOBAL_TRAIN_RATIO,\n    val_ratio=cfg.GLOBAL_VAL_RATIO,\n    seed=SEED\n)\n\nprint(\"\\nGLOBAL split counts:\")\nprint(\"  Train pool:\", len(train_pool_df))\nprint(\"  Val      :\", len(val_df))\nprint(\"  Test     :\", len(test_df))\n\n# Controlled pool applies to TRAIN only\nif cfg.USE_CONTROLLED_POOL:\n    fire_df   = train_pool_df[train_pool_df[\"has_fire\"] == 1].copy()\n    nofire_df = train_pool_df[train_pool_df[\"has_fire\"] == 0].copy()\n\n    n_fire_total = len(fire_df)\n    n_nofire_total = len(nofire_df)\n\n    n_fire_keep = n_fire_total if cfg.POOL_KEEP_FIRE in (-1, None) else min(cfg.POOL_KEEP_FIRE, n_fire_total)\n    fire_keep = fire_df.sample(n=n_fire_keep, random_state=SEED) if n_fire_keep > 0 else fire_df.iloc[:0]\n\n    n_nofire_keep = min(n_nofire_total, n_fire_keep * int(cfg.NONFIRE_PER_FIRE))\n    nofire_keep = nofire_df.sample(n=n_nofire_keep, random_state=SEED) if n_nofire_keep > 0 else nofire_df.iloc[:0]\n\n    train_df = pd.concat([fire_keep, nofire_keep]).sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n\n    print(\"\\nTRAIN controlled sampling:\")\n    print(f\"  fire_total_in_pool   : {n_fire_total}\")\n    print(f\"  nofire_total_in_pool : {n_nofire_total}\")\n    print(f\"  fire_kept            : {len(fire_keep)}\")\n    print(f\"  nofire_kept          : {len(nofire_keep)} (NONFIRE_PER_FIRE={cfg.NONFIRE_PER_FIRE})\")\n    print(f\"  train_final          : {len(train_df)}\")\nelse:\n    train_df = train_pool_df.copy()\n\ntrain_paths = train_df[\"path\"].tolist()\nval_paths   = val_df[\"path\"].tolist()\ntest_paths  = test_df[\"path\"].tolist()\n\n# leakage check\nassert len(set(train_paths)&set(val_paths))==0\nassert len(set(train_paths)&set(test_paths))==0\nassert len(set(val_paths)&set(test_paths))==0\n\nprint(\"\\nFinal used split sizes:\")\nprint(\"  train:\", len(train_paths))\nprint(\"  val  :\", len(val_paths))\nprint(\"  test :\", len(test_paths))\n","metadata":{"execution":{"iopub.status.busy":"2026-02-01T13:41:24.074209Z","iopub.execute_input":"2026-02-01T13:41:24.075043Z","iopub.status.idle":"2026-02-01T13:41:24.103233Z","shell.execute_reply.started":"2026-02-01T13:41:24.075016Z","shell.execute_reply":"2026-02-01T13:41:24.102715Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\nGLOBAL split counts:\n  Train pool: 1973\n  Val      : 247\n  Test     : 246\n\nTRAIN controlled sampling:\n  fire_total_in_pool   : 279\n  nofire_total_in_pool : 1694\n  fire_kept            : 279\n  nofire_kept          : 837 (NONFIRE_PER_FIRE=3)\n  train_final          : 1116\n\nFinal used split sizes:\n  train: 1116\n  val  : 247\n  test : 246\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"test_df[\"path\"]","metadata":{"execution":{"iopub.status.busy":"2026-02-01T13:41:24.105291Z","iopub.execute_input":"2026-02-01T13:41:24.105882Z","iopub.status.idle":"2026-02-01T13:41:24.111746Z","shell.execute_reply.started":"2026-02-01T13:41:24.105851Z","shell.execute_reply":"2026-02-01T13:41:24.111169Z"},"trusted":true},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"0      /kaggle/input/sen2fire/Sen2Fire/Sen2Fire/scene...\n1      /kaggle/input/sen2fire/Sen2Fire/Sen2Fire/scene...\n2      /kaggle/input/sen2fire/Sen2Fire/Sen2Fire/scene...\n3      /kaggle/input/sen2fire/Sen2Fire/Sen2Fire/scene...\n4      /kaggle/input/sen2fire/Sen2Fire/Sen2Fire/scene...\n                             ...                        \n241    /kaggle/input/sen2fire/Sen2Fire/Sen2Fire/scene...\n242    /kaggle/input/sen2fire/Sen2Fire/Sen2Fire/scene...\n243    /kaggle/input/sen2fire/Sen2Fire/Sen2Fire/scene...\n244    /kaggle/input/sen2fire/Sen2Fire/Sen2Fire/scene...\n245    /kaggle/input/sen2fire/Sen2Fire/Sen2Fire/scene...\nName: path, Length: 246, dtype: object"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"class Sen2FireDataset(Dataset):\n    def __init__(self, paths: List[str], with_label: bool = True):\n        self.paths = paths\n        self.with_label = with_label\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, idx):\n        p = self.paths[idx]\n        with np.load(p) as d:\n            img12 = d[cfg.X_KEY].astype(np.float32)      # (12,512,512)\n            aer   = d[cfg.A_KEY].astype(np.float32)[None, ...]  # (1,512,512)\n            x = np.concatenate([img12, aer], axis=0)     # (13,512,512)\n\n            if self.with_label:\n                y = d[cfg.Y_KEY]\n                if y.ndim == 2:\n                    y = y[None, ...]\n                y = (y > 0).astype(np.float32)\n                return torch.from_numpy(x), torch.from_numpy(y)\n            else:\n                return torch.from_numpy(x)\n","metadata":{"execution":{"iopub.status.busy":"2026-02-01T13:41:24.112681Z","iopub.execute_input":"2026-02-01T13:41:24.113009Z","iopub.status.idle":"2026-02-01T13:41:24.123634Z","shell.execute_reply.started":"2026-02-01T13:41:24.112977Z","shell.execute_reply":"2026-02-01T13:41:24.122876Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train_loader = DataLoader(Sen2FireDataset(train_paths, with_label=True),\n                          batch_size=cfg.BATCH_SIZE, shuffle=True,\n                          num_workers=cfg.NUM_WORKERS, pin_memory=True)\n\nval_loader = DataLoader(Sen2FireDataset(val_paths, with_label=True),\n                        batch_size=cfg.BATCH_SIZE, shuffle=False,\n                        num_workers=cfg.NUM_WORKERS, pin_memory=True)\n\ntest_loader = DataLoader(Sen2FireDataset(test_paths, with_label=True),\n                         batch_size=cfg.BATCH_SIZE, shuffle=False,\n                         num_workers=cfg.NUM_WORKERS, pin_memory=True)\n","metadata":{"execution":{"iopub.status.busy":"2026-02-01T13:41:24.124753Z","iopub.execute_input":"2026-02-01T13:41:24.125201Z","iopub.status.idle":"2026-02-01T13:41:24.136391Z","shell.execute_reply.started":"2026-02-01T13:41:24.125180Z","shell.execute_reply":"2026-02-01T13:41:24.135686Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"@torch.no_grad()\ndef compute_mean_std(loader, max_batches=50):\n    mean = torch.zeros(cfg.IN_CHANNELS, device=DEVICE)\n    var  = torch.zeros(cfg.IN_CHANNELS, device=DEVICE)\n    n_batches = 0\n\n    for bi, (x, y) in enumerate(loader):\n        if bi >= max_batches:\n            break\n        x = x.to(DEVICE)  # (B,C,H,W)\n        x_ = x.view(x.size(0), cfg.IN_CHANNELS, -1)\n        mean += x_.mean(dim=(0,2))\n        var  += x_.var(dim=(0,2), unbiased=False)\n        n_batches += 1\n\n    mean /= max(n_batches, 1)\n    var  /= max(n_batches, 1)\n    std = torch.sqrt(var + 1e-6)\n    return mean.detach().cpu().tolist(), std.detach().cpu().tolist()\n\nMEAN_13, STD_13 = compute_mean_std(train_loader, max_batches=50)\nprint(\"MEAN_13 len:\", len(MEAN_13), \"STD_13 len:\", len(STD_13))\n","metadata":{"execution":{"iopub.status.busy":"2026-02-01T13:41:24.137207Z","iopub.execute_input":"2026-02-01T13:41:24.137465Z","iopub.status.idle":"2026-02-01T13:41:28.355923Z","shell.execute_reply.started":"2026-02-01T13:41:24.137446Z","shell.execute_reply":"2026-02-01T13:41:28.355152Z"},"trusted":true},"outputs":[{"name":"stdout","text":"MEAN_13 len: 13 STD_13 len: 13\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# MODEL PREPARATION\n","metadata":{}},{"cell_type":"code","source":"!pip -q install segmentation-models-pytorch\n","metadata":{"execution":{"iopub.status.busy":"2026-02-01T13:41:28.357118Z","iopub.execute_input":"2026-02-01T13:41:28.357343Z","iopub.status.idle":"2026-02-01T13:41:33.046964Z","shell.execute_reply.started":"2026-02-01T13:41:28.357316Z","shell.execute_reply":"2026-02-01T13:41:33.046212Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"def normalize_batch(x, mean_13, std_13):\n    mean_t = torch.tensor(mean_13, device=x.device).view(1, cfg.IN_CHANNELS, 1, 1)\n    std_t  = torch.tensor(std_13,  device=x.device).view(1, cfg.IN_CHANNELS, 1, 1)\n    return (x - mean_t) / (std_t + 1e-6)","metadata":{"execution":{"iopub.status.busy":"2026-02-01T13:41:33.048193Z","iopub.execute_input":"2026-02-01T13:41:33.048527Z","iopub.status.idle":"2026-02-01T13:41:33.053387Z","shell.execute_reply.started":"2026-02-01T13:41:33.048483Z","shell.execute_reply":"2026-02-01T13:41:33.052672Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import segmentation_models_pytorch as smp\n\ncriterion = nn.BCEWithLogitsLoss()\ndef build_unet(in_channels=13):\n    model = smp.Unet(\n        encoder_name=\"resnet18\",\n        encoder_weights=\"imagenet\",\n        in_channels=in_channels,\n        classes=1,\n        activation=None\n    )\n    return model\n    \nmodel = build_unet(cfg.IN_CHANNELS).to(DEVICE)\nprint(\"Model:\", type(model).__name__)","metadata":{"execution":{"iopub.status.busy":"2026-02-01T13:41:33.054496Z","iopub.execute_input":"2026-02-01T13:41:33.055021Z","iopub.status.idle":"2026-02-01T13:41:42.717500Z","shell.execute_reply.started":"2026-02-01T13:41:33.054986Z","shell.execute_reply":"2026-02-01T13:41:42.716771Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c27a91e8ef54388a5099335b3d10d8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/46.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b49de9632894ae89b50885045813db5"}},"metadata":{}},{"name":"stdout","text":"Model: Unet\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from torch.cuda.amp import autocast, GradScaler\nfrom sklearn.metrics import roc_auc_score\nimport time\n\noptimizer = torch.optim.Adam(model.parameters(), lr=cfg.LR)\nscaler = GradScaler(enabled=(DEVICE.type == \"cuda\"))\n\ndef train_one_epoch(model, loader, thr=0.5, eps=1e-6):\n    model.train()\n    total_loss_sum = 0.0\n    total_samples = 0\n\n    total_tp = total_fp = total_fn = total_tn = 0.0\n    all_probs, all_targets = [], []\n\n    for x, y in loader:\n        x, y = x.to(DEVICE), y.to(DEVICE)\n        x = normalize_batch(x, MEAN_13, STD_13)\n\n        optimizer.zero_grad(set_to_none=True)\n\n        with autocast(enabled=(DEVICE.type == \"cuda\")):\n            logits = model(x)\n            loss = criterion(logits, y)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        bs = x.size(0)\n        total_loss_sum += loss.item() * bs\n        total_samples += bs\n\n        probs = torch.sigmoid(logits)\n        preds = (probs >= thr).float()\n\n        total_tp += (preds * y).sum().item()\n        total_fp += (preds * (1 - y)).sum().item()\n        total_fn += ((1 - preds) * y).sum().item()\n        total_tn += ((1 - preds) * (1 - y)).sum().item()\n\n        all_probs.append(probs.flatten().detach().cpu())\n        all_targets.append(y.flatten().detach().cpu())\n\n    precision = (total_tp + eps) / (total_tp + total_fp + eps)\n    recall    = (total_tp + eps) / (total_tp + total_fn + eps)\n    f1        = (2 * precision * recall) / (precision + recall + eps)\n    acc       = (total_tp + total_tn + eps) / (\n        total_tp + total_tn + total_fp + total_fn + eps\n    )\n\n    all_probs = torch.cat(all_probs).numpy()\n    all_targets = torch.cat(all_targets).numpy()\n    auc = roc_auc_score(all_targets, all_probs)\n\n    loss_global = total_loss_sum / total_samples\n\n    return loss_global, precision, recall, f1, acc, auc\n\n\n@torch.no_grad()\ndef validate_epoch(model, loader, thr=0.5, eps=1e-6):\n    model.eval()\n    total_loss_sum = 0.0\n    total_samples = 0\n\n    total_tp = total_fp = total_fn = total_tn = 0.0\n    all_probs, all_targets = [], []\n\n    for x, y in loader:\n        x, y = x.to(DEVICE), y.to(DEVICE)\n        x = normalize_batch(x, MEAN_13, STD_13)\n\n        logits = model(x)\n        loss = criterion(logits, y)\n\n        bs = x.size(0)\n        total_loss_sum += loss.item() * bs\n        total_samples += bs\n\n        probs = torch.sigmoid(logits)\n        preds = (probs >= thr).float()\n\n        total_tp += (preds * y).sum().item()\n        total_fp += (preds * (1 - y)).sum().item()\n        total_fn += ((1 - preds) * y).sum().item()\n        total_tn += ((1 - preds) * (1 - y)).sum().item()\n\n        all_probs.append(probs.flatten().cpu())\n        all_targets.append(y.flatten().cpu())\n\n    precision = (total_tp + eps) / (total_tp + total_fp + eps)\n    recall    = (total_tp + eps) / (total_tp + total_fn + eps)\n    f1        = (2 * precision * recall) / (precision + recall + eps)\n    acc       = (total_tp + total_tn + eps) / (\n        total_tp + total_tn + total_fp + total_fn + eps\n    )\n\n    all_probs = torch.cat(all_probs).numpy()\n    all_targets = torch.cat(all_targets).numpy()\n    auc = roc_auc_score(all_targets, all_probs)\n\n    loss_global = total_loss_sum / total_samples\n\n    return loss_global, precision, recall, f1, acc, auc\n","metadata":{"execution":{"iopub.status.busy":"2026-02-01T13:41:42.718597Z","iopub.execute_input":"2026-02-01T13:41:42.718863Z","iopub.status.idle":"2026-02-01T13:41:43.379808Z","shell.execute_reply.started":"2026-02-01T13:41:42.718838Z","shell.execute_reply":"2026-02-01T13:41:43.379106Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_55/735404605.py:6: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler(enabled=(DEVICE.type == \"cuda\"))\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"x_tr, _ = next(iter(train_loader))\nx_va, _ = next(iter(val_loader))\n\nx_tr = normalize_batch(x_tr.to(DEVICE), MEAN_13, STD_13)\nx_va = normalize_batch(x_va.to(DEVICE), MEAN_13, STD_13)\n\nprint(\"train norm min/max:\", x_tr.min().item(), x_tr.max().item())\nprint(\"val   norm min/max:\", x_va.min().item(), x_va.max().item())","metadata":{"execution":{"iopub.status.busy":"2026-02-01T13:41:43.380752Z","iopub.execute_input":"2026-02-01T13:41:43.381139Z","iopub.status.idle":"2026-02-01T13:41:44.151005Z","shell.execute_reply.started":"2026-02-01T13:41:43.381116Z","shell.execute_reply":"2026-02-01T13:41:44.150162Z"},"trusted":true},"outputs":[{"name":"stdout","text":"train norm min/max: -3.318262815475464 16.394107818603516\nval   norm min/max: -4.052846431732178 6.27053165435791\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"# TRAINING","metadata":{}},{"cell_type":"markdown","source":"JANGAN JLANIN INI LANGSUNG KE RECALL","metadata":{}},{"cell_type":"code","source":"BEST_PATH = \"/kaggle/working/unet_best.pth\"\nbest_val_f1 = -1\n\nimport pandas as pd\nhistory = []\n\nfor epoch in range(1, cfg.EPOCHS + 1):\n    t0 = time.time()\n\n    tr_loss, tr_prec, tr_rec, tr_f1, tr_acc, tr_auc = train_one_epoch(model, train_loader)\n    va_loss, va_prec, va_rec, va_f1, va_acc, va_auc = validate_epoch(model, val_loader, thr=0.5)\n    elapsed = time.time() - t0\n\n    print(\n        f\"[unet_basic] Epoch {epoch:03d} | \"\n        f\"tr_loss={tr_loss:.4f} tr_f1={tr_f1:.4f} tr_acc={tr_acc:.4f} tr_auc={tr_auc:.4f} || \"\n        f\"va_loss={va_loss:.4f} va_f1={va_f1:.4f} va_acc={va_acc:.4f} va_auc={va_auc:.4f} | \"\n        f\"{elapsed:.1f}s\"\n    )\n\n    history.append({\n        \"epoch\": epoch,\n    \n        \"tr_loss\": tr_loss,\n        \"tr_precision\": tr_prec,\n        \"tr_recall\": tr_rec,\n        \"tr_f1\": tr_f1,\n        \"tr_acc\": tr_acc,\n        \"tr_auc\": tr_auc,\n    \n        \"va_loss\": va_loss,\n        \"va_precision\": va_prec,\n        \"va_recall\": va_rec,\n        \"va_f1\": va_f1,\n        \"va_acc\": va_acc,\n        \"va_auc\": va_auc,\n    \n        \"seconds\": elapsed\n    })\n\n    if va_f1 > best_val_f1:\n        torch.save({\n            \"model_state\": model.state_dict(),\n            \"mean_13\": MEAN_13,\n            \"std_13\": STD_13,\n            \"thr\": thr,\n            \"epoch\": epoch,\n            \"best_val_f1\": best_val_f1,\n            \"va_auc\": va_auc,\n            \"model_name\": model_name\n        }, BEST_PATH)\n","metadata":{"execution":{"iopub.execute_input":"2026-01-01T17:53:08.918692Z","iopub.status.busy":"2026-01-01T17:53:08.918321Z","iopub.status.idle":"2026-01-01T18:57:24.681270Z","shell.execute_reply":"2026-01-01T18:57:24.680419Z","shell.execute_reply.started":"2026-01-01T17:53:08.918656Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"]},{"name":"stdout","output_type":"stream","text":["[unet_basic] Epoch 001 | tr_loss=0.2158 tr_f1=0.0234 tr_acc=0.9411 tr_auc=0.7017 || va_loss=0.1627 va_f1=0.0007 va_acc=0.9522 va_auc=0.8390 | 198.8s\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"]},{"name":"stdout","output_type":"stream","text":["[unet_basic] Epoch 002 | tr_loss=0.2008 tr_f1=0.0241 tr_acc=0.9411 tr_auc=0.6884 || va_loss=0.1650 va_f1=0.0468 va_acc=0.9530 va_auc=0.7855 | 195.5s\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"]},{"name":"stdout","output_type":"stream","text":["[unet_basic] Epoch 003 | tr_loss=0.1884 tr_f1=0.0207 tr_acc=0.9410 tr_auc=0.7671 || va_loss=0.1480 va_f1=0.1404 va_acc=0.9546 va_auc=0.8509 | 192.3s\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"]},{"name":"stdout","output_type":"stream","text":["[unet_basic] Epoch 004 | tr_loss=0.1851 tr_f1=0.1225 tr_acc=0.9419 tr_auc=0.7681 || va_loss=0.1444 va_f1=0.1438 va_acc=0.9547 va_auc=0.8699 | 187.6s\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"]},{"name":"stdout","output_type":"stream","text":["[unet_basic] Epoch 005 | tr_loss=0.1787 tr_f1=0.2314 tr_acc=0.9437 tr_auc=0.7872 || va_loss=0.1605 va_f1=0.0214 va_acc=0.9525 va_auc=0.8287 | 187.1s\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"]},{"name":"stdout","output_type":"stream","text":["[unet_basic] Epoch 006 | tr_loss=0.1752 tr_f1=0.2767 tr_acc=0.9436 tr_auc=0.8052 || va_loss=0.1584 va_f1=0.0000 va_acc=0.9522 va_auc=0.8290 | 195.6s\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"]},{"name":"stdout","output_type":"stream","text":["[unet_basic] Epoch 007 | tr_loss=0.1756 tr_f1=0.2651 tr_acc=0.9430 tr_auc=0.7977 || va_loss=0.1667 va_f1=0.0000 va_acc=0.9522 va_auc=0.7991 | 194.4s\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"]},{"name":"stdout","output_type":"stream","text":["[unet_basic] Epoch 008 | tr_loss=0.1735 tr_f1=0.2695 tr_acc=0.9437 tr_auc=0.8178 || va_loss=0.1469 va_f1=0.1335 va_acc=0.9543 va_auc=0.8729 | 194.8s\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"]},{"name":"stdout","output_type":"stream","text":["[unet_basic] Epoch 009 | tr_loss=0.1707 tr_f1=0.2865 tr_acc=0.9449 tr_auc=0.8161 || va_loss=0.1573 va_f1=0.0000 va_acc=0.9522 va_auc=0.8554 | 189.7s\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"]},{"name":"stdout","output_type":"stream","text":["[unet_basic] Epoch 010 | tr_loss=0.1685 tr_f1=0.3602 tr_acc=0.9463 tr_auc=0.8220 || va_loss=0.1472 va_f1=0.1832 va_acc=0.9549 va_auc=0.8600 | 189.6s\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"]},{"name":"stdout","output_type":"stream","text":["[unet_basic] Epoch 011 | tr_loss=0.1649 tr_f1=0.3347 tr_acc=0.9458 tr_auc=0.8312 || va_loss=0.1505 va_f1=0.0550 va_acc=0.9531 va_auc=0.8533 | 191.4s\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"]},{"name":"stdout","output_type":"stream","text":["[unet_basic] Epoch 012 | tr_loss=0.1681 tr_f1=0.3607 tr_acc=0.9470 tr_auc=0.8157 || va_loss=0.1489 va_f1=0.0000 va_acc=0.9522 va_auc=0.8641 | 191.8s\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"]},{"name":"stdout","output_type":"stream","text":["[unet_basic] Epoch 013 | tr_loss=0.1652 tr_f1=0.3453 tr_acc=0.9458 tr_auc=0.8426 || va_loss=0.1415 va_f1=0.1635 va_acc=0.9545 va_auc=0.8671 | 195.2s\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"]},{"name":"stdout","output_type":"stream","text":["[unet_basic] Epoch 014 | tr_loss=0.1628 tr_f1=0.3625 tr_acc=0.9462 tr_auc=0.8417 || va_loss=0.1614 va_f1=0.0000 va_acc=0.9522 va_auc=0.8598 | 192.5s\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"]},{"name":"stdout","output_type":"stream","text":["[unet_basic] Epoch 015 | tr_loss=0.1756 tr_f1=0.2703 tr_acc=0.9443 tr_auc=0.8111 || va_loss=0.2844 va_f1=0.0000 va_acc=0.9522 va_auc=0.5947 | 194.8s\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"]},{"name":"stdout","output_type":"stream","text":["[unet_basic] Epoch 016 | tr_loss=0.1684 tr_f1=0.2927 tr_acc=0.9465 tr_auc=0.8270 || va_loss=0.1428 va_f1=0.1002 va_acc=0.9537 va_auc=0.8595 | 193.8s\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"]},{"name":"stdout","output_type":"stream","text":["[unet_basic] Epoch 017 | tr_loss=0.1602 tr_f1=0.3762 tr_acc=0.9472 tr_auc=0.8480 || va_loss=0.1379 va_f1=0.2023 va_acc=0.9556 va_auc=0.8790 | 194.1s\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"]},{"name":"stdout","output_type":"stream","text":["[unet_basic] Epoch 018 | tr_loss=0.1484 tr_f1=0.4399 tr_acc=0.9500 tr_auc=0.8739 || va_loss=0.1444 va_f1=0.4110 va_acc=0.9599 va_auc=0.8884 | 190.3s\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"]},{"name":"stdout","output_type":"stream","text":["[unet_basic] Epoch 019 | tr_loss=0.1477 tr_f1=0.4413 tr_acc=0.9489 tr_auc=0.8770 || va_loss=0.1427 va_f1=0.2610 va_acc=0.9564 va_auc=0.8880 | 193.1s\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"]},{"name":"stdout","output_type":"stream","text":["[unet_basic] Epoch 020 | tr_loss=0.1380 tr_f1=0.4970 tr_acc=0.9531 tr_auc=0.8877 || va_loss=0.1479 va_f1=0.0000 va_acc=0.9522 va_auc=0.8732 | 192.7s\n"]}],"execution_count":23},{"cell_type":"code","source":"df_history = pd.DataFrame(history)\n\ndf_history = df_history.round(4)\ncsv_path = \"/kaggle/working/training_metrics1.csv\"\ndf_history.to_csv(csv_path, index=False)\nprint(\"Saved to:\", csv_path)\ndf_history\n","metadata":{"execution":{"iopub.execute_input":"2026-01-01T19:07:51.921829Z","iopub.status.busy":"2026-01-01T19:07:51.921070Z","iopub.status.idle":"2026-01-01T19:07:51.952498Z","shell.execute_reply":"2026-01-01T19:07:51.951646Z","shell.execute_reply.started":"2026-01-01T19:07:51.921800Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>epoch</th>\n","      <th>tr_loss</th>\n","      <th>tr_precision</th>\n","      <th>tr_recall</th>\n","      <th>tr_f1</th>\n","      <th>tr_acc</th>\n","      <th>tr_auc</th>\n","      <th>va_loss</th>\n","      <th>va_precision</th>\n","      <th>va_recall</th>\n","      <th>va_f1</th>\n","      <th>va_acc</th>\n","      <th>va_auc</th>\n","      <th>seconds</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0.2158</td>\n","      <td>0.5144</td>\n","      <td>0.0120</td>\n","      <td>0.0234</td>\n","      <td>0.9411</td>\n","      <td>0.7017</td>\n","      <td>0.1627</td>\n","      <td>0.6629</td>\n","      <td>0.0004</td>\n","      <td>0.0007</td>\n","      <td>0.9522</td>\n","      <td>0.8390</td>\n","      <td>198.7840</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0.2008</td>\n","      <td>0.4886</td>\n","      <td>0.0124</td>\n","      <td>0.0241</td>\n","      <td>0.9411</td>\n","      <td>0.6884</td>\n","      <td>0.1650</td>\n","      <td>0.7561</td>\n","      <td>0.0241</td>\n","      <td>0.0468</td>\n","      <td>0.9530</td>\n","      <td>0.7855</td>\n","      <td>195.5212</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0.1884</td>\n","      <td>0.4473</td>\n","      <td>0.0106</td>\n","      <td>0.0207</td>\n","      <td>0.9410</td>\n","      <td>0.7671</td>\n","      <td>0.1480</td>\n","      <td>0.7419</td>\n","      <td>0.0775</td>\n","      <td>0.1404</td>\n","      <td>0.9546</td>\n","      <td>0.8509</td>\n","      <td>192.3430</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>0.1851</td>\n","      <td>0.5523</td>\n","      <td>0.0689</td>\n","      <td>0.1225</td>\n","      <td>0.9419</td>\n","      <td>0.7681</td>\n","      <td>0.1444</td>\n","      <td>0.7418</td>\n","      <td>0.0796</td>\n","      <td>0.1438</td>\n","      <td>0.9547</td>\n","      <td>0.8699</td>\n","      <td>187.6002</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0.1787</td>\n","      <td>0.5891</td>\n","      <td>0.1440</td>\n","      <td>0.2314</td>\n","      <td>0.9437</td>\n","      <td>0.7872</td>\n","      <td>0.1605</td>\n","      <td>0.7568</td>\n","      <td>0.0109</td>\n","      <td>0.0214</td>\n","      <td>0.9525</td>\n","      <td>0.8287</td>\n","      <td>187.1016</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>0.1752</td>\n","      <td>0.5649</td>\n","      <td>0.1832</td>\n","      <td>0.2767</td>\n","      <td>0.9436</td>\n","      <td>0.8052</td>\n","      <td>0.1584</td>\n","      <td>1.0000</td>\n","      <td>0.0000</td>\n","      <td>0.0000</td>\n","      <td>0.9522</td>\n","      <td>0.8290</td>\n","      <td>195.6284</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>0.1756</td>\n","      <td>0.5516</td>\n","      <td>0.1745</td>\n","      <td>0.2651</td>\n","      <td>0.9430</td>\n","      <td>0.7977</td>\n","      <td>0.1667</td>\n","      <td>1.0000</td>\n","      <td>0.0000</td>\n","      <td>0.0000</td>\n","      <td>0.9522</td>\n","      <td>0.7991</td>\n","      <td>194.3773</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>0.1735</td>\n","      <td>0.5704</td>\n","      <td>0.1764</td>\n","      <td>0.2695</td>\n","      <td>0.9437</td>\n","      <td>0.8178</td>\n","      <td>0.1469</td>\n","      <td>0.7227</td>\n","      <td>0.0735</td>\n","      <td>0.1335</td>\n","      <td>0.9543</td>\n","      <td>0.8729</td>\n","      <td>194.8437</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>0.1707</td>\n","      <td>0.6034</td>\n","      <td>0.1878</td>\n","      <td>0.2865</td>\n","      <td>0.9449</td>\n","      <td>0.8161</td>\n","      <td>0.1573</td>\n","      <td>1.0000</td>\n","      <td>0.0000</td>\n","      <td>0.0000</td>\n","      <td>0.9522</td>\n","      <td>0.8554</td>\n","      <td>189.7026</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>0.1685</td>\n","      <td>0.6035</td>\n","      <td>0.2568</td>\n","      <td>0.3602</td>\n","      <td>0.9463</td>\n","      <td>0.8220</td>\n","      <td>0.1472</td>\n","      <td>0.6880</td>\n","      <td>0.1057</td>\n","      <td>0.1832</td>\n","      <td>0.9549</td>\n","      <td>0.8600</td>\n","      <td>189.6036</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>11</td>\n","      <td>0.1649</td>\n","      <td>0.6053</td>\n","      <td>0.2313</td>\n","      <td>0.3347</td>\n","      <td>0.9458</td>\n","      <td>0.8312</td>\n","      <td>0.1505</td>\n","      <td>0.7427</td>\n","      <td>0.0285</td>\n","      <td>0.0550</td>\n","      <td>0.9531</td>\n","      <td>0.8533</td>\n","      <td>191.3678</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>12</td>\n","      <td>0.1681</td>\n","      <td>0.6222</td>\n","      <td>0.2539</td>\n","      <td>0.3607</td>\n","      <td>0.9470</td>\n","      <td>0.8157</td>\n","      <td>0.1489</td>\n","      <td>1.0000</td>\n","      <td>0.0000</td>\n","      <td>0.0000</td>\n","      <td>0.9522</td>\n","      <td>0.8641</td>\n","      <td>191.7600</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>13</td>\n","      <td>0.1652</td>\n","      <td>0.5974</td>\n","      <td>0.2428</td>\n","      <td>0.3453</td>\n","      <td>0.9458</td>\n","      <td>0.8426</td>\n","      <td>0.1415</td>\n","      <td>0.6730</td>\n","      <td>0.0930</td>\n","      <td>0.1635</td>\n","      <td>0.9545</td>\n","      <td>0.8671</td>\n","      <td>195.1704</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>14</td>\n","      <td>0.1628</td>\n","      <td>0.6008</td>\n","      <td>0.2596</td>\n","      <td>0.3625</td>\n","      <td>0.9462</td>\n","      <td>0.8417</td>\n","      <td>0.1614</td>\n","      <td>1.0000</td>\n","      <td>0.0000</td>\n","      <td>0.0000</td>\n","      <td>0.9522</td>\n","      <td>0.8598</td>\n","      <td>192.4867</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>15</td>\n","      <td>0.1756</td>\n","      <td>0.5928</td>\n","      <td>0.1751</td>\n","      <td>0.2703</td>\n","      <td>0.9443</td>\n","      <td>0.8111</td>\n","      <td>0.2844</td>\n","      <td>1.0000</td>\n","      <td>0.0000</td>\n","      <td>0.0000</td>\n","      <td>0.9522</td>\n","      <td>0.5947</td>\n","      <td>194.8026</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>16</td>\n","      <td>0.1684</td>\n","      <td>0.6598</td>\n","      <td>0.1881</td>\n","      <td>0.2927</td>\n","      <td>0.9465</td>\n","      <td>0.8270</td>\n","      <td>0.1428</td>\n","      <td>0.7188</td>\n","      <td>0.0539</td>\n","      <td>0.1002</td>\n","      <td>0.9537</td>\n","      <td>0.8595</td>\n","      <td>193.7663</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>17</td>\n","      <td>0.1602</td>\n","      <td>0.6194</td>\n","      <td>0.2702</td>\n","      <td>0.3762</td>\n","      <td>0.9472</td>\n","      <td>0.8480</td>\n","      <td>0.1379</td>\n","      <td>0.7183</td>\n","      <td>0.1177</td>\n","      <td>0.2023</td>\n","      <td>0.9556</td>\n","      <td>0.8790</td>\n","      <td>194.0770</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>18</td>\n","      <td>0.1484</td>\n","      <td>0.6462</td>\n","      <td>0.3335</td>\n","      <td>0.4399</td>\n","      <td>0.9500</td>\n","      <td>0.8739</td>\n","      <td>0.1444</td>\n","      <td>0.6905</td>\n","      <td>0.2926</td>\n","      <td>0.4110</td>\n","      <td>0.9599</td>\n","      <td>0.8884</td>\n","      <td>190.2770</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>19</td>\n","      <td>0.1477</td>\n","      <td>0.6198</td>\n","      <td>0.3426</td>\n","      <td>0.4413</td>\n","      <td>0.9489</td>\n","      <td>0.8770</td>\n","      <td>0.1427</td>\n","      <td>0.6871</td>\n","      <td>0.1611</td>\n","      <td>0.2610</td>\n","      <td>0.9564</td>\n","      <td>0.8880</td>\n","      <td>193.0908</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>20</td>\n","      <td>0.1380</td>\n","      <td>0.6756</td>\n","      <td>0.3931</td>\n","      <td>0.4970</td>\n","      <td>0.9531</td>\n","      <td>0.8877</td>\n","      <td>0.1479</td>\n","      <td>0.0000</td>\n","      <td>0.0000</td>\n","      <td>0.0000</td>\n","      <td>0.9522</td>\n","      <td>0.8732</td>\n","      <td>192.6742</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    epoch  tr_loss  tr_precision  tr_recall   tr_f1  tr_acc  tr_auc  va_loss  \\\n","0       1   0.2158        0.5144     0.0120  0.0234  0.9411  0.7017   0.1627   \n","1       2   0.2008        0.4886     0.0124  0.0241  0.9411  0.6884   0.1650   \n","2       3   0.1884        0.4473     0.0106  0.0207  0.9410  0.7671   0.1480   \n","3       4   0.1851        0.5523     0.0689  0.1225  0.9419  0.7681   0.1444   \n","4       5   0.1787        0.5891     0.1440  0.2314  0.9437  0.7872   0.1605   \n","5       6   0.1752        0.5649     0.1832  0.2767  0.9436  0.8052   0.1584   \n","6       7   0.1756        0.5516     0.1745  0.2651  0.9430  0.7977   0.1667   \n","7       8   0.1735        0.5704     0.1764  0.2695  0.9437  0.8178   0.1469   \n","8       9   0.1707        0.6034     0.1878  0.2865  0.9449  0.8161   0.1573   \n","9      10   0.1685        0.6035     0.2568  0.3602  0.9463  0.8220   0.1472   \n","10     11   0.1649        0.6053     0.2313  0.3347  0.9458  0.8312   0.1505   \n","11     12   0.1681        0.6222     0.2539  0.3607  0.9470  0.8157   0.1489   \n","12     13   0.1652        0.5974     0.2428  0.3453  0.9458  0.8426   0.1415   \n","13     14   0.1628        0.6008     0.2596  0.3625  0.9462  0.8417   0.1614   \n","14     15   0.1756        0.5928     0.1751  0.2703  0.9443  0.8111   0.2844   \n","15     16   0.1684        0.6598     0.1881  0.2927  0.9465  0.8270   0.1428   \n","16     17   0.1602        0.6194     0.2702  0.3762  0.9472  0.8480   0.1379   \n","17     18   0.1484        0.6462     0.3335  0.4399  0.9500  0.8739   0.1444   \n","18     19   0.1477        0.6198     0.3426  0.4413  0.9489  0.8770   0.1427   \n","19     20   0.1380        0.6756     0.3931  0.4970  0.9531  0.8877   0.1479   \n","\n","    va_precision  va_recall   va_f1  va_acc  va_auc   seconds  \n","0         0.6629     0.0004  0.0007  0.9522  0.8390  198.7840  \n","1         0.7561     0.0241  0.0468  0.9530  0.7855  195.5212  \n","2         0.7419     0.0775  0.1404  0.9546  0.8509  192.3430  \n","3         0.7418     0.0796  0.1438  0.9547  0.8699  187.6002  \n","4         0.7568     0.0109  0.0214  0.9525  0.8287  187.1016  \n","5         1.0000     0.0000  0.0000  0.9522  0.8290  195.6284  \n","6         1.0000     0.0000  0.0000  0.9522  0.7991  194.3773  \n","7         0.7227     0.0735  0.1335  0.9543  0.8729  194.8437  \n","8         1.0000     0.0000  0.0000  0.9522  0.8554  189.7026  \n","9         0.6880     0.1057  0.1832  0.9549  0.8600  189.6036  \n","10        0.7427     0.0285  0.0550  0.9531  0.8533  191.3678  \n","11        1.0000     0.0000  0.0000  0.9522  0.8641  191.7600  \n","12        0.6730     0.0930  0.1635  0.9545  0.8671  195.1704  \n","13        1.0000     0.0000  0.0000  0.9522  0.8598  192.4867  \n","14        1.0000     0.0000  0.0000  0.9522  0.5947  194.8026  \n","15        0.7188     0.0539  0.1002  0.9537  0.8595  193.7663  \n","16        0.7183     0.1177  0.2023  0.9556  0.8790  194.0770  \n","17        0.6905     0.2926  0.4110  0.9599  0.8884  190.2770  \n","18        0.6871     0.1611  0.2610  0.9564  0.8880  193.0908  \n","19        0.0000     0.0000  0.0000  0.9522  0.8732  192.6742  "]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"execution_count":25},{"cell_type":"markdown","source":"# SETTING THRESHOLD & PREDICTING VAL_TEST SET","metadata":{}},{"cell_type":"code","source":"@torch.no_grad()\ndef find_best_thr_global_f1(model, loader, grid=None, eps=1e-6):\n    model.eval()\n    if grid is None:\n        grid = np.linspace(0.05, 0.95, 19)\n\n    best_thr = None\n    best_f1 = -1\n    log = []\n\n    for thr in grid:\n        total_tp = total_fp = total_fn = 0.0\n\n        for x, y in loader:\n            x, y = x.to(DEVICE), y.to(DEVICE)\n            x = normalize_batch(x, MEAN_13, STD_13)\n\n            logits = model(x)\n            probs = torch.sigmoid(logits)\n            preds = (probs >= thr).float()\n\n            total_tp += (preds * y).sum().item()\n            total_fp += (preds * (1 - y)).sum().item()\n            total_fn += ((1 - preds) * y).sum().item()\n\n        precision = (total_tp + eps) / (total_tp + total_fp + eps)\n        recall    = (total_tp + eps) / (total_tp + total_fn + eps)\n        f1        = (2 * precision * recall) / (precision + recall + eps)\n\n        log.append((float(thr), f1))\n\n        if f1 > best_f1:\n            best_f1 = f1\n            best_thr = float(thr)\n\n    return best_thr, best_f1, log\n\nt_best, best_f1, thr_log = find_best_thr_global_f1(model, val_loader)\n\nprint(\"Chosen threshold:\", t_best)\nprint(\"Best global F1:\", best_f1)\n\nprint(\"Top-5 thresholds:\")\nfor thr, f1 in sorted(thr_log, key=lambda x: x[1], reverse=True)[:5]:\n    print(thr, f1)","metadata":{"execution":{"iopub.execute_input":"2026-01-01T19:34:35.925718Z","iopub.status.busy":"2026-01-01T19:34:35.925386Z","iopub.status.idle":"2026-01-01T19:37:05.838004Z","shell.execute_reply":"2026-01-01T19:37:05.837293Z","shell.execute_reply.started":"2026-01-01T19:34:35.925690Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Chosen threshold: 0.15\n","Best global F1: 0.4531659705675882\n","Top-5 thresholds:\n","0.15 0.4531659705675882\n","0.1 0.4306327801299006\n","0.2 0.31735838172380243\n","0.05 0.2870529543492742\n","0.25 0.0921978563493968\n"]}],"execution_count":31},{"cell_type":"code","source":"va_loss, va_prec, va_rec, va_f1, va_acc, va_auc = validate_epoch(\n    model, val_loader, thr=t_best\n)\nprint(f\"val_loss   : {va_loss:.4f}\")\nprint(f\"val_prec   : {va_prec:.4f}\")\nprint(f\"val_recall : {va_rec:.4f}\")\nprint(f\"val_f1     : {va_f1:.4f}\")\nprint(f\"val_acc    : {va_acc:.4f}\")\nprint(f\"val_auc    : {va_auc:.4f}\")\nprint(f\"threshold  : {t_best:.2f}\")","metadata":{"execution":{"iopub.execute_input":"2026-01-01T20:11:33.171675Z","iopub.status.busy":"2026-01-01T20:11:33.171076Z","iopub.status.idle":"2026-01-01T20:12:03.913323Z","shell.execute_reply":"2026-01-01T20:12:03.912529Z","shell.execute_reply.started":"2026-01-01T20:11:33.171633Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["val_loss   : 0.1479\n","val_prec   : 0.5960\n","val_recall : 0.3655\n","val_f1     : 0.4532\n","val_acc    : 0.9578\n","val_auc    : 0.8732\n","threshold  : 0.15\n"]}],"execution_count":42},{"cell_type":"code","source":"# sweet spot refine\nsweet_grid = np.linspace(0.10, 0.20, 11)  # step 0.01\nt_best, best_f1, thr_log = find_best_thr_global_f1(model, val_loader,  grid=sweet_grid)\nprint(\"Chosen threshold:\", t_best)\nprint(\"Best global F1:\", best_f1)","metadata":{"execution":{"iopub.execute_input":"2026-01-01T19:49:16.068620Z","iopub.status.busy":"2026-01-01T19:49:16.067782Z","iopub.status.idle":"2026-01-01T19:50:41.461336Z","shell.execute_reply":"2026-01-01T19:50:41.460519Z","shell.execute_reply.started":"2026-01-01T19:49:16.068588Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Chosen threshold: 0.13\n","Best global F1: 0.45931266084982436\n"]}],"execution_count":36},{"cell_type":"markdown","source":"bener ini harusny metric nya AUC bukan F1-score, selisih dari 0.1 sampe 0.5 drastis bgt, ini kebetulan didapat f1 tertingginy sama dengan AUC tertinggi","metadata":{}},{"cell_type":"code","source":"va_loss, va_prec, va_rec, va_f1, va_acc, va_auc = validate_epoch(\n    model, val_loader, thr=t_best\n)\nprint(f\"val_loss   : {va_loss:.4f}\")\nprint(f\"val_prec   : {va_prec:.4f}\")\nprint(f\"val_recall : {va_rec:.4f}\")\nprint(f\"val_f1     : {va_f1:.4f}\")\nprint(f\"val_acc    : {va_acc:.4f}\")\nprint(f\"val_auc    : {va_auc:.4f}\")\nprint(f\"threshold  : {t_best:.2f}\")","metadata":{"execution":{"iopub.execute_input":"2026-01-01T20:09:43.501958Z","iopub.status.busy":"2026-01-01T20:09:43.501056Z","iopub.status.idle":"2026-01-01T20:10:13.864371Z","shell.execute_reply":"2026-01-01T20:10:13.863470Z","shell.execute_reply.started":"2026-01-01T20:09:43.501931Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["val_loss   : 0.1479\n","val_prec   : 0.5068\n","val_recall : 0.4199\n","val_f1     : 0.4593\n","val_acc    : 0.9527\n","val_auc    : 0.8732\n","threshold  : 0.13\n"]}],"execution_count":39},{"cell_type":"code","source":"# pake t_high 0.45 0.85 auc LU\n\n# print(f\"val_loss   : {va_loss:.4f}\")\n# print(f\"val_prec   : {va_prec:.4f}\")\n# print(f\"val_recall : {va_rec:.4f}\")\n# print(f\"val_f1     : {va_f1:.4f}\")\n# print(f\"val_acc    : {va_acc:.4f}\")\n# print(f\"val_auc    : {va_auc:.4f}\")\n# print(f\"threshold  : {t_high:.2f}\")","metadata":{"execution":{"iopub.execute_input":"2026-01-01T19:22:34.740380Z","iopub.status.busy":"2026-01-01T19:22:34.740071Z","iopub.status.idle":"2026-01-01T19:22:34.745600Z","shell.execute_reply":"2026-01-01T19:22:34.744943Z","shell.execute_reply.started":"2026-01-01T19:22:34.740353Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["val_loss   : 0.1479\n","val_prec   : 0.5132\n","val_recall : 0.0001\n","val_f1     : 0.0002\n","val_acc    : 0.9522\n","val_auc    : 0.8732\n","threshold  : 0.45\n"]}],"execution_count":30},{"cell_type":"code","source":"test_loss, test_prec, test_rec, test_f1, test_acc, test_auc = validate_epoch(\n    model, test_loader, thr=t_best\n)\n\nprint(f\"Test Loss   : {test_loss:.4f}\")\nprint(f\"Test Prec   : {test_prec:.4f}\")\nprint(f\"Test Recall : {test_rec:.4f}\")\nprint(f\"Test F1     : {test_f1:.4f}\")\nprint(f\"Test Acc    : {test_acc:.4f}\")\nprint(f\"Test AUC    : {test_auc:.4f}\")","metadata":{"execution":{"iopub.execute_input":"2026-01-01T20:16:09.825665Z","iopub.status.busy":"2026-01-01T20:16:09.824925Z","iopub.status.idle":"2026-01-01T20:16:39.344312Z","shell.execute_reply":"2026-01-01T20:16:39.343366Z","shell.execute_reply.started":"2026-01-01T20:16:09.825636Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Loss   : 0.0958\n","Test Prec   : 0.2929\n","Test Recall : 0.3537\n","Test F1     : 0.3204\n","Test Acc    : 0.9636\n","Test AUC    : 0.8443\n"]}],"execution_count":45},{"cell_type":"markdown","source":"# RECALL MODEL","metadata":{}},{"cell_type":"code","source":"model = build_unet(cfg.IN_CHANNELS).to(DEVICE)\nckpt = torch.load(\n    \"/kaggle/input/unet-best2/pytorch/default/1/unet_best.pth\",\n    map_location=DEVICE\n)\nmodel.load_state_dict(ckpt[\"model_state\"])","metadata":{"execution":{"iopub.execute_input":"2026-01-08T09:29:27.878066Z","iopub.status.busy":"2026-01-08T09:29:27.877671Z","iopub.status.idle":"2026-01-08T09:29:28.990291Z","shell.execute_reply":"2026-01-08T09:29:28.989731Z","shell.execute_reply.started":"2026-01-08T09:29:27.878042Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"execution_count":18},{"cell_type":"markdown","source":"# Load model (yang diatas error)","metadata":{}},{"cell_type":"code","source":"import torch\nimport segmentation_models_pytorch as smp\nimport re\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# -------------------------------------------------\n# 1. Extract state_dict dengan aman\n# -------------------------------------------------\ndef extract_state_dict(ckpt):\n    if \"model_state\" in ckpt:\n        return ckpt[\"model_state\"]\n    if \"state_dict\" in ckpt:\n        return ckpt[\"state_dict\"]\n    if any(k.startswith((\"encoder.\", \"decoder.\", \"segmentation_head\")) for k in ckpt.keys()):\n        return ckpt\n    raise ValueError(\"Tidak ditemukan state_dict di checkpoint\")\n\n# -------------------------------------------------\n# 2. Auto-detect ResNet encoder\n# -------------------------------------------------\ndef infer_resnet_encoder(state):\n    layer_max = {1:-1, 2:-1, 3:-1, 4:-1}\n    pat = re.compile(r\"encoder\\.layer([1-4])\\.(\\d+)\\.\")\n    for k in state.keys():\n        m = pat.search(k)\n        if m:\n            layer = int(m.group(1))\n            blk   = int(m.group(2))\n            layer_max[layer] = max(layer_max[layer], blk)\n\n    if layer_max == {1:1, 2:1, 3:1, 4:1}:\n        return \"resnet18\"\n    if layer_max == {1:2, 2:3, 3:5, 4:2}:\n        return \"resnet34\"\n    return \"resnet34\"  # fallback aman\n\n# -------------------------------------------------\n# 3. Loader UNet-ResNet FINAL\n# -------------------------------------------------\ndef load_unet_resnet(path, in_channels):\n    ckpt = torch.load(path, map_location=\"cpu\", weights_only=False)\n    state = extract_state_dict(ckpt)\n\n    # bersihkan prefix module.\n    state = {k.replace(\"module.\", \"\"): v for k, v in state.items()}\n\n    encoder = infer_resnet_encoder(state)\n    print(f\"[INFO] Detected UNet encoder = {encoder}\")\n\n    model = smp.Unet(\n        encoder_name=encoder,\n        encoder_weights=None,\n        in_channels=in_channels,\n        classes=1,\n        activation=None\n    ).to(DEVICE).eval()\n\n    model.load_state_dict(state, strict=True)\n    print(\"[OK] UNet-ResNet loaded successfully\")\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-01T13:41:44.152479Z","iopub.execute_input":"2026-02-01T13:41:44.153046Z","iopub.status.idle":"2026-02-01T13:41:44.161749Z","shell.execute_reply.started":"2026-02-01T13:41:44.153015Z","shell.execute_reply":"2026-02-01T13:41:44.161135Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"UNET_RESNET_PATH = \"/kaggle/input/u-net/pytorch/default/1/unet_best (1).pth\"\n\nunet_resnet = load_unet_resnet(\n    UNET_RESNET_PATH,\n    in_channels=cfg.IN_CHANNELS\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-01T13:41:44.162810Z","iopub.execute_input":"2026-02-01T13:41:44.163152Z","iopub.status.idle":"2026-02-01T13:41:44.752200Z","shell.execute_reply.started":"2026-02-01T13:41:44.163117Z","shell.execute_reply":"2026-02-01T13:41:44.751613Z"}},"outputs":[{"name":"stdout","text":"[INFO] Detected UNet encoder = resnet18\n[OK] UNet-ResNet loaded successfully\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"from torch.amp import autocast, GradScaler\nfrom sklearn.metrics import roc_auc_score\nimport time\n\noptimizer = torch.optim.Adam(model.parameters(), lr=cfg.LR)\nscaler = GradScaler(enabled=(DEVICE.type == \"cuda\"))\n\ndef train_one_epoch(model, loader, thr=0.5, eps=1e-6):\n    model.train()\n    total_loss_sum = 0.0\n    total_samples = 0\n\n    total_tp = total_fp = total_fn = total_tn = 0.0\n    all_probs, all_targets = [], []\n\n    for x, y in loader:\n        x, y = x.to(DEVICE), y.to(DEVICE)\n        x = normalize_batch(x, MEAN_13, STD_13)\n\n        optimizer.zero_grad(set_to_none=True)\n\n        with autocast(\"cuda\", enabled=(DEVICE.type == \"cuda\")):\n            logits = model(x)\n            loss = criterion(logits, y)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        bs = x.size(0)\n        total_loss_sum += loss.item() * bs\n        total_samples += bs\n\n        probs = torch.sigmoid(logits)\n        preds = (probs >= thr).float()\n\n        total_tp += (preds * y).sum().item()\n        total_fp += (preds * (1 - y)).sum().item()\n        total_fn += ((1 - preds) * y).sum().item()\n        total_tn += ((1 - preds) * (1 - y)).sum().item()\n\n        all_probs.append(probs.flatten().detach().cpu())\n        all_targets.append(y.flatten().detach().cpu())\n\n    precision = (total_tp + eps) / (total_tp + total_fp + eps)\n    recall    = (total_tp + eps) / (total_tp + total_fn + eps)\n    f1        = (2 * precision * recall) / (precision + recall + eps)\n    acc       = (total_tp + total_tn + eps) / (\n        total_tp + total_tn + total_fp + total_fn + eps\n    )\n\n    all_probs = torch.cat(all_probs).numpy()\n    all_targets = torch.cat(all_targets).numpy()\n    auc = roc_auc_score(all_targets, all_probs)\n\n    loss_global = total_loss_sum / total_samples\n\n    return loss_global, precision, recall, f1, acc, auc\n\n\n@torch.no_grad()\ndef validate_epoch(model, loader, thr=0.13, eps=1e-6):\n    model.eval()\n    total_loss_sum = 0.0\n    total_samples = 0\n\n    total_tp = total_fp = total_fn = total_tn = 0.0\n    all_probs, all_targets = [], []\n\n    for x, y in loader:\n        x, y = x.to(DEVICE), y.to(DEVICE)\n        x = normalize_batch(x, MEAN_13, STD_13)\n\n        logits = model(x)\n        loss = criterion(logits, y)\n\n        bs = x.size(0)\n        total_loss_sum += loss.item() * bs\n        total_samples += bs\n\n        probs = torch.sigmoid(logits)\n        preds = (probs >= thr).float()\n\n        total_tp += (preds * y).sum().item()\n        total_fp += (preds * (1 - y)).sum().item()\n        total_fn += ((1 - preds) * y).sum().item()\n        total_tn += ((1 - preds) * (1 - y)).sum().item()\n\n        all_probs.append(probs.flatten().cpu())\n        all_targets.append(y.flatten().cpu())\n\n    precision = (total_tp + eps) / (total_tp + total_fp + eps)\n    recall    = (total_tp + eps) / (total_tp + total_fn + eps)\n    f1        = (2 * precision * recall) / (precision + recall + eps)\n    acc       = (total_tp + total_tn + eps) / (\n        total_tp + total_tn + total_fp + total_fn + eps\n    )\n\n    all_probs = torch.cat(all_probs).numpy()\n    all_targets = torch.cat(all_targets).numpy()\n    auc = roc_auc_score(all_targets, all_probs)\n\n    loss_global = total_loss_sum / total_samples\n\n    return loss_global, precision, recall, f1, acc, auc","metadata":{"execution":{"iopub.status.busy":"2026-02-01T13:41:44.754828Z","iopub.execute_input":"2026-02-01T13:41:44.755071Z","iopub.status.idle":"2026-02-01T13:41:44.770378Z","shell.execute_reply.started":"2026-02-01T13:41:44.755049Z","shell.execute_reply":"2026-02-01T13:41:44.769517Z"},"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"code","source":"BEST_PATH = \"/kaggle/working/unet_best_retrained2.pth\"\nbest_val_f1 = -1\n\nimport pandas as pd\nhistory = []\n\nfor epoch in range(1, cfg.EPOCHS + 1):\n    t0 = time.time()\n\n    tr_loss, tr_prec, tr_rec, tr_f1, tr_acc, tr_auc = train_one_epoch(model, train_loader)\n    va_loss, va_prec, va_rec, va_f1, va_acc, va_auc = validate_epoch(model, val_loader)\n    elapsed = time.time() - t0\n\n    print(\n        f\"[unet_basic] Epoch {epoch:03d} | \"\n        f\"tr_loss={tr_loss:.4f} tr_f1={tr_f1:.4f} tr_acc={tr_acc:.4f} tr_auc={tr_auc:.4f} || \"\n        f\"va_loss={va_loss:.4f} va_f1={va_f1:.4f} va_acc={va_acc:.4f} va_auc={va_auc:.4f} | \"\n        f\"{elapsed:.1f}s\"\n    )\n\n    history.append({\n        \"epoch\": epoch,\n    \n        \"tr_loss\": tr_loss,\n        \"tr_precision\": tr_prec,\n        \"tr_recall\": tr_rec,\n        \"tr_f1\": tr_f1,\n        \"tr_acc\": tr_acc,\n        \"tr_auc\": tr_auc,\n    \n        \"va_loss\": va_loss,\n        \"va_precision\": va_prec,\n        \"va_recall\": va_rec,\n        \"va_f1\": va_f1,\n        \"va_acc\": va_acc,\n        \"va_auc\": va_auc,\n    \n        \"seconds\": elapsed\n    })\n\n    if va_f1 > best_val_f1:\n        best_val_f1 = va_f1\n        torch.save({\n            \"model_state\": model.state_dict(),\n            \"mean_13\": MEAN_13,\n            \"std_13\":  STD_13,\n            \"epoch\": epoch,\n            \"best_val_f1\": best_val_f1,\n            \"va_auc\": va_auc,\n        }, BEST_PATH)","metadata":{"execution":{"iopub.status.busy":"2026-02-01T13:41:44.771394Z","iopub.execute_input":"2026-02-01T13:41:44.771631Z","iopub.status.idle":"2026-02-01T14:44:10.607135Z","shell.execute_reply.started":"2026-02-01T13:41:44.771610Z","shell.execute_reply":"2026-02-01T14:44:10.606335Z"},"trusted":true},"outputs":[{"name":"stdout","text":"[unet_basic] Epoch 001 | tr_loss=0.3207 tr_f1=0.0602 tr_acc=0.9134 tr_auc=0.6002 || va_loss=0.1948 va_f1=0.2505 va_acc=0.8377 va_auc=0.7708 | 197.8s\n[unet_basic] Epoch 002 | tr_loss=0.2179 tr_f1=0.0080 tr_acc=0.9411 tr_auc=0.6515 || va_loss=0.1669 va_f1=0.3492 va_acc=0.9391 va_auc=0.7602 | 186.0s\n[unet_basic] Epoch 003 | tr_loss=0.1983 tr_f1=0.0491 tr_acc=0.9408 tr_auc=0.7258 || va_loss=0.1551 va_f1=0.4511 va_acc=0.9540 va_auc=0.8488 | 186.9s\n[unet_basic] Epoch 004 | tr_loss=0.1857 tr_f1=0.1888 tr_acc=0.9427 tr_auc=0.7571 || va_loss=0.1571 va_f1=0.3539 va_acc=0.9271 va_auc=0.8188 | 184.4s\n[unet_basic] Epoch 005 | tr_loss=0.1853 tr_f1=0.1571 tr_acc=0.9411 tr_auc=0.7839 || va_loss=0.1575 va_f1=0.2928 va_acc=0.9213 va_auc=0.8348 | 186.7s\n[unet_basic] Epoch 006 | tr_loss=0.1918 tr_f1=0.0456 tr_acc=0.9412 tr_auc=0.7606 || va_loss=0.2571 va_f1=0.0251 va_acc=0.9475 va_auc=0.4748 | 187.0s\n[unet_basic] Epoch 007 | tr_loss=0.1788 tr_f1=0.1286 tr_acc=0.9422 tr_auc=0.7909 || va_loss=0.1592 va_f1=0.2404 va_acc=0.7605 va_auc=0.8552 | 188.7s\n[unet_basic] Epoch 008 | tr_loss=0.1771 tr_f1=0.2638 tr_acc=0.9439 tr_auc=0.7936 || va_loss=0.1552 va_f1=0.4039 va_acc=0.9431 va_auc=0.8682 | 185.4s\n[unet_basic] Epoch 009 | tr_loss=0.1749 tr_f1=0.2786 tr_acc=0.9456 tr_auc=0.8071 || va_loss=0.1620 va_f1=0.2758 va_acc=0.8474 va_auc=0.8304 | 183.3s\n[unet_basic] Epoch 010 | tr_loss=0.1743 tr_f1=0.2998 tr_acc=0.9451 tr_auc=0.8009 || va_loss=0.1683 va_f1=0.1093 va_acc=0.9510 va_auc=0.8092 | 186.5s\n[unet_basic] Epoch 011 | tr_loss=0.1707 tr_f1=0.3163 tr_acc=0.9458 tr_auc=0.8236 || va_loss=0.1615 va_f1=0.1925 va_acc=0.9546 va_auc=0.8630 | 184.8s\n[unet_basic] Epoch 012 | tr_loss=0.1710 tr_f1=0.2441 tr_acc=0.9420 tr_auc=0.8358 || va_loss=0.1640 va_f1=0.2929 va_acc=0.9334 va_auc=0.8092 | 188.5s\n[unet_basic] Epoch 013 | tr_loss=0.1652 tr_f1=0.3144 tr_acc=0.9456 tr_auc=0.8333 || va_loss=0.1467 va_f1=0.3996 va_acc=0.9293 va_auc=0.8674 | 187.4s\n[unet_basic] Epoch 014 | tr_loss=0.1581 tr_f1=0.4038 tr_acc=0.9490 tr_auc=0.8497 || va_loss=0.1389 va_f1=0.4438 va_acc=0.9438 va_auc=0.8874 | 187.6s\n[unet_basic] Epoch 015 | tr_loss=0.1592 tr_f1=0.3744 tr_acc=0.9481 tr_auc=0.8524 || va_loss=0.1625 va_f1=0.2455 va_acc=0.9534 va_auc=0.8267 | 190.5s\n[unet_basic] Epoch 016 | tr_loss=0.1476 tr_f1=0.4553 tr_acc=0.9497 tr_auc=0.8793 || va_loss=0.1573 va_f1=0.2472 va_acc=0.9513 va_auc=0.8538 | 189.0s\n[unet_basic] Epoch 017 | tr_loss=0.1432 tr_f1=0.4665 tr_acc=0.9505 tr_auc=0.8874 || va_loss=0.1477 va_f1=0.4264 va_acc=0.9581 va_auc=0.8632 | 188.1s\n[unet_basic] Epoch 018 | tr_loss=0.1387 tr_f1=0.4857 tr_acc=0.9528 tr_auc=0.8950 || va_loss=0.1592 va_f1=0.3077 va_acc=0.9543 va_auc=0.8622 | 185.4s\n[unet_basic] Epoch 019 | tr_loss=0.1220 tr_f1=0.5698 tr_acc=0.9565 tr_auc=0.9258 || va_loss=0.1363 va_f1=0.4740 va_acc=0.9599 va_auc=0.8966 | 187.3s\n[unet_basic] Epoch 020 | tr_loss=0.1127 tr_f1=0.6243 tr_acc=0.9610 tr_auc=0.9358 || va_loss=0.1502 va_f1=0.3838 va_acc=0.9601 va_auc=0.9082 | 184.2s\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"df_history = pd.DataFrame(history)\n\ndf_history = df_history.round(4)\ncsv_path = \"/kaggle/working/training_metrics2.csv\"\ndf_history.to_csv(csv_path, index=False)\nprint(\"Saved to:\", csv_path)\ndf_history","metadata":{"execution":{"iopub.status.busy":"2026-02-01T14:44:10.608576Z","iopub.execute_input":"2026-02-01T14:44:10.608862Z","iopub.status.idle":"2026-02-01T14:44:10.667314Z","shell.execute_reply.started":"2026-02-01T14:44:10.608834Z","shell.execute_reply":"2026-02-01T14:44:10.666690Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Saved to: /kaggle/working/training_metrics2.csv\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"    epoch  tr_loss  tr_precision  tr_recall   tr_f1  tr_acc  tr_auc  va_loss  \\\n0       1   0.3207        0.0835     0.0471  0.0602  0.9134  0.6002   0.1948   \n1       2   0.2179        0.4984     0.0040  0.0080  0.9411  0.6515   0.1669   \n2       3   0.1983        0.4556     0.0260  0.0491  0.9408  0.7258   0.1551   \n3       4   0.1857        0.5673     0.1133  0.1888  0.9427  0.7571   0.1571   \n4       5   0.1853        0.4994     0.0932  0.1571  0.9411  0.7839   0.1575   \n5       6   0.1918        0.5243     0.0238  0.0456  0.9412  0.7606   0.2571   \n6       7   0.1788        0.5697     0.0725  0.1286  0.9422  0.7909   0.1592   \n7       8   0.1771        0.5818     0.1705  0.2638  0.9439  0.7936   0.1552   \n8       9   0.1749        0.6379     0.1783  0.2786  0.9456  0.8071   0.1620   \n9      10   0.1743        0.6010     0.1998  0.2998  0.9451  0.8009   0.1683   \n10     11   0.1707        0.6157     0.2128  0.3163  0.9458  0.8236   0.1615   \n11     12   0.1710        0.5248     0.1590  0.2441  0.9420  0.8358   0.1640   \n12     13   0.1652        0.6111     0.2117  0.3144  0.9456  0.8333   0.1467   \n13     14   0.1581        0.6484     0.2932  0.4038  0.9490  0.8497   0.1389   \n14     15   0.1592        0.6446     0.2638  0.3744  0.9481  0.8524   0.1625   \n15     16   0.1476        0.6284     0.3570  0.4553  0.9497  0.8793   0.1573   \n16     17   0.1432        0.6379     0.3677  0.4665  0.9505  0.8874   0.1477   \n17     18   0.1387        0.6779     0.3784  0.4857  0.9528  0.8950   0.1592   \n18     19   0.1220        0.6831     0.4887  0.5698  0.9565  0.9258   0.1363   \n19     20   0.1127        0.7218     0.5501  0.6243  0.9610  0.9358   0.1502   \n\n    va_precision  va_recall   va_f1  va_acc  va_auc   seconds  \n0         0.1608     0.5670  0.2505  0.8377  0.7708  197.8450  \n1         0.3570     0.3418  0.3492  0.9391  0.7602  186.0204  \n2         0.5255     0.3952  0.4511  0.9540  0.8488  186.8807  \n3         0.3070     0.4176  0.3539  0.9271  0.8188  184.3976  \n4         0.2567     0.3408  0.2928  0.9213  0.8348  186.6694  \n5         0.1122     0.0141  0.0251  0.9475  0.4748  186.9774  \n6         0.1417     0.7924  0.2404  0.7605  0.8552  188.7460  \n7         0.4051     0.4027  0.4039  0.9431  0.8682  185.3527  \n8         0.1784     0.6078  0.2758  0.8474  0.8304  183.2521  \n9         0.4210     0.0628  0.1093  0.9510  0.8092  186.4610  \n10        0.6468     0.1131  0.1925  0.9546  0.8630  184.8171  \n11        0.2977     0.2882  0.2929  0.9334  0.8092  188.5375  \n12        0.3365     0.4917  0.3996  0.9293  0.8674  187.3870  \n13        0.4212     0.4690  0.4438  0.9438  0.8874  187.5960  \n14        0.5432     0.1586  0.2455  0.9534  0.8267  190.4583  \n15        0.4744     0.1671  0.2472  0.9513  0.8538  189.0115  \n16        0.6164     0.3259  0.4264  0.9581  0.8632  188.1190  \n17        0.5597     0.2122  0.3077  0.9543  0.8622  185.4002  \n18        0.6369     0.3774  0.4740  0.9599  0.8966  187.2975  \n19        0.7319     0.2601  0.3838  0.9601  0.9082  184.1543  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>epoch</th>\n      <th>tr_loss</th>\n      <th>tr_precision</th>\n      <th>tr_recall</th>\n      <th>tr_f1</th>\n      <th>tr_acc</th>\n      <th>tr_auc</th>\n      <th>va_loss</th>\n      <th>va_precision</th>\n      <th>va_recall</th>\n      <th>va_f1</th>\n      <th>va_acc</th>\n      <th>va_auc</th>\n      <th>seconds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.3207</td>\n      <td>0.0835</td>\n      <td>0.0471</td>\n      <td>0.0602</td>\n      <td>0.9134</td>\n      <td>0.6002</td>\n      <td>0.1948</td>\n      <td>0.1608</td>\n      <td>0.5670</td>\n      <td>0.2505</td>\n      <td>0.8377</td>\n      <td>0.7708</td>\n      <td>197.8450</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.2179</td>\n      <td>0.4984</td>\n      <td>0.0040</td>\n      <td>0.0080</td>\n      <td>0.9411</td>\n      <td>0.6515</td>\n      <td>0.1669</td>\n      <td>0.3570</td>\n      <td>0.3418</td>\n      <td>0.3492</td>\n      <td>0.9391</td>\n      <td>0.7602</td>\n      <td>186.0204</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.1983</td>\n      <td>0.4556</td>\n      <td>0.0260</td>\n      <td>0.0491</td>\n      <td>0.9408</td>\n      <td>0.7258</td>\n      <td>0.1551</td>\n      <td>0.5255</td>\n      <td>0.3952</td>\n      <td>0.4511</td>\n      <td>0.9540</td>\n      <td>0.8488</td>\n      <td>186.8807</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.1857</td>\n      <td>0.5673</td>\n      <td>0.1133</td>\n      <td>0.1888</td>\n      <td>0.9427</td>\n      <td>0.7571</td>\n      <td>0.1571</td>\n      <td>0.3070</td>\n      <td>0.4176</td>\n      <td>0.3539</td>\n      <td>0.9271</td>\n      <td>0.8188</td>\n      <td>184.3976</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.1853</td>\n      <td>0.4994</td>\n      <td>0.0932</td>\n      <td>0.1571</td>\n      <td>0.9411</td>\n      <td>0.7839</td>\n      <td>0.1575</td>\n      <td>0.2567</td>\n      <td>0.3408</td>\n      <td>0.2928</td>\n      <td>0.9213</td>\n      <td>0.8348</td>\n      <td>186.6694</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>0.1918</td>\n      <td>0.5243</td>\n      <td>0.0238</td>\n      <td>0.0456</td>\n      <td>0.9412</td>\n      <td>0.7606</td>\n      <td>0.2571</td>\n      <td>0.1122</td>\n      <td>0.0141</td>\n      <td>0.0251</td>\n      <td>0.9475</td>\n      <td>0.4748</td>\n      <td>186.9774</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>0.1788</td>\n      <td>0.5697</td>\n      <td>0.0725</td>\n      <td>0.1286</td>\n      <td>0.9422</td>\n      <td>0.7909</td>\n      <td>0.1592</td>\n      <td>0.1417</td>\n      <td>0.7924</td>\n      <td>0.2404</td>\n      <td>0.7605</td>\n      <td>0.8552</td>\n      <td>188.7460</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>0.1771</td>\n      <td>0.5818</td>\n      <td>0.1705</td>\n      <td>0.2638</td>\n      <td>0.9439</td>\n      <td>0.7936</td>\n      <td>0.1552</td>\n      <td>0.4051</td>\n      <td>0.4027</td>\n      <td>0.4039</td>\n      <td>0.9431</td>\n      <td>0.8682</td>\n      <td>185.3527</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>0.1749</td>\n      <td>0.6379</td>\n      <td>0.1783</td>\n      <td>0.2786</td>\n      <td>0.9456</td>\n      <td>0.8071</td>\n      <td>0.1620</td>\n      <td>0.1784</td>\n      <td>0.6078</td>\n      <td>0.2758</td>\n      <td>0.8474</td>\n      <td>0.8304</td>\n      <td>183.2521</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>0.1743</td>\n      <td>0.6010</td>\n      <td>0.1998</td>\n      <td>0.2998</td>\n      <td>0.9451</td>\n      <td>0.8009</td>\n      <td>0.1683</td>\n      <td>0.4210</td>\n      <td>0.0628</td>\n      <td>0.1093</td>\n      <td>0.9510</td>\n      <td>0.8092</td>\n      <td>186.4610</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>0.1707</td>\n      <td>0.6157</td>\n      <td>0.2128</td>\n      <td>0.3163</td>\n      <td>0.9458</td>\n      <td>0.8236</td>\n      <td>0.1615</td>\n      <td>0.6468</td>\n      <td>0.1131</td>\n      <td>0.1925</td>\n      <td>0.9546</td>\n      <td>0.8630</td>\n      <td>184.8171</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>0.1710</td>\n      <td>0.5248</td>\n      <td>0.1590</td>\n      <td>0.2441</td>\n      <td>0.9420</td>\n      <td>0.8358</td>\n      <td>0.1640</td>\n      <td>0.2977</td>\n      <td>0.2882</td>\n      <td>0.2929</td>\n      <td>0.9334</td>\n      <td>0.8092</td>\n      <td>188.5375</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>0.1652</td>\n      <td>0.6111</td>\n      <td>0.2117</td>\n      <td>0.3144</td>\n      <td>0.9456</td>\n      <td>0.8333</td>\n      <td>0.1467</td>\n      <td>0.3365</td>\n      <td>0.4917</td>\n      <td>0.3996</td>\n      <td>0.9293</td>\n      <td>0.8674</td>\n      <td>187.3870</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>0.1581</td>\n      <td>0.6484</td>\n      <td>0.2932</td>\n      <td>0.4038</td>\n      <td>0.9490</td>\n      <td>0.8497</td>\n      <td>0.1389</td>\n      <td>0.4212</td>\n      <td>0.4690</td>\n      <td>0.4438</td>\n      <td>0.9438</td>\n      <td>0.8874</td>\n      <td>187.5960</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>0.1592</td>\n      <td>0.6446</td>\n      <td>0.2638</td>\n      <td>0.3744</td>\n      <td>0.9481</td>\n      <td>0.8524</td>\n      <td>0.1625</td>\n      <td>0.5432</td>\n      <td>0.1586</td>\n      <td>0.2455</td>\n      <td>0.9534</td>\n      <td>0.8267</td>\n      <td>190.4583</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>16</td>\n      <td>0.1476</td>\n      <td>0.6284</td>\n      <td>0.3570</td>\n      <td>0.4553</td>\n      <td>0.9497</td>\n      <td>0.8793</td>\n      <td>0.1573</td>\n      <td>0.4744</td>\n      <td>0.1671</td>\n      <td>0.2472</td>\n      <td>0.9513</td>\n      <td>0.8538</td>\n      <td>189.0115</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>0.1432</td>\n      <td>0.6379</td>\n      <td>0.3677</td>\n      <td>0.4665</td>\n      <td>0.9505</td>\n      <td>0.8874</td>\n      <td>0.1477</td>\n      <td>0.6164</td>\n      <td>0.3259</td>\n      <td>0.4264</td>\n      <td>0.9581</td>\n      <td>0.8632</td>\n      <td>188.1190</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>18</td>\n      <td>0.1387</td>\n      <td>0.6779</td>\n      <td>0.3784</td>\n      <td>0.4857</td>\n      <td>0.9528</td>\n      <td>0.8950</td>\n      <td>0.1592</td>\n      <td>0.5597</td>\n      <td>0.2122</td>\n      <td>0.3077</td>\n      <td>0.9543</td>\n      <td>0.8622</td>\n      <td>185.4002</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>19</td>\n      <td>0.1220</td>\n      <td>0.6831</td>\n      <td>0.4887</td>\n      <td>0.5698</td>\n      <td>0.9565</td>\n      <td>0.9258</td>\n      <td>0.1363</td>\n      <td>0.6369</td>\n      <td>0.3774</td>\n      <td>0.4740</td>\n      <td>0.9599</td>\n      <td>0.8966</td>\n      <td>187.2975</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>20</td>\n      <td>0.1127</td>\n      <td>0.7218</td>\n      <td>0.5501</td>\n      <td>0.6243</td>\n      <td>0.9610</td>\n      <td>0.9358</td>\n      <td>0.1502</td>\n      <td>0.7319</td>\n      <td>0.2601</td>\n      <td>0.3838</td>\n      <td>0.9601</td>\n      <td>0.9082</td>\n      <td>184.1543</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"# YANG INI JANGAN DIRERUN, COPY CODE NYA AJ DIBAWAH\ntest_loss, test_prec, test_rec, test_f1, test_acc, test_auc = validate_epoch(\n    model, test_loader, thr=0.13\n)\n\nprint(f\"Test Loss   : {test_loss:.4f}\")\nprint(f\"Test Prec   : {test_prec:.4f}\")\nprint(f\"Test Recall : {test_rec:.4f}\")\nprint(f\"Test F1     : {test_f1:.4f}\")\nprint(f\"Test Acc    : {test_acc:.4f}\")\nprint(f\"Test AUC    : {test_auc:.4f}\")","metadata":{"execution":{"iopub.execute_input":"2026-01-03T12:58:09.057351Z","iopub.status.busy":"2026-01-03T12:58:09.056513Z","iopub.status.idle":"2026-01-03T12:58:40.253348Z","shell.execute_reply":"2026-01-03T12:58:40.252464Z","shell.execute_reply.started":"2026-01-03T12:58:09.057318Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Loss   : 0.0741\n","Test Prec   : 0.7120\n","Test Recall : 0.6341\n","Test F1     : 0.6708\n","Test Acc    : 0.9849\n","Test AUC    : 0.9381\n"]}],"execution_count":null},{"cell_type":"code","source":"test_loss, test_prec, test_rec, test_f1, test_acc, test_auc = validate_epoch(\n    model, test_loader, thr=0.13\n)\n\nprint(f\"Test Loss   : {test_loss:.4f}\")\nprint(f\"Test Prec   : {test_prec:.4f}\")\nprint(f\"Test Recall : {test_rec:.4f}\")\nprint(f\"Test F1     : {test_f1:.4f}\")\nprint(f\"Test Acc    : {test_acc:.4f}\")\nprint(f\"Test AUC    : {test_auc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-01T14:44:10.668240Z","iopub.execute_input":"2026-02-01T14:44:10.668602Z","iopub.status.idle":"2026-02-01T14:44:42.737355Z","shell.execute_reply.started":"2026-02-01T14:44:10.668579Z","shell.execute_reply":"2026-02-01T14:44:42.736609Z"}},"outputs":[{"name":"stdout","text":"Test Loss   : 0.0831\nTest Prec   : 0.6190\nTest Recall : 0.3597\nTest F1     : 0.4550\nTest Acc    : 0.9791\nTest AUC    : 0.8907\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"test_loss, test_prec, test_rec, test_f1, test_acc, test_auc = validate_epoch(\n    model, test_loader, thr=0.5\n)\n\nprint(f\"Test Loss   : {test_loss:.4f}\")\nprint(f\"Test Prec   : {test_prec:.4f}\")\nprint(f\"Test Recall : {test_rec:.4f}\")\nprint(f\"Test F1     : {test_f1:.4f}\")\nprint(f\"Test Acc    : {test_acc:.4f}\")\nprint(f\"Test AUC    : {test_auc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-01T14:44:42.739572Z","iopub.execute_input":"2026-02-01T14:44:42.739853Z","iopub.status.idle":"2026-02-01T14:45:13.144355Z","shell.execute_reply.started":"2026-02-01T14:44:42.739825Z","shell.execute_reply":"2026-02-01T14:45:13.143521Z"}},"outputs":[{"name":"stdout","text":"Test Loss   : 0.0831\nTest Prec   : 1.0000\nTest Recall : 0.0000\nTest F1     : 0.0000\nTest Acc    : 0.9757\nTest AUC    : 0.8907\n","output_type":"stream"}],"execution_count":23}]}