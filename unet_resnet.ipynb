{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T07:48:16.325209Z",
     "iopub.status.busy": "2026-02-03T07:48:16.324955Z",
     "iopub.status.idle": "2026-02-03T07:48:21.121588Z",
     "shell.execute_reply": "2026-02-03T07:48:21.120808Z",
     "shell.execute_reply.started": "2026-02-03T07:48:16.325176Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "DATA_ROOT OK: /kaggle/input/sen2fire/Sen2Fire/Sen2Fire\n"
     ]
    }
   ],
   "source": [
    "import os, glob, random, json\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ----------------------------\n",
    "# Reproducibility\n",
    "# ----------------------------\n",
    "def seed_everything(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "SEED = 24\n",
    "seed_everything(SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "@dataclass\n",
    "class CFG:\n",
    "    DATA_ROOT: str = \"/kaggle/input/sen2fire/Sen2Fire/Sen2Fire\"\n",
    "    SCENES: Tuple[str, ...] = (\"scene1\", \"scene2\", \"scene3\", \"scene4\")\n",
    "    PATCH_EXT: str = \".npz\"\n",
    "\n",
    "    # Global split (VD default)\n",
    "    USE_GLOBAL_SPLIT: bool = True\n",
    "    GLOBAL_TRAIN_RATIO: float = 0.80\n",
    "    GLOBAL_VAL_RATIO: float = 0.10\n",
    "    GLOBAL_TEST_RATIO: float = 0.10\n",
    "    KEEP_VAL_TEST_NATURAL: bool = True\n",
    "\n",
    "    # Keys inside npz\n",
    "    X_KEY: str = \"image\"     # (12,512,512)\n",
    "    A_KEY: str = \"aerosol\"   # (512,512) -> becomes 1 channel\n",
    "    Y_KEY: str = \"label\"     # (512,512)\n",
    "\n",
    "    # Fire patch definition\n",
    "    FIRE_PATCH_MIN_RATIO: float = 0\n",
    "\n",
    "    # Controlled train pool (VD default)\n",
    "    USE_CONTROLLED_POOL: bool = True\n",
    "    POOL_KEEP_FIRE: int = -1\n",
    "    NONFIRE_PER_FIRE: int = 3\n",
    "\n",
    "    # Training config (RAM-safe)\n",
    "    IN_CHANNELS: int = 13\n",
    "    H: int = 512\n",
    "    W: int = 512\n",
    "    BATCH_SIZE: int = 2\n",
    "    NUM_WORKERS: int = 2\n",
    "    LR: float = 1e-4\n",
    "    EPOCHS: int = 40 \n",
    "\n",
    "    VERBOSE: bool = True\n",
    "\n",
    "cfg = CFG()\n",
    "\n",
    "assert abs((cfg.GLOBAL_TRAIN_RATIO + cfg.GLOBAL_VAL_RATIO + cfg.GLOBAL_TEST_RATIO) - 1.0) < 1e-6\n",
    "assert os.path.exists(cfg.DATA_ROOT), f\"DATA_ROOT not found: {cfg.DATA_ROOT}\"\n",
    "print(\"DATA_ROOT OK:\", cfg.DATA_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T07:48:21.123528Z",
     "iopub.status.busy": "2026-02-03T07:48:21.123135Z",
     "iopub.status.idle": "2026-02-03T07:48:21.177145Z",
     "shell.execute_reply": "2026-02-03T07:48:21.176458Z",
     "shell.execute_reply.started": "2026-02-03T07:48:21.123502Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene1: 864 patches\n",
      "scene2: 594 patches\n",
      "scene3: 504 patches\n",
      "scene4: 504 patches\n",
      "Total patches: 2466\n"
     ]
    }
   ],
   "source": [
    "def list_scene_files(data_root: str, scene_name: str, ext: str = \".npz\") -> List[str]:\n",
    "    scene_dir = os.path.join(data_root, scene_name)\n",
    "    return sorted(glob.glob(os.path.join(scene_dir, f\"*{ext}\")))\n",
    "\n",
    "scene_to_files = {}\n",
    "total = 0\n",
    "for s in cfg.SCENES:\n",
    "    files = list_scene_files(cfg.DATA_ROOT, s, cfg.PATCH_EXT)\n",
    "    scene_to_files[s] = files\n",
    "    total += len(files)\n",
    "    print(f\"{s}: {len(files)} patches\")\n",
    "\n",
    "print(\"Total patches:\", total)\n",
    "if total == 0:\n",
    "    raise RuntimeError(\"No patch files found. Check DATA_ROOT / PATCH_EXT.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T07:48:21.178469Z",
     "iopub.status.busy": "2026-02-03T07:48:21.178210Z",
     "iopub.status.idle": "2026-02-03T07:48:21.305210Z",
     "shell.execute_reply": "2026-02-03T07:48:21.304506Z",
     "shell.execute_reply.started": "2026-02-03T07:48:21.178447Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample file: /kaggle/input/sen2fire/Sen2Fire/Sen2Fire/scene1/scene_1_patch_10_1.npz\n",
      "  -      image: shape=(12, 512, 512), dtype=int16\n",
      "  -    aerosol: shape=(512, 512), dtype=float32\n",
      "  -      label: shape=(512, 512), dtype=uint8\n"
     ]
    }
   ],
   "source": [
    "def inspect_npz(npz_path: str):\n",
    "    with np.load(npz_path) as data:\n",
    "        return {k: (data[k].shape, str(data[k].dtype)) for k in data.keys()}\n",
    "\n",
    "sample_path = scene_to_files[cfg.SCENES[0]][0]\n",
    "print(\"Sample file:\", sample_path)\n",
    "info = inspect_npz(sample_path)\n",
    "for k, (shape, dtype) in info.items():\n",
    "    print(f\"  - {k:>10s}: shape={shape}, dtype={dtype}\")\n",
    "\n",
    "for rk in [cfg.X_KEY, cfg.A_KEY, cfg.Y_KEY]:\n",
    "    if rk not in info:\n",
    "        raise KeyError(f\"Missing key '{rk}' in npz. Found keys: {list(info.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T07:48:21.306302Z",
     "iopub.status.busy": "2026-02-03T07:48:21.306006Z",
     "iopub.status.idle": "2026-02-03T07:48:44.842681Z",
     "shell.execute_reply": "2026-02-03T07:48:44.842039Z",
     "shell.execute_reply.started": "2026-02-03T07:48:21.306272Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FULL dataset has_fire distribution:\n",
      "has_fire\n",
      "0    2117\n",
      "1     349\n",
      "Name: count, dtype: int64\n",
      "\n",
      "FULL dataset has_fire ratio:\n",
      "has_fire\n",
      "0    0.858475\n",
      "1    0.141525\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for s, files in scene_to_files.items():\n",
    "    for p in files:\n",
    "        rows.append({\"scene\": s, \"path\": p})\n",
    "manifest = pd.DataFrame(rows)\n",
    "\n",
    "def fire_ratio_from_path(npz_path: str) -> float:\n",
    "    with np.load(npz_path) as data:\n",
    "        y = data[cfg.Y_KEY]\n",
    "        if y.ndim == 3 and y.shape[-1] == 1:\n",
    "            y = y[..., 0]\n",
    "        yb = (y > 0).astype(np.uint8)\n",
    "        return float(yb.mean())\n",
    "\n",
    "fire_ratios = []\n",
    "has_fire = []\n",
    "for p in manifest[\"path\"].tolist():\n",
    "    r = fire_ratio_from_path(p)\n",
    "    fire_ratios.append(r)\n",
    "    has_fire.append(1 if r > cfg.FIRE_PATCH_MIN_RATIO else 0)\n",
    "\n",
    "manifest[\"fire_ratio\"] = fire_ratios\n",
    "manifest[\"has_fire\"] = has_fire\n",
    "\n",
    "print(\"\\nFULL dataset has_fire distribution:\")\n",
    "print(manifest[\"has_fire\"].value_counts().sort_index())\n",
    "print(\"\\nFULL dataset has_fire ratio:\")\n",
    "print(manifest[\"has_fire\"].value_counts(normalize=True).sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T07:48:44.843854Z",
     "iopub.status.busy": "2026-02-03T07:48:44.843589Z",
     "iopub.status.idle": "2026-02-03T07:48:44.849578Z",
     "shell.execute_reply": "2026-02-03T07:48:44.848884Z",
     "shell.execute_reply.started": "2026-02-03T07:48:44.843830Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.shape: (512, 512)\n"
     ]
    }
   ],
   "source": [
    "with np.load(manifest[\"path\"][0]) as data:\n",
    "    y = data[cfg.Y_KEY]\n",
    "    print(\"y.shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T07:48:44.850546Z",
     "iopub.status.busy": "2026-02-03T07:48:44.850306Z",
     "iopub.status.idle": "2026-02-03T07:48:44.862047Z",
     "shell.execute_reply": "2026-02-03T07:48:44.861381Z",
     "shell.execute_reply.started": "2026-02-03T07:48:44.850526Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fire channel: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y = np.load(manifest[\"path\"][0])[cfg.Y_KEY]\n",
    "fire_channel = np.argmax(y.sum(axis=(0,1)))  # channel dengan paling banyak fire\n",
    "print(\"Fire channel:\", fire_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T07:48:44.864244Z",
     "iopub.status.busy": "2026-02-03T07:48:44.863977Z",
     "iopub.status.idle": "2026-02-03T07:48:44.889396Z",
     "shell.execute_reply": "2026-02-03T07:48:44.888629Z",
     "shell.execute_reply.started": "2026-02-03T07:48:44.864223Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GLOBAL split counts:\n",
      "  Train pool: 1973\n",
      "  Val      : 247\n",
      "  Test     : 246\n",
      "\n",
      "TRAIN controlled sampling:\n",
      "  fire_total_in_pool   : 279\n",
      "  nofire_total_in_pool : 1694\n",
      "  fire_kept            : 279\n",
      "  nofire_kept          : 837 (NONFIRE_PER_FIRE=3)\n",
      "  train_final          : 1116\n",
      "\n",
      "Final used split sizes:\n",
      "  train: 1116\n",
      "  val  : 247\n",
      "  test : 246\n"
     ]
    }
   ],
   "source": [
    "def stratified_split(df, train_ratio, val_ratio, seed=42):\n",
    "    df = df.sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
    "    parts = []\n",
    "    for cls in [0, 1]:\n",
    "        sub = df[df[\"has_fire\"] == cls].copy()\n",
    "        n = len(sub)\n",
    "        n_train = int(round(n * train_ratio))\n",
    "        n_val   = int(round(n * val_ratio))\n",
    "        sub_train = sub.iloc[:n_train]\n",
    "        sub_val   = sub.iloc[n_train:n_train+n_val]\n",
    "        sub_test  = sub.iloc[n_train+n_val:]\n",
    "        parts.append((sub_train, sub_val, sub_test))\n",
    "\n",
    "    train_df = pd.concat([parts[0][0], parts[1][0]]).sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
    "    val_df   = pd.concat([parts[0][1], parts[1][1]]).sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
    "    test_df  = pd.concat([parts[0][2], parts[1][2]]).sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "train_pool_df, val_df, test_df = stratified_split(\n",
    "    manifest,\n",
    "    train_ratio=cfg.GLOBAL_TRAIN_RATIO,\n",
    "    val_ratio=cfg.GLOBAL_VAL_RATIO,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "print(\"\\nGLOBAL split counts:\")\n",
    "print(\"  Train pool:\", len(train_pool_df))\n",
    "print(\"  Val      :\", len(val_df))\n",
    "print(\"  Test     :\", len(test_df))\n",
    "\n",
    "# Controlled pool applies to TRAIN only\n",
    "if cfg.USE_CONTROLLED_POOL:\n",
    "    fire_df   = train_pool_df[train_pool_df[\"has_fire\"] == 1].copy()\n",
    "    nofire_df = train_pool_df[train_pool_df[\"has_fire\"] == 0].copy()\n",
    "\n",
    "    n_fire_total = len(fire_df)\n",
    "    n_nofire_total = len(nofire_df)\n",
    "\n",
    "    n_fire_keep = n_fire_total if cfg.POOL_KEEP_FIRE in (-1, None) else min(cfg.POOL_KEEP_FIRE, n_fire_total)\n",
    "    fire_keep = fire_df.sample(n=n_fire_keep, random_state=SEED) if n_fire_keep > 0 else fire_df.iloc[:0]\n",
    "\n",
    "    n_nofire_keep = min(n_nofire_total, n_fire_keep * int(cfg.NONFIRE_PER_FIRE))\n",
    "    nofire_keep = nofire_df.sample(n=n_nofire_keep, random_state=SEED) if n_nofire_keep > 0 else nofire_df.iloc[:0]\n",
    "\n",
    "    train_df = pd.concat([fire_keep, nofire_keep]).sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "    print(\"\\nTRAIN controlled sampling:\")\n",
    "    print(f\"  fire_total_in_pool   : {n_fire_total}\")\n",
    "    print(f\"  nofire_total_in_pool : {n_nofire_total}\")\n",
    "    print(f\"  fire_kept            : {len(fire_keep)}\")\n",
    "    print(f\"  nofire_kept          : {len(nofire_keep)} (NONFIRE_PER_FIRE={cfg.NONFIRE_PER_FIRE})\")\n",
    "    print(f\"  train_final          : {len(train_df)}\")\n",
    "else:\n",
    "    train_df = train_pool_df.copy()\n",
    "\n",
    "train_paths = train_df[\"path\"].tolist()\n",
    "val_paths   = val_df[\"path\"].tolist()\n",
    "test_paths  = test_df[\"path\"].tolist()\n",
    "\n",
    "# leakage check\n",
    "assert len(set(train_paths)&set(val_paths))==0\n",
    "assert len(set(train_paths)&set(test_paths))==0\n",
    "assert len(set(val_paths)&set(test_paths))==0\n",
    "\n",
    "print(\"\\nFinal used split sizes:\")\n",
    "print(\"  train:\", len(train_paths))\n",
    "print(\"  val  :\", len(val_paths))\n",
    "print(\"  test :\", len(test_paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T07:48:44.891000Z",
     "iopub.status.busy": "2026-02-03T07:48:44.890263Z",
     "iopub.status.idle": "2026-02-03T07:48:44.897089Z",
     "shell.execute_reply": "2026-02-03T07:48:44.896274Z",
     "shell.execute_reply.started": "2026-02-03T07:48:44.890972Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      /kaggle/input/sen2fire/Sen2Fire/Sen2Fire/scene...\n",
       "1      /kaggle/input/sen2fire/Sen2Fire/Sen2Fire/scene...\n",
       "2      /kaggle/input/sen2fire/Sen2Fire/Sen2Fire/scene...\n",
       "3      /kaggle/input/sen2fire/Sen2Fire/Sen2Fire/scene...\n",
       "4      /kaggle/input/sen2fire/Sen2Fire/Sen2Fire/scene...\n",
       "                             ...                        \n",
       "241    /kaggle/input/sen2fire/Sen2Fire/Sen2Fire/scene...\n",
       "242    /kaggle/input/sen2fire/Sen2Fire/Sen2Fire/scene...\n",
       "243    /kaggle/input/sen2fire/Sen2Fire/Sen2Fire/scene...\n",
       "244    /kaggle/input/sen2fire/Sen2Fire/Sen2Fire/scene...\n",
       "245    /kaggle/input/sen2fire/Sen2Fire/Sen2Fire/scene...\n",
       "Name: path, Length: 246, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T07:48:44.898326Z",
     "iopub.status.busy": "2026-02-03T07:48:44.898109Z",
     "iopub.status.idle": "2026-02-03T07:48:44.907838Z",
     "shell.execute_reply": "2026-02-03T07:48:44.907273Z",
     "shell.execute_reply.started": "2026-02-03T07:48:44.898306Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Sen2FireDataset(Dataset):\n",
    "    def __init__(self, paths: List[str], with_label: bool = True):\n",
    "        self.paths = paths\n",
    "        self.with_label = with_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.paths[idx]\n",
    "        with np.load(p) as d:\n",
    "            img12 = d[cfg.X_KEY].astype(np.float32)      # (12,512,512)\n",
    "            aer   = d[cfg.A_KEY].astype(np.float32)[None, ...]  # (1,512,512)\n",
    "            x = np.concatenate([img12, aer], axis=0)     # (13,512,512)\n",
    "\n",
    "            if self.with_label:\n",
    "                y = d[cfg.Y_KEY]\n",
    "                if y.ndim == 2:\n",
    "                    y = y[None, ...]\n",
    "                y = (y > 0).astype(np.float32)\n",
    "                return torch.from_numpy(x), torch.from_numpy(y)\n",
    "            else:\n",
    "                return torch.from_numpy(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T07:48:44.908682Z",
     "iopub.status.busy": "2026-02-03T07:48:44.908485Z",
     "iopub.status.idle": "2026-02-03T07:48:44.918863Z",
     "shell.execute_reply": "2026-02-03T07:48:44.918248Z",
     "shell.execute_reply.started": "2026-02-03T07:48:44.908664Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(Sen2FireDataset(train_paths, with_label=True),\n",
    "                          batch_size=cfg.BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=cfg.NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "val_loader = DataLoader(Sen2FireDataset(val_paths, with_label=True),\n",
    "                        batch_size=cfg.BATCH_SIZE, shuffle=False,\n",
    "                        num_workers=cfg.NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "test_loader = DataLoader(Sen2FireDataset(test_paths, with_label=True),\n",
    "                         batch_size=cfg.BATCH_SIZE, shuffle=False,\n",
    "                         num_workers=cfg.NUM_WORKERS, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T07:48:44.919945Z",
     "iopub.status.busy": "2026-02-03T07:48:44.919659Z",
     "iopub.status.idle": "2026-02-03T07:48:48.867953Z",
     "shell.execute_reply": "2026-02-03T07:48:48.867175Z",
     "shell.execute_reply.started": "2026-02-03T07:48:44.919912Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN_13 len: 13 STD_13 len: 13\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def compute_mean_std(loader, max_batches=50):\n",
    "    mean = torch.zeros(cfg.IN_CHANNELS, device=DEVICE)\n",
    "    var  = torch.zeros(cfg.IN_CHANNELS, device=DEVICE)\n",
    "    n_batches = 0\n",
    "\n",
    "    for bi, (x, y) in enumerate(loader):\n",
    "        if bi >= max_batches:\n",
    "            break\n",
    "        x = x.to(DEVICE)  # (B,C,H,W)\n",
    "        x_ = x.view(x.size(0), cfg.IN_CHANNELS, -1)\n",
    "        mean += x_.mean(dim=(0,2))\n",
    "        var  += x_.var(dim=(0,2), unbiased=False)\n",
    "        n_batches += 1\n",
    "\n",
    "    mean /= max(n_batches, 1)\n",
    "    var  /= max(n_batches, 1)\n",
    "    std = torch.sqrt(var + 1e-6)\n",
    "    return mean.detach().cpu().tolist(), std.detach().cpu().tolist()\n",
    "\n",
    "MEAN_13, STD_13 = compute_mean_std(train_loader, max_batches=50)\n",
    "print(\"MEAN_13 len:\", len(MEAN_13), \"STD_13 len:\", len(STD_13))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL PREPARATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T07:48:48.869304Z",
     "iopub.status.busy": "2026-02-03T07:48:48.869070Z",
     "iopub.status.idle": "2026-02-03T07:48:53.133301Z",
     "shell.execute_reply": "2026-02-03T07:48:53.132405Z",
     "shell.execute_reply.started": "2026-02-03T07:48:48.869277Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip -q install segmentation-models-pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T07:48:53.135115Z",
     "iopub.status.busy": "2026-02-03T07:48:53.134775Z",
     "iopub.status.idle": "2026-02-03T07:48:53.139757Z",
     "shell.execute_reply": "2026-02-03T07:48:53.139154Z",
     "shell.execute_reply.started": "2026-02-03T07:48:53.135076Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def normalize_batch(x, mean_13, std_13):\n",
    "    mean_t = torch.tensor(mean_13, device=x.device).view(1, cfg.IN_CHANNELS, 1, 1)\n",
    "    std_t  = torch.tensor(std_13,  device=x.device).view(1, cfg.IN_CHANNELS, 1, 1)\n",
    "    return (x - mean_t) / (std_t + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T07:48:53.140971Z",
     "iopub.status.busy": "2026-02-03T07:48:53.140754Z",
     "iopub.status.idle": "2026-02-03T07:49:02.627602Z",
     "shell.execute_reply": "2026-02-03T07:49:02.626886Z",
     "shell.execute_reply.started": "2026-02-03T07:48:53.140951Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc56a054c33431cb7993a08a234c1d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6c19ed726a4b4da8fc403b4909361c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/46.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Unet\n"
     ]
    }
   ],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "def build_unet(in_channels=13):\n",
    "    model = smp.Unet(\n",
    "        encoder_name=\"resnet18\",\n",
    "        encoder_weights=\"imagenet\",\n",
    "        in_channels=in_channels,\n",
    "        classes=1,\n",
    "        activation=None\n",
    "    )\n",
    "    return model\n",
    "    \n",
    "model = build_unet(cfg.IN_CHANNELS).to(DEVICE)\n",
    "print(\"Model:\", type(model).__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T07:49:41.167393Z",
     "iopub.status.busy": "2026-02-03T07:49:41.167074Z",
     "iopub.status.idle": "2026-02-03T07:49:41.781737Z",
     "shell.execute_reply": "2026-02-03T07:49:41.781069Z",
     "shell.execute_reply.started": "2026-02-03T07:49:41.167362Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/735404605.py:6: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=(DEVICE.type == \"cuda\"))\n"
     ]
    }
   ],
   "source": [
    "from torch.amp import autocast, GradScaler\n",
    "from sklearn.metrics import average_precision_score\n",
    "import time\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cfg.LR)\n",
    "scaler = GradScaler(enabled=(DEVICE.type == \"cuda\"))\n",
    "\n",
    "def train_one_epoch(model, loader, thr=0.5, eps=1e-6):\n",
    "    model.train()\n",
    "    total_loss_sum = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    total_tp = total_fp = total_fn = total_tn = 0.0\n",
    "    all_probs, all_targets = [], []\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        x = normalize_batch(x, MEAN_13, STD_13)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with autocast(\"cuda\", enabled=(DEVICE.type == \"cuda\")):\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        bs = x.size(0)\n",
    "        total_loss_sum += loss.item() * bs\n",
    "        total_samples += bs\n",
    "\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= thr).float()\n",
    "\n",
    "        total_tp += (preds * y).sum().item()\n",
    "        total_fp += (preds * (1 - y)).sum().item()\n",
    "        total_fn += ((1 - preds) * y).sum().item()\n",
    "        total_tn += ((1 - preds) * (1 - y)).sum().item()\n",
    "\n",
    "        all_probs.append(probs.flatten().detach().cpu())\n",
    "        all_targets.append(y.flatten().detach().cpu())\n",
    "\n",
    "    precision = (total_tp + eps) / (total_tp + total_fp + eps)\n",
    "    recall    = (total_tp + eps) / (total_tp + total_fn + eps)\n",
    "    f1        = (2 * precision * recall) / (precision + recall + eps)\n",
    "    acc       = (total_tp + total_tn + eps) / (\n",
    "        total_tp + total_tn + total_fp + total_fn + eps\n",
    "    )\n",
    "\n",
    "    all_probs = torch.cat(all_probs).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "    auc = average_precision_score(all_targets, all_probs)\n",
    "\n",
    "    loss_global = total_loss_sum / total_samples\n",
    "\n",
    "    return loss_global, precision, recall, f1, acc, auc\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_epoch(model, loader, thr=0.5, eps=1e-6):\n",
    "    model.eval()\n",
    "    total_loss_sum = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    total_tp = total_fp = total_fn = total_tn = 0.0\n",
    "    all_probs, all_targets = [], []\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        x = normalize_batch(x, MEAN_13, STD_13)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        bs = x.size(0)\n",
    "        total_loss_sum += loss.item() * bs\n",
    "        total_samples += bs\n",
    "\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= thr).float()\n",
    "\n",
    "        total_tp += (preds * y).sum().item()\n",
    "        total_fp += (preds * (1 - y)).sum().item()\n",
    "        total_fn += ((1 - preds) * y).sum().item()\n",
    "        total_tn += ((1 - preds) * (1 - y)).sum().item()\n",
    "\n",
    "        all_probs.append(probs.flatten().cpu())\n",
    "        all_targets.append(y.flatten().cpu())\n",
    "\n",
    "    precision = (total_tp + eps) / (total_tp + total_fp + eps)\n",
    "    recall    = (total_tp + eps) / (total_tp + total_fn + eps)\n",
    "    f1        = (2 * precision * recall) / (precision + recall + eps)\n",
    "    acc       = (total_tp + total_tn + eps) / (\n",
    "        total_tp + total_tn + total_fp + total_fn + eps\n",
    "    )\n",
    "\n",
    "    all_probs = torch.cat(all_probs).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "    auc = average_precision_score(all_targets, all_probs)\n",
    "\n",
    "    loss_global = total_loss_sum / total_samples\n",
    "\n",
    "    return loss_global, precision, recall, f1, acc, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T17:53:08.918692Z",
     "iopub.status.busy": "2026-01-01T17:53:08.918321Z",
     "iopub.status.idle": "2026-01-01T18:57:24.681270Z",
     "shell.execute_reply": "2026-01-01T18:57:24.680419Z",
     "shell.execute_reply.started": "2026-01-01T17:53:08.918656Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[unet_basic] Epoch 001 | tr_loss=0.2158 tr_f1=0.0234 tr_acc=0.9411 tr_auc=0.7017 || va_loss=0.1627 va_f1=0.0007 va_acc=0.9522 va_auc=0.8390 | 198.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[unet_basic] Epoch 002 | tr_loss=0.2008 tr_f1=0.0241 tr_acc=0.9411 tr_auc=0.6884 || va_loss=0.1650 va_f1=0.0468 va_acc=0.9530 va_auc=0.7855 | 195.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[unet_basic] Epoch 003 | tr_loss=0.1884 tr_f1=0.0207 tr_acc=0.9410 tr_auc=0.7671 || va_loss=0.1480 va_f1=0.1404 va_acc=0.9546 va_auc=0.8509 | 192.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[unet_basic] Epoch 004 | tr_loss=0.1851 tr_f1=0.1225 tr_acc=0.9419 tr_auc=0.7681 || va_loss=0.1444 va_f1=0.1438 va_acc=0.9547 va_auc=0.8699 | 187.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[unet_basic] Epoch 005 | tr_loss=0.1787 tr_f1=0.2314 tr_acc=0.9437 tr_auc=0.7872 || va_loss=0.1605 va_f1=0.0214 va_acc=0.9525 va_auc=0.8287 | 187.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[unet_basic] Epoch 006 | tr_loss=0.1752 tr_f1=0.2767 tr_acc=0.9436 tr_auc=0.8052 || va_loss=0.1584 va_f1=0.0000 va_acc=0.9522 va_auc=0.8290 | 195.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[unet_basic] Epoch 007 | tr_loss=0.1756 tr_f1=0.2651 tr_acc=0.9430 tr_auc=0.7977 || va_loss=0.1667 va_f1=0.0000 va_acc=0.9522 va_auc=0.7991 | 194.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[unet_basic] Epoch 008 | tr_loss=0.1735 tr_f1=0.2695 tr_acc=0.9437 tr_auc=0.8178 || va_loss=0.1469 va_f1=0.1335 va_acc=0.9543 va_auc=0.8729 | 194.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[unet_basic] Epoch 009 | tr_loss=0.1707 tr_f1=0.2865 tr_acc=0.9449 tr_auc=0.8161 || va_loss=0.1573 va_f1=0.0000 va_acc=0.9522 va_auc=0.8554 | 189.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[unet_basic] Epoch 010 | tr_loss=0.1685 tr_f1=0.3602 tr_acc=0.9463 tr_auc=0.8220 || va_loss=0.1472 va_f1=0.1832 va_acc=0.9549 va_auc=0.8600 | 189.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[unet_basic] Epoch 011 | tr_loss=0.1649 tr_f1=0.3347 tr_acc=0.9458 tr_auc=0.8312 || va_loss=0.1505 va_f1=0.0550 va_acc=0.9531 va_auc=0.8533 | 191.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[unet_basic] Epoch 012 | tr_loss=0.1681 tr_f1=0.3607 tr_acc=0.9470 tr_auc=0.8157 || va_loss=0.1489 va_f1=0.0000 va_acc=0.9522 va_auc=0.8641 | 191.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[unet_basic] Epoch 013 | tr_loss=0.1652 tr_f1=0.3453 tr_acc=0.9458 tr_auc=0.8426 || va_loss=0.1415 va_f1=0.1635 va_acc=0.9545 va_auc=0.8671 | 195.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[unet_basic] Epoch 014 | tr_loss=0.1628 tr_f1=0.3625 tr_acc=0.9462 tr_auc=0.8417 || va_loss=0.1614 va_f1=0.0000 va_acc=0.9522 va_auc=0.8598 | 192.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[unet_basic] Epoch 015 | tr_loss=0.1756 tr_f1=0.2703 tr_acc=0.9443 tr_auc=0.8111 || va_loss=0.2844 va_f1=0.0000 va_acc=0.9522 va_auc=0.5947 | 194.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[unet_basic] Epoch 016 | tr_loss=0.1684 tr_f1=0.2927 tr_acc=0.9465 tr_auc=0.8270 || va_loss=0.1428 va_f1=0.1002 va_acc=0.9537 va_auc=0.8595 | 193.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[unet_basic] Epoch 017 | tr_loss=0.1602 tr_f1=0.3762 tr_acc=0.9472 tr_auc=0.8480 || va_loss=0.1379 va_f1=0.2023 va_acc=0.9556 va_auc=0.8790 | 194.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[unet_basic] Epoch 018 | tr_loss=0.1484 tr_f1=0.4399 tr_acc=0.9500 tr_auc=0.8739 || va_loss=0.1444 va_f1=0.4110 va_acc=0.9599 va_auc=0.8884 | 190.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[unet_basic] Epoch 019 | tr_loss=0.1477 tr_f1=0.4413 tr_acc=0.9489 tr_auc=0.8770 || va_loss=0.1427 va_f1=0.2610 va_acc=0.9564 va_auc=0.8880 | 193.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/735404605.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(DEVICE.type == \"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[unet_basic] Epoch 020 | tr_loss=0.1380 tr_f1=0.4970 tr_acc=0.9531 tr_auc=0.8877 || va_loss=0.1479 va_f1=0.0000 va_acc=0.9522 va_auc=0.8732 | 192.7s\n"
     ]
    }
   ],
   "source": [
    "BEST_PATH = \"/kaggle/working/unet-best.pth\"\n",
    "best_val_f1 = -1\n",
    "\n",
    "import pandas as pd\n",
    "history = []\n",
    "\n",
    "for epoch in range(1, cfg.EPOCHS + 1):\n",
    "    t0 = time.time()\n",
    "\n",
    "    tr_loss, tr_prec, tr_rec, tr_f1, tr_acc, tr_auc = train_one_epoch(model, train_loader, thr=0.5)\n",
    "    va_loss, va_prec, va_rec, va_f1, va_acc, va_auc = validate_epoch(model, val_loader, thr=0.5)\n",
    "    elapsed = time.time() - t0\n",
    "\n",
    "    print(\n",
    "        f\"[unet_basic] Epoch {epoch:03d} | \"\n",
    "        f\"tr_loss={tr_loss:.4f} tr_f1={tr_f1:.4f} tr_acc={tr_acc:.4f} tr_PRauc={tr_auc:.4f} || \"\n",
    "        f\"va_loss={va_loss:.4f} va_f1={va_f1:.4f} va_acc={va_acc:.4f} va_PRauc={va_auc:.4f} | \"\n",
    "        f\"{elapsed:.1f}s\"\n",
    "    )\n",
    "\n",
    "    history.append({\n",
    "        \"epoch\": epoch,\n",
    "    \n",
    "        \"tr_loss\": tr_loss,\n",
    "        \"tr_precision\": tr_prec,\n",
    "        \"tr_recall\": tr_rec,\n",
    "        \"tr_f1\": tr_f1,\n",
    "        \"tr_acc\": tr_acc,\n",
    "        \"tr_PRauc\": tr_auc,\n",
    "    \n",
    "        \"va_loss\": va_loss,\n",
    "        \"va_precision\": va_prec,\n",
    "        \"va_recall\": va_rec,\n",
    "        \"va_f1\": va_f1,\n",
    "        \"va_acc\": va_acc,\n",
    "        \"va_PRauc\": va_auc,\n",
    "    \n",
    "        \"seconds\": elapsed\n",
    "    })\n",
    "\n",
    "    if va_f1 > best_val_f1:\n",
    "        best_val_f1 = va_f1\n",
    "        torch.save({\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"mean_13\": MEAN_13,\n",
    "            \"std_13\": STD_13,\n",
    "            \"epoch\": epoch,\n",
    "            \"best_val_f1\": best_val_f1,\n",
    "            \"va_auc\": va_auc,\n",
    "        }, BEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T19:07:51.921829Z",
     "iopub.status.busy": "2026-01-01T19:07:51.921070Z",
     "iopub.status.idle": "2026-01-01T19:07:51.952498Z",
     "shell.execute_reply": "2026-01-01T19:07:51.951646Z",
     "shell.execute_reply.started": "2026-01-01T19:07:51.921800Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>tr_loss</th>\n",
       "      <th>tr_precision</th>\n",
       "      <th>tr_recall</th>\n",
       "      <th>tr_f1</th>\n",
       "      <th>tr_acc</th>\n",
       "      <th>tr_auc</th>\n",
       "      <th>va_loss</th>\n",
       "      <th>va_precision</th>\n",
       "      <th>va_recall</th>\n",
       "      <th>va_f1</th>\n",
       "      <th>va_acc</th>\n",
       "      <th>va_auc</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2158</td>\n",
       "      <td>0.5144</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.9411</td>\n",
       "      <td>0.7017</td>\n",
       "      <td>0.1627</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.9522</td>\n",
       "      <td>0.8390</td>\n",
       "      <td>198.7840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.2008</td>\n",
       "      <td>0.4886</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.9411</td>\n",
       "      <td>0.6884</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.7561</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0468</td>\n",
       "      <td>0.9530</td>\n",
       "      <td>0.7855</td>\n",
       "      <td>195.5212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.1884</td>\n",
       "      <td>0.4473</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.9410</td>\n",
       "      <td>0.7671</td>\n",
       "      <td>0.1480</td>\n",
       "      <td>0.7419</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.1404</td>\n",
       "      <td>0.9546</td>\n",
       "      <td>0.8509</td>\n",
       "      <td>192.3430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.1851</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1225</td>\n",
       "      <td>0.9419</td>\n",
       "      <td>0.7681</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.7418</td>\n",
       "      <td>0.0796</td>\n",
       "      <td>0.1438</td>\n",
       "      <td>0.9547</td>\n",
       "      <td>0.8699</td>\n",
       "      <td>187.6002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.1787</td>\n",
       "      <td>0.5891</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.2314</td>\n",
       "      <td>0.9437</td>\n",
       "      <td>0.7872</td>\n",
       "      <td>0.1605</td>\n",
       "      <td>0.7568</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>0.8287</td>\n",
       "      <td>187.1016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.5649</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>0.2767</td>\n",
       "      <td>0.9436</td>\n",
       "      <td>0.8052</td>\n",
       "      <td>0.1584</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9522</td>\n",
       "      <td>0.8290</td>\n",
       "      <td>195.6284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.1756</td>\n",
       "      <td>0.5516</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.2651</td>\n",
       "      <td>0.9430</td>\n",
       "      <td>0.7977</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9522</td>\n",
       "      <td>0.7991</td>\n",
       "      <td>194.3773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.1735</td>\n",
       "      <td>0.5704</td>\n",
       "      <td>0.1764</td>\n",
       "      <td>0.2695</td>\n",
       "      <td>0.9437</td>\n",
       "      <td>0.8178</td>\n",
       "      <td>0.1469</td>\n",
       "      <td>0.7227</td>\n",
       "      <td>0.0735</td>\n",
       "      <td>0.1335</td>\n",
       "      <td>0.9543</td>\n",
       "      <td>0.8729</td>\n",
       "      <td>194.8437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.1707</td>\n",
       "      <td>0.6034</td>\n",
       "      <td>0.1878</td>\n",
       "      <td>0.2865</td>\n",
       "      <td>0.9449</td>\n",
       "      <td>0.8161</td>\n",
       "      <td>0.1573</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9522</td>\n",
       "      <td>0.8554</td>\n",
       "      <td>189.7026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1685</td>\n",
       "      <td>0.6035</td>\n",
       "      <td>0.2568</td>\n",
       "      <td>0.3602</td>\n",
       "      <td>0.9463</td>\n",
       "      <td>0.8220</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.6880</td>\n",
       "      <td>0.1057</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>0.9549</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>189.6036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.1649</td>\n",
       "      <td>0.6053</td>\n",
       "      <td>0.2313</td>\n",
       "      <td>0.3347</td>\n",
       "      <td>0.9458</td>\n",
       "      <td>0.8312</td>\n",
       "      <td>0.1505</td>\n",
       "      <td>0.7427</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>0.8533</td>\n",
       "      <td>191.3678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.1681</td>\n",
       "      <td>0.6222</td>\n",
       "      <td>0.2539</td>\n",
       "      <td>0.3607</td>\n",
       "      <td>0.9470</td>\n",
       "      <td>0.8157</td>\n",
       "      <td>0.1489</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9522</td>\n",
       "      <td>0.8641</td>\n",
       "      <td>191.7600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.1652</td>\n",
       "      <td>0.5974</td>\n",
       "      <td>0.2428</td>\n",
       "      <td>0.3453</td>\n",
       "      <td>0.9458</td>\n",
       "      <td>0.8426</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.6730</td>\n",
       "      <td>0.0930</td>\n",
       "      <td>0.1635</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>0.8671</td>\n",
       "      <td>195.1704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.6008</td>\n",
       "      <td>0.2596</td>\n",
       "      <td>0.3625</td>\n",
       "      <td>0.9462</td>\n",
       "      <td>0.8417</td>\n",
       "      <td>0.1614</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9522</td>\n",
       "      <td>0.8598</td>\n",
       "      <td>192.4867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.1756</td>\n",
       "      <td>0.5928</td>\n",
       "      <td>0.1751</td>\n",
       "      <td>0.2703</td>\n",
       "      <td>0.9443</td>\n",
       "      <td>0.8111</td>\n",
       "      <td>0.2844</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9522</td>\n",
       "      <td>0.5947</td>\n",
       "      <td>194.8026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.1684</td>\n",
       "      <td>0.6598</td>\n",
       "      <td>0.1881</td>\n",
       "      <td>0.2927</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.8270</td>\n",
       "      <td>0.1428</td>\n",
       "      <td>0.7188</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>0.1002</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.8595</td>\n",
       "      <td>193.7663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.1602</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>0.2702</td>\n",
       "      <td>0.3762</td>\n",
       "      <td>0.9472</td>\n",
       "      <td>0.8480</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.7183</td>\n",
       "      <td>0.1177</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>0.9556</td>\n",
       "      <td>0.8790</td>\n",
       "      <td>194.0770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.1484</td>\n",
       "      <td>0.6462</td>\n",
       "      <td>0.3335</td>\n",
       "      <td>0.4399</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.8739</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.6905</td>\n",
       "      <td>0.2926</td>\n",
       "      <td>0.4110</td>\n",
       "      <td>0.9599</td>\n",
       "      <td>0.8884</td>\n",
       "      <td>190.2770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.1477</td>\n",
       "      <td>0.6198</td>\n",
       "      <td>0.3426</td>\n",
       "      <td>0.4413</td>\n",
       "      <td>0.9489</td>\n",
       "      <td>0.8770</td>\n",
       "      <td>0.1427</td>\n",
       "      <td>0.6871</td>\n",
       "      <td>0.1611</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.9564</td>\n",
       "      <td>0.8880</td>\n",
       "      <td>193.0908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>0.6756</td>\n",
       "      <td>0.3931</td>\n",
       "      <td>0.4970</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>0.8877</td>\n",
       "      <td>0.1479</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9522</td>\n",
       "      <td>0.8732</td>\n",
       "      <td>192.6742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  tr_loss  tr_precision  tr_recall   tr_f1  tr_acc  tr_auc  va_loss  \\\n",
       "0       1   0.2158        0.5144     0.0120  0.0234  0.9411  0.7017   0.1627   \n",
       "1       2   0.2008        0.4886     0.0124  0.0241  0.9411  0.6884   0.1650   \n",
       "2       3   0.1884        0.4473     0.0106  0.0207  0.9410  0.7671   0.1480   \n",
       "3       4   0.1851        0.5523     0.0689  0.1225  0.9419  0.7681   0.1444   \n",
       "4       5   0.1787        0.5891     0.1440  0.2314  0.9437  0.7872   0.1605   \n",
       "5       6   0.1752        0.5649     0.1832  0.2767  0.9436  0.8052   0.1584   \n",
       "6       7   0.1756        0.5516     0.1745  0.2651  0.9430  0.7977   0.1667   \n",
       "7       8   0.1735        0.5704     0.1764  0.2695  0.9437  0.8178   0.1469   \n",
       "8       9   0.1707        0.6034     0.1878  0.2865  0.9449  0.8161   0.1573   \n",
       "9      10   0.1685        0.6035     0.2568  0.3602  0.9463  0.8220   0.1472   \n",
       "10     11   0.1649        0.6053     0.2313  0.3347  0.9458  0.8312   0.1505   \n",
       "11     12   0.1681        0.6222     0.2539  0.3607  0.9470  0.8157   0.1489   \n",
       "12     13   0.1652        0.5974     0.2428  0.3453  0.9458  0.8426   0.1415   \n",
       "13     14   0.1628        0.6008     0.2596  0.3625  0.9462  0.8417   0.1614   \n",
       "14     15   0.1756        0.5928     0.1751  0.2703  0.9443  0.8111   0.2844   \n",
       "15     16   0.1684        0.6598     0.1881  0.2927  0.9465  0.8270   0.1428   \n",
       "16     17   0.1602        0.6194     0.2702  0.3762  0.9472  0.8480   0.1379   \n",
       "17     18   0.1484        0.6462     0.3335  0.4399  0.9500  0.8739   0.1444   \n",
       "18     19   0.1477        0.6198     0.3426  0.4413  0.9489  0.8770   0.1427   \n",
       "19     20   0.1380        0.6756     0.3931  0.4970  0.9531  0.8877   0.1479   \n",
       "\n",
       "    va_precision  va_recall   va_f1  va_acc  va_auc   seconds  \n",
       "0         0.6629     0.0004  0.0007  0.9522  0.8390  198.7840  \n",
       "1         0.7561     0.0241  0.0468  0.9530  0.7855  195.5212  \n",
       "2         0.7419     0.0775  0.1404  0.9546  0.8509  192.3430  \n",
       "3         0.7418     0.0796  0.1438  0.9547  0.8699  187.6002  \n",
       "4         0.7568     0.0109  0.0214  0.9525  0.8287  187.1016  \n",
       "5         1.0000     0.0000  0.0000  0.9522  0.8290  195.6284  \n",
       "6         1.0000     0.0000  0.0000  0.9522  0.7991  194.3773  \n",
       "7         0.7227     0.0735  0.1335  0.9543  0.8729  194.8437  \n",
       "8         1.0000     0.0000  0.0000  0.9522  0.8554  189.7026  \n",
       "9         0.6880     0.1057  0.1832  0.9549  0.8600  189.6036  \n",
       "10        0.7427     0.0285  0.0550  0.9531  0.8533  191.3678  \n",
       "11        1.0000     0.0000  0.0000  0.9522  0.8641  191.7600  \n",
       "12        0.6730     0.0930  0.1635  0.9545  0.8671  195.1704  \n",
       "13        1.0000     0.0000  0.0000  0.9522  0.8598  192.4867  \n",
       "14        1.0000     0.0000  0.0000  0.9522  0.5947  194.8026  \n",
       "15        0.7188     0.0539  0.1002  0.9537  0.8595  193.7663  \n",
       "16        0.7183     0.1177  0.2023  0.9556  0.8790  194.0770  \n",
       "17        0.6905     0.2926  0.4110  0.9599  0.8884  190.2770  \n",
       "18        0.6871     0.1611  0.2610  0.9564  0.8880  193.0908  \n",
       "19        0.0000     0.0000  0.0000  0.9522  0.8732  192.6742  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_history = pd.DataFrame(history)\n",
    "\n",
    "df_history = df_history.round(4)\n",
    "csv_path = \"/kaggle/working/training_metrics1.csv\"\n",
    "df_history.to_csv(csv_path, index=False)\n",
    "print(\"Saved to:\", csv_path)\n",
    "df_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RECALL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T07:56:45.345274Z",
     "iopub.status.busy": "2026-02-03T07:56:45.344418Z",
     "iopub.status.idle": "2026-02-03T07:56:45.552550Z",
     "shell.execute_reply": "2026-02-03T07:56:45.551750Z",
     "shell.execute_reply.started": "2026-02-03T07:56:45.345239Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Unet\n"
     ]
    }
   ],
   "source": [
    "def build_unet(in_channels=13):\n",
    "    model = smp.Unet(\n",
    "        encoder_name=\"resnet18\",\n",
    "        encoder_weights=\"imagenet\",\n",
    "        in_channels=in_channels,\n",
    "        classes=1,\n",
    "        activation=None\n",
    "    )\n",
    "    return model\n",
    "    \n",
    "model_resnet = build_unet(cfg.IN_CHANNELS).to(DEVICE)\n",
    "print(\"Model:\", type(model_resnet).__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T07:56:56.558187Z",
     "iopub.status.busy": "2026-02-03T07:56:56.557880Z",
     "iopub.status.idle": "2026-02-03T07:56:57.575708Z",
     "shell.execute_reply": "2026-02-03T07:56:57.575138Z",
     "shell.execute_reply.started": "2026-02-03T07:56:56.558161Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load(\n",
    "    \"/kaggle/input/unet-resnet-pretrained/pytorch/default/1/unet_best_retrained2.pth\",\n",
    "    map_location=DEVICE,\n",
    "    weights_only=False  # biar load semua, bukan cuma weights\n",
    ")\n",
    "model_resnet.load_state_dict(ckpt[\"model_state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T10:51:01.964780Z",
     "iopub.status.busy": "2026-01-03T10:51:01.963931Z",
     "iopub.status.idle": "2026-01-03T12:56:48.042653Z",
     "shell.execute_reply": "2026-01-03T12:56:48.041846Z",
     "shell.execute_reply.started": "2026-01-03T10:51:01.964750Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BEST_PATH = \"/kaggle/working/unet_best_retrained2.pth\"\n",
    "best_val_f1 = -1\n",
    "\n",
    "import pandas as pd\n",
    "history = []\n",
    "\n",
    "for epoch in range(1, cfg.EPOCHS + 1):\n",
    "    t0 = time.time()\n",
    "\n",
    "    tr_loss, tr_prec, tr_rec, tr_f1, tr_acc, tr_auc = train_one_epoch(model_resnet, train_loader, thr=0.5)\n",
    "    va_loss, va_prec, va_rec, va_f1, va_acc, va_auc = validate_epoch(model_resnet, val_loader, thr=0.5)\n",
    "    elapsed = time.time() - t0\n",
    "\n",
    "    print(\n",
    "        f\"[unet_basic] Epoch {epoch:03d} | \"\n",
    "        f\"tr_loss={tr_loss:.4f} tr_f1={tr_f1:.4f} tr_acc={tr_acc:.4f} tr_auc={tr_auc:.4f} || \"\n",
    "        f\"va_loss={va_loss:.4f} va_f1={va_f1:.4f} va_acc={va_acc:.4f} va_auc={va_auc:.4f} | \"\n",
    "        f\"{elapsed:.1f}s\"\n",
    "    )\n",
    "\n",
    "    history.append({\n",
    "        \"epoch\": epoch,\n",
    "    \n",
    "        \"tr_loss\": tr_loss,\n",
    "        \"tr_precision\": tr_prec,\n",
    "        \"tr_recall\": tr_rec,\n",
    "        \"tr_f1\": tr_f1,\n",
    "        \"tr_acc\": tr_acc,\n",
    "        \"tr_auc\": tr_auc,\n",
    "    \n",
    "        \"va_loss\": va_loss,\n",
    "        \"va_precision\": va_prec,\n",
    "        \"va_recall\": va_rec,\n",
    "        \"va_f1\": va_f1,\n",
    "        \"va_acc\": va_acc,\n",
    "        \"va_auc\": va_auc,\n",
    "    \n",
    "        \"seconds\": elapsed\n",
    "    })\n",
    "\n",
    "    if va_f1 > best_val_f1:\n",
    "        torch.save({\n",
    "            \"model_state\": model_resnet.state_dict(),\n",
    "            \"mean_13\": MEAN_13,\n",
    "            \"std_13\":  STD_13,\n",
    "            \"epoch\": epoch,\n",
    "            \"best_val_f1\": best_val_f1,\n",
    "            \"va_auc\": va_auc,\n",
    "        }, BEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>tr_loss</th>\n",
       "      <th>tr_precision</th>\n",
       "      <th>tr_recall</th>\n",
       "      <th>tr_f1</th>\n",
       "      <th>tr_acc</th>\n",
       "      <th>tr_PRauc</th>\n",
       "      <th>va_loss</th>\n",
       "      <th>va_precision</th>\n",
       "      <th>va_recall</th>\n",
       "      <th>va_f1</th>\n",
       "      <th>va_acc</th>\n",
       "      <th>va_PRauc</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1353</td>\n",
       "      <td>0.4725</td>\n",
       "      <td>0.6825</td>\n",
       "      <td>0.5584</td>\n",
       "      <td>0.9364</td>\n",
       "      <td>0.7038</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>0.4725</td>\n",
       "      <td>0.4449</td>\n",
       "      <td>0.4583</td>\n",
       "      <td>0.9497</td>\n",
       "      <td>0.6217</td>\n",
       "      <td>192.7795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.1233</td>\n",
       "      <td>0.4960</td>\n",
       "      <td>0.7449</td>\n",
       "      <td>0.5955</td>\n",
       "      <td>0.9404</td>\n",
       "      <td>0.7214</td>\n",
       "      <td>0.1480</td>\n",
       "      <td>0.6728</td>\n",
       "      <td>0.3807</td>\n",
       "      <td>0.4862</td>\n",
       "      <td>0.9615</td>\n",
       "      <td>0.6432</td>\n",
       "      <td>187.1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.1284</td>\n",
       "      <td>0.4977</td>\n",
       "      <td>0.7104</td>\n",
       "      <td>0.5853</td>\n",
       "      <td>0.9407</td>\n",
       "      <td>0.7136</td>\n",
       "      <td>0.1357</td>\n",
       "      <td>0.4361</td>\n",
       "      <td>0.5744</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.9441</td>\n",
       "      <td>0.6589</td>\n",
       "      <td>186.4594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.1132</td>\n",
       "      <td>0.5361</td>\n",
       "      <td>0.7695</td>\n",
       "      <td>0.6319</td>\n",
       "      <td>0.9472</td>\n",
       "      <td>0.7569</td>\n",
       "      <td>0.1335</td>\n",
       "      <td>0.6459</td>\n",
       "      <td>0.4932</td>\n",
       "      <td>0.5593</td>\n",
       "      <td>0.9628</td>\n",
       "      <td>0.7014</td>\n",
       "      <td>186.0612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.1157</td>\n",
       "      <td>0.5369</td>\n",
       "      <td>0.7534</td>\n",
       "      <td>0.6270</td>\n",
       "      <td>0.9472</td>\n",
       "      <td>0.7421</td>\n",
       "      <td>0.1635</td>\n",
       "      <td>0.2717</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.9504</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>188.7184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.1081</td>\n",
       "      <td>0.5549</td>\n",
       "      <td>0.7820</td>\n",
       "      <td>0.6492</td>\n",
       "      <td>0.9502</td>\n",
       "      <td>0.7748</td>\n",
       "      <td>0.1376</td>\n",
       "      <td>0.3320</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>0.4201</td>\n",
       "      <td>0.9245</td>\n",
       "      <td>0.6128</td>\n",
       "      <td>186.6802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>0.5584</td>\n",
       "      <td>0.7838</td>\n",
       "      <td>0.6522</td>\n",
       "      <td>0.9508</td>\n",
       "      <td>0.7816</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>0.3180</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>0.9158</td>\n",
       "      <td>0.6294</td>\n",
       "      <td>186.8502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.6110</td>\n",
       "      <td>0.8363</td>\n",
       "      <td>0.7061</td>\n",
       "      <td>0.9590</td>\n",
       "      <td>0.8243</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.3152</td>\n",
       "      <td>0.6474</td>\n",
       "      <td>0.4240</td>\n",
       "      <td>0.9159</td>\n",
       "      <td>0.6231</td>\n",
       "      <td>185.2827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0831</td>\n",
       "      <td>0.6185</td>\n",
       "      <td>0.8574</td>\n",
       "      <td>0.7186</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>0.8437</td>\n",
       "      <td>0.1274</td>\n",
       "      <td>0.7018</td>\n",
       "      <td>0.5021</td>\n",
       "      <td>0.5854</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.7216</td>\n",
       "      <td>186.3489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0782</td>\n",
       "      <td>0.6185</td>\n",
       "      <td>0.8707</td>\n",
       "      <td>0.7233</td>\n",
       "      <td>0.9608</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.1261</td>\n",
       "      <td>0.4229</td>\n",
       "      <td>0.6122</td>\n",
       "      <td>0.5002</td>\n",
       "      <td>0.9415</td>\n",
       "      <td>0.6692</td>\n",
       "      <td>185.1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0701</td>\n",
       "      <td>0.6590</td>\n",
       "      <td>0.8924</td>\n",
       "      <td>0.7582</td>\n",
       "      <td>0.9665</td>\n",
       "      <td>0.8729</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>0.7626</td>\n",
       "      <td>0.5740</td>\n",
       "      <td>0.6550</td>\n",
       "      <td>0.9711</td>\n",
       "      <td>0.7826</td>\n",
       "      <td>186.4164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0606</td>\n",
       "      <td>0.6840</td>\n",
       "      <td>0.9195</td>\n",
       "      <td>0.7844</td>\n",
       "      <td>0.9702</td>\n",
       "      <td>0.8894</td>\n",
       "      <td>0.1107</td>\n",
       "      <td>0.8157</td>\n",
       "      <td>0.5076</td>\n",
       "      <td>0.6258</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>187.0958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.7317</td>\n",
       "      <td>0.9435</td>\n",
       "      <td>0.8242</td>\n",
       "      <td>0.9763</td>\n",
       "      <td>0.9127</td>\n",
       "      <td>0.1359</td>\n",
       "      <td>0.8367</td>\n",
       "      <td>0.3871</td>\n",
       "      <td>0.5293</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>0.6915</td>\n",
       "      <td>189.4120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.7256</td>\n",
       "      <td>0.9416</td>\n",
       "      <td>0.8196</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.9141</td>\n",
       "      <td>0.1381</td>\n",
       "      <td>0.8337</td>\n",
       "      <td>0.4298</td>\n",
       "      <td>0.5672</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>0.7421</td>\n",
       "      <td>188.6246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.7549</td>\n",
       "      <td>0.9582</td>\n",
       "      <td>0.8445</td>\n",
       "      <td>0.9792</td>\n",
       "      <td>0.9328</td>\n",
       "      <td>0.1294</td>\n",
       "      <td>0.7789</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.6127</td>\n",
       "      <td>0.9695</td>\n",
       "      <td>0.7684</td>\n",
       "      <td>187.5607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0419</td>\n",
       "      <td>0.7686</td>\n",
       "      <td>0.9498</td>\n",
       "      <td>0.8497</td>\n",
       "      <td>0.9802</td>\n",
       "      <td>0.9346</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.5231</td>\n",
       "      <td>0.6177</td>\n",
       "      <td>0.5665</td>\n",
       "      <td>0.9548</td>\n",
       "      <td>0.7296</td>\n",
       "      <td>186.7185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.0367</td>\n",
       "      <td>0.7603</td>\n",
       "      <td>0.9654</td>\n",
       "      <td>0.8507</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>0.1632</td>\n",
       "      <td>0.7981</td>\n",
       "      <td>0.5057</td>\n",
       "      <td>0.6191</td>\n",
       "      <td>0.9702</td>\n",
       "      <td>0.7812</td>\n",
       "      <td>187.5261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.7937</td>\n",
       "      <td>0.9715</td>\n",
       "      <td>0.8736</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>0.9569</td>\n",
       "      <td>0.1403</td>\n",
       "      <td>0.7766</td>\n",
       "      <td>0.5332</td>\n",
       "      <td>0.6323</td>\n",
       "      <td>0.9703</td>\n",
       "      <td>0.7923</td>\n",
       "      <td>191.8909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.8089</td>\n",
       "      <td>0.9772</td>\n",
       "      <td>0.8851</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>0.9634</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>0.6208</td>\n",
       "      <td>0.6465</td>\n",
       "      <td>0.6334</td>\n",
       "      <td>0.9642</td>\n",
       "      <td>0.7895</td>\n",
       "      <td>188.9727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.7683</td>\n",
       "      <td>0.9558</td>\n",
       "      <td>0.8518</td>\n",
       "      <td>0.9804</td>\n",
       "      <td>0.9478</td>\n",
       "      <td>0.1353</td>\n",
       "      <td>0.7480</td>\n",
       "      <td>0.6344</td>\n",
       "      <td>0.6865</td>\n",
       "      <td>0.9723</td>\n",
       "      <td>0.8127</td>\n",
       "      <td>188.8407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  tr_loss  tr_precision  tr_recall   tr_f1  tr_acc  tr_PRauc  \\\n",
       "0       1   0.1353        0.4725     0.6825  0.5584  0.9364    0.7038   \n",
       "1       2   0.1233        0.4960     0.7449  0.5955  0.9404    0.7214   \n",
       "2       3   0.1284        0.4977     0.7104  0.5853  0.9407    0.7136   \n",
       "3       4   0.1132        0.5361     0.7695  0.6319  0.9472    0.7569   \n",
       "4       5   0.1157        0.5369     0.7534  0.6270  0.9472    0.7421   \n",
       "5       6   0.1081        0.5549     0.7820  0.6492  0.9502    0.7748   \n",
       "6       7   0.1071        0.5584     0.7838  0.6522  0.9508    0.7816   \n",
       "7       8   0.0913        0.6110     0.8363  0.7061  0.9590    0.8243   \n",
       "8       9   0.0831        0.6185     0.8574  0.7186  0.9605    0.8437   \n",
       "9      10   0.0782        0.6185     0.8707  0.7233  0.9608    0.8562   \n",
       "10     11   0.0701        0.6590     0.8924  0.7582  0.9665    0.8729   \n",
       "11     12   0.0606        0.6840     0.9195  0.7844  0.9702    0.8894   \n",
       "12     13   0.0481        0.7317     0.9435  0.8242  0.9763    0.9127   \n",
       "13     14   0.0475        0.7256     0.9416  0.8196  0.9756    0.9141   \n",
       "14     15   0.0400        0.7549     0.9582  0.8445  0.9792    0.9328   \n",
       "15     16   0.0419        0.7686     0.9498  0.8497  0.9802    0.9346   \n",
       "16     17   0.0367        0.7603     0.9654  0.8507  0.9800    0.9482   \n",
       "17     18   0.0310        0.7937     0.9715  0.8736  0.9835    0.9569   \n",
       "18     19   0.0272        0.8089     0.9772  0.8851  0.9851    0.9634   \n",
       "19     20   0.0374        0.7683     0.9558  0.8518  0.9804    0.9478   \n",
       "\n",
       "    va_loss  va_precision  va_recall   va_f1  va_acc  va_PRauc   seconds  \n",
       "0    0.1394        0.4725     0.4449  0.4583  0.9497    0.6217  192.7795  \n",
       "1    0.1480        0.6728     0.3807  0.4862  0.9615    0.6432  187.1700  \n",
       "2    0.1357        0.4361     0.5744  0.4958  0.9441    0.6589  186.4594  \n",
       "3    0.1335        0.6459     0.4932  0.5593  0.9628    0.7014  186.0612  \n",
       "4    0.1635        0.2717     0.0218  0.0403  0.9504    0.5016  188.7184  \n",
       "5    0.1376        0.3320     0.5719  0.4201  0.9245    0.6128  186.6802  \n",
       "6    0.1247        0.3180     0.6638  0.4300  0.9158    0.6294  186.8502  \n",
       "7    0.1340        0.3152     0.6474  0.4240  0.9159    0.6231  185.2827  \n",
       "8    0.1274        0.7018     0.5021  0.5854  0.9660    0.7216  186.3489  \n",
       "9    0.1261        0.4229     0.6122  0.5002  0.9415    0.6692  185.1338  \n",
       "10   0.1189        0.7626     0.5740  0.6550  0.9711    0.7826  186.4164  \n",
       "11   0.1107        0.8157     0.5076  0.6258  0.9710    0.7778  187.0958  \n",
       "12   0.1359        0.8367     0.3871  0.5293  0.9671    0.6915  189.4120  \n",
       "13   0.1381        0.8337     0.4298  0.5672  0.9686    0.7421  188.6246  \n",
       "14   0.1294        0.7789     0.5050  0.6127  0.9695    0.7684  187.5607  \n",
       "15   0.1328        0.5231     0.6177  0.5665  0.9548    0.7296  186.7185  \n",
       "16   0.1632        0.7981     0.5057  0.6191  0.9702    0.7812  187.5261  \n",
       "17   0.1403        0.7766     0.5332  0.6323  0.9703    0.7923  191.8909  \n",
       "18   0.1510        0.6208     0.6465  0.6334  0.9642    0.7895  188.9727  \n",
       "19   0.1353        0.7480     0.6344  0.6865  0.9723    0.8127  188.8407  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_history = pd.DataFrame(history)\n",
    "\n",
    "df_history = df_history.round(4)\n",
    "csv_path = \"/kaggle/working/training_metrics2.csv\"\n",
    "df_history.to_csv(csv_path, index=False)\n",
    "print(\"Saved to:\", csv_path)\n",
    "df_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T08:09:31.782912Z",
     "iopub.status.busy": "2026-02-03T08:09:31.782628Z",
     "iopub.status.idle": "2026-02-03T08:10:01.502568Z",
     "shell.execute_reply": "2026-02-03T08:10:01.501708Z",
     "shell.execute_reply.started": "2026-02-03T08:09:31.782882Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss   : 0.0741\n",
      "Test Prec   : 0.7919\n",
      "Test Recall : 0.5115\n",
      "Test F1     : 0.6215\n",
      "Test Acc    : 0.9849\n",
      "Test AUC    : 0.9381\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_prec, test_rec, test_f1, test_acc, test_auc = validate_epoch(\n",
    "    model_resnet, test_loader, thr=0.5\n",
    ")\n",
    "\n",
    "print(f\"Test Loss   : {test_loss:.4f}\")\n",
    "print(f\"Test Prec   : {test_prec:.4f}\")\n",
    "print(f\"Test Recall : {test_rec:.4f}\")\n",
    "print(f\"Test F1     : {test_f1:.4f}\")\n",
    "print(f\"Test Acc    : {test_acc:.4f}\")\n",
    "print(f\"Test AUC    : {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T08:04:30.547255Z",
     "iopub.status.busy": "2026-02-03T08:04:30.546926Z",
     "iopub.status.idle": "2026-02-03T08:06:55.552641Z",
     "shell.execute_reply": "2026-02-03T08:06:55.551884Z",
     "shell.execute_reply.started": "2026-02-03T08:04:30.547224Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen threshold: 0.05\n",
      "Best global F1: 0.7089154482663805\n",
      "Top-5 thresholds:\n",
      "0.05 0.7089154482663805\n",
      "0.1 0.6982025983080857\n",
      "0.15 0.6826100804908246\n",
      "0.2 0.6655139540121443\n",
      "0.25 0.6510137989363838\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def find_best_thr_global_f1(model, loader, grid=None, eps=1e-6):\n",
    "    model.eval()\n",
    "    if grid is None:\n",
    "        grid = np.linspace(0.05, 0.95, 19)\n",
    "\n",
    "    best_thr = None\n",
    "    best_f1 = -1\n",
    "    log = []\n",
    "\n",
    "    for thr in grid:\n",
    "        total_tp = total_fp = total_fn = 0.0\n",
    "\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            x = normalize_batch(x, MEAN_13, STD_13)\n",
    "\n",
    "            logits = model(x)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs >= thr).float()\n",
    "\n",
    "            total_tp += (preds * y).sum().item()\n",
    "            total_fp += (preds * (1 - y)).sum().item()\n",
    "            total_fn += ((1 - preds) * y).sum().item()\n",
    "\n",
    "        precision = (total_tp + eps) / (total_tp + total_fp + eps)\n",
    "        recall    = (total_tp + eps) / (total_tp + total_fn + eps)\n",
    "        f1        = (2 * precision * recall) / (precision + recall + eps)\n",
    "\n",
    "        log.append((float(thr), f1))\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_thr = float(thr)\n",
    "\n",
    "    return best_thr, best_f1, log\n",
    "\n",
    "t_best, best_f1, thr_log = find_best_thr_global_f1(model_resnet, val_loader)\n",
    "\n",
    "print(\"Chosen threshold:\", t_best)\n",
    "print(\"Best global F1:\", best_f1)\n",
    "\n",
    "print(\"Top-5 thresholds:\")\n",
    "for thr, f1 in sorted(thr_log, key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print(thr, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T08:10:01.504287Z",
     "iopub.status.busy": "2026-02-03T08:10:01.503980Z",
     "iopub.status.idle": "2026-02-03T08:10:30.762640Z",
     "shell.execute_reply": "2026-02-03T08:10:30.761777Z",
     "shell.execute_reply.started": "2026-02-03T08:10:01.504256Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss   : 0.0741\n",
      "Test Prec   : 0.7120\n",
      "Test Recall : 0.6341\n",
      "Test F1     : 0.6708\n",
      "Test Acc    : 0.9849\n",
      "Test AUC    : 0.9381\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_prec, test_rec, test_f1, test_acc, test_auc = validate_epoch(\n",
    "    model_resnet, test_loader, thr=0.05\n",
    ")\n",
    "\n",
    "print(f\"Test Loss   : {test_loss:.4f}\")\n",
    "print(f\"Test Prec   : {test_prec:.4f}\")\n",
    "print(f\"Test Recall : {test_rec:.4f}\")\n",
    "print(f\"Test F1     : {test_f1:.4f}\")\n",
    "print(f\"Test Acc    : {test_acc:.4f}\")\n",
    "print(f\"Test AUC    : {test_auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8507641,
     "sourceId": 14342736,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9210066,
     "sourceId": 14420149,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 550436,
     "modelInstanceId": 537030,
     "sourceId": 707273,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 555041,
     "modelInstanceId": 541846,
     "sourceId": 713095,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
