{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T19:38:03.118917Z",
     "iopub.status.busy": "2026-01-05T19:38:03.118630Z",
     "iopub.status.idle": "2026-01-05T19:38:06.903731Z",
     "shell.execute_reply": "2026-01-05T19:38:06.902964Z",
     "shell.execute_reply.started": "2026-01-05T19:38:03.118893Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "DATA_ROOT OK: /kaggle/input/sen2fire/Sen2Fire/Sen2Fire\n"
     ]
    }
   ],
   "source": [
    "import os, glob, random, json\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ----------------------------\n",
    "# Reproducibility\n",
    "# ----------------------------\n",
    "def seed_everything(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "SEED = 24\n",
    "seed_everything(SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "@dataclass\n",
    "class CFG:\n",
    "    DATA_ROOT: str = \"/kaggle/input/sen2fire/Sen2Fire/Sen2Fire\"\n",
    "    SCENES: Tuple[str, ...] = (\"scene1\", \"scene2\", \"scene3\", \"scene4\")\n",
    "    PATCH_EXT: str = \".npz\"\n",
    "\n",
    "    # Global split (VD default)\n",
    "    USE_GLOBAL_SPLIT: bool = True\n",
    "    GLOBAL_TRAIN_RATIO: float = 0.80\n",
    "    GLOBAL_VAL_RATIO: float = 0.10\n",
    "    GLOBAL_TEST_RATIO: float = 0.10\n",
    "    KEEP_VAL_TEST_NATURAL: bool = True\n",
    "\n",
    "    # Keys inside npz\n",
    "    X_KEY: str = \"image\"     # (12,512,512)\n",
    "    A_KEY: str = \"aerosol\"   # (512,512) -> becomes 1 channel\n",
    "    Y_KEY: str = \"label\"     # (512,512)\n",
    "\n",
    "    # Fire patch definition\n",
    "    FIRE_PATCH_MIN_RATIO: float = 0\n",
    "\n",
    "    # Controlled train pool (VD default)\n",
    "    USE_CONTROLLED_POOL: bool = True\n",
    "    POOL_KEEP_FIRE: int = -1\n",
    "    NONFIRE_PER_FIRE: int = 3\n",
    "\n",
    "    # Training config (RAM-safe)\n",
    "    IN_CHANNELS: int = 13\n",
    "    H: int = 512\n",
    "    W: int = 512\n",
    "    BATCH_SIZE: int = 2\n",
    "    NUM_WORKERS: int = 2\n",
    "    LR: float = 1e-4\n",
    "    EPOCHS: int = 20\n",
    "\n",
    "    VERBOSE: bool = True\n",
    "\n",
    "cfg = CFG()\n",
    "\n",
    "assert abs((cfg.GLOBAL_TRAIN_RATIO + cfg.GLOBAL_VAL_RATIO + cfg.GLOBAL_TEST_RATIO) - 1.0) < 1e-6\n",
    "assert os.path.exists(cfg.DATA_ROOT), f\"DATA_ROOT not found: {cfg.DATA_ROOT}\"\n",
    "print(\"DATA_ROOT OK:\", cfg.DATA_ROOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire Risk Mapping (Sen2Fire) — Notebook 2 (DeepLabV3+)\n",
    "\n",
    "Same pipeline as Notebook 1 (UNet++):\n",
    "- Global stratified split + controlled train pool\n",
    "- Normalization (13-channel)\n",
    "- Segmentation training\n",
    "- t_high selection by validation mean Dice sweep\n",
    "- Export Streamlit-ready model package\n",
    "\n",
    "Export folder:\n",
    "- /kaggle/working/model_packages/deeplabv3p_fire/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine 1 — Patch Intake (NPZ → X, Y)\n",
    "\n",
    "Inside each patch (.npz):\n",
    "- `image`: (12,512,512) Sentinel-2 bands\n",
    "- `aerosol`: (512,512) additional band\n",
    "- `label`: (512,512) fire mask (0/1)\n",
    "\n",
    "We construct:\n",
    "- X: concat(image[12], aerosol[1]) → (13,512,512)\n",
    "- Y: label → (1,512,512)\n",
    "\n",
    "Note:\n",
    "- Y is only used during training/validation to compute loss/metrics.\n",
    "- During Streamlit inference, we only have X.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T19:38:08.047878Z",
     "iopub.status.busy": "2026-01-05T19:38:08.047468Z",
     "iopub.status.idle": "2026-01-05T19:38:08.117596Z",
     "shell.execute_reply": "2026-01-05T19:38:08.117046Z",
     "shell.execute_reply.started": "2026-01-05T19:38:08.047851Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene1: 864 patches\n",
      "scene2: 594 patches\n",
      "scene3: 504 patches\n",
      "scene4: 504 patches\n",
      "Total patches: 2466\n"
     ]
    }
   ],
   "source": [
    "def list_scene_files(data_root: str, scene_name: str, ext: str = \".npz\") -> List[str]:\n",
    "    scene_dir = os.path.join(data_root, scene_name)\n",
    "    return sorted(glob.glob(os.path.join(scene_dir, f\"*{ext}\")))\n",
    "\n",
    "scene_to_files = {}\n",
    "total = 0\n",
    "for s in cfg.SCENES:\n",
    "    files = list_scene_files(cfg.DATA_ROOT, s, cfg.PATCH_EXT)\n",
    "    scene_to_files[s] = files\n",
    "    total += len(files)\n",
    "    print(f\"{s}: {len(files)} patches\")\n",
    "\n",
    "print(\"Total patches:\", total)\n",
    "if total == 0:\n",
    "    raise RuntimeError(\"No patch files found. Check DATA_ROOT / PATCH_EXT.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T19:38:10.755516Z",
     "iopub.status.busy": "2026-01-05T19:38:10.754894Z",
     "iopub.status.idle": "2026-01-05T19:38:10.877778Z",
     "shell.execute_reply": "2026-01-05T19:38:10.877027Z",
     "shell.execute_reply.started": "2026-01-05T19:38:10.755486Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample file: /kaggle/input/sen2fire/Sen2Fire/Sen2Fire/scene1/scene_1_patch_10_1.npz\n",
      "  -      image: shape=(12, 512, 512), dtype=int16\n",
      "  -    aerosol: shape=(512, 512), dtype=float32\n",
      "  -      label: shape=(512, 512), dtype=uint8\n"
     ]
    }
   ],
   "source": [
    "def inspect_npz(npz_path: str):\n",
    "    with np.load(npz_path) as data:\n",
    "        return {k: (data[k].shape, str(data[k].dtype)) for k in data.keys()}\n",
    "\n",
    "sample_path = scene_to_files[cfg.SCENES[0]][0]\n",
    "print(\"Sample file:\", sample_path)\n",
    "info = inspect_npz(sample_path)\n",
    "for k, (shape, dtype) in info.items():\n",
    "    print(f\"  - {k:>10s}: shape={shape}, dtype={dtype}\")\n",
    "\n",
    "for rk in [cfg.X_KEY, cfg.A_KEY, cfg.Y_KEY]:\n",
    "    if rk not in info:\n",
    "        raise KeyError(f\"Missing key '{rk}' in npz. Found keys: {list(info.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T19:38:15.510363Z",
     "iopub.status.busy": "2026-01-05T19:38:15.509621Z",
     "iopub.status.idle": "2026-01-05T19:38:46.478095Z",
     "shell.execute_reply": "2026-01-05T19:38:46.477379Z",
     "shell.execute_reply.started": "2026-01-05T19:38:15.510332Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FULL dataset has_fire distribution:\n",
      "has_fire\n",
      "0    2117\n",
      "1     349\n",
      "Name: count, dtype: int64\n",
      "\n",
      "FULL dataset has_fire ratio:\n",
      "has_fire\n",
      "0    0.858475\n",
      "1    0.141525\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for s, files in scene_to_files.items():\n",
    "    for p in files:\n",
    "        rows.append({\"scene\": s, \"path\": p})\n",
    "manifest = pd.DataFrame(rows)\n",
    "\n",
    "def fire_ratio_from_path(npz_path: str) -> float:\n",
    "    with np.load(npz_path) as data:\n",
    "        y = data[cfg.Y_KEY]\n",
    "        if y.ndim == 3 and y.shape[-1] == 1:\n",
    "            y = y[..., 0]\n",
    "        yb = (y > 0).astype(np.uint8)\n",
    "        return float(yb.mean())\n",
    "\n",
    "fire_ratios = []\n",
    "has_fire = []\n",
    "for p in manifest[\"path\"].tolist():\n",
    "    r = fire_ratio_from_path(p)\n",
    "    fire_ratios.append(r)\n",
    "    has_fire.append(1 if r > cfg.FIRE_PATCH_MIN_RATIO else 0)\n",
    "\n",
    "manifest[\"fire_ratio\"] = fire_ratios\n",
    "manifest[\"has_fire\"] = has_fire\n",
    "\n",
    "print(\"\\nFULL dataset has_fire distribution:\")\n",
    "print(manifest[\"has_fire\"].value_counts().sort_index())\n",
    "print(\"\\nFULL dataset has_fire ratio:\")\n",
    "print(manifest[\"has_fire\"].value_counts(normalize=True).sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T19:38:46.479708Z",
     "iopub.status.busy": "2026-01-05T19:38:46.479409Z",
     "iopub.status.idle": "2026-01-05T19:38:46.503631Z",
     "shell.execute_reply": "2026-01-05T19:38:46.503053Z",
     "shell.execute_reply.started": "2026-01-05T19:38:46.479683Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GLOBAL split counts:\n",
      "  Train pool: 1973\n",
      "  Val      : 247\n",
      "  Test     : 246\n",
      "\n",
      "TRAIN controlled sampling:\n",
      "  fire_total_in_pool   : 279\n",
      "  nofire_total_in_pool : 1694\n",
      "  fire_kept            : 279\n",
      "  nofire_kept          : 837 (NONFIRE_PER_FIRE=3)\n",
      "  train_final          : 1116\n",
      "\n",
      "Final used split sizes:\n",
      "  train: 1116\n",
      "  val  : 247\n",
      "  test : 246\n"
     ]
    }
   ],
   "source": [
    "def stratified_split(df, train_ratio, val_ratio, seed=42):\n",
    "    df = df.sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
    "    parts = []\n",
    "    for cls in [0, 1]:\n",
    "        sub = df[df[\"has_fire\"] == cls].copy()\n",
    "        n = len(sub)\n",
    "        n_train = int(round(n * train_ratio))\n",
    "        n_val   = int(round(n * val_ratio))\n",
    "        sub_train = sub.iloc[:n_train]\n",
    "        sub_val   = sub.iloc[n_train:n_train+n_val]\n",
    "        sub_test  = sub.iloc[n_train+n_val:]\n",
    "        parts.append((sub_train, sub_val, sub_test))\n",
    "\n",
    "    train_df = pd.concat([parts[0][0], parts[1][0]]).sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
    "    val_df   = pd.concat([parts[0][1], parts[1][1]]).sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
    "    test_df  = pd.concat([parts[0][2], parts[1][2]]).sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "train_pool_df, val_df, test_df = stratified_split(\n",
    "    manifest,\n",
    "    train_ratio=cfg.GLOBAL_TRAIN_RATIO,\n",
    "    val_ratio=cfg.GLOBAL_VAL_RATIO,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "print(\"\\nGLOBAL split counts:\")\n",
    "print(\"  Train pool:\", len(train_pool_df))\n",
    "print(\"  Val      :\", len(val_df))\n",
    "print(\"  Test     :\", len(test_df))\n",
    "\n",
    "# Controlled pool applies to TRAIN only\n",
    "if cfg.USE_CONTROLLED_POOL:\n",
    "    fire_df   = train_pool_df[train_pool_df[\"has_fire\"] == 1].copy()\n",
    "    nofire_df = train_pool_df[train_pool_df[\"has_fire\"] == 0].copy()\n",
    "\n",
    "    n_fire_total = len(fire_df)\n",
    "    n_nofire_total = len(nofire_df)\n",
    "\n",
    "    n_fire_keep = n_fire_total if cfg.POOL_KEEP_FIRE in (-1, None) else min(cfg.POOL_KEEP_FIRE, n_fire_total)\n",
    "    fire_keep = fire_df.sample(n=n_fire_keep, random_state=SEED) if n_fire_keep > 0 else fire_df.iloc[:0]\n",
    "\n",
    "    n_nofire_keep = min(n_nofire_total, n_fire_keep * int(cfg.NONFIRE_PER_FIRE))\n",
    "    nofire_keep = nofire_df.sample(n=n_nofire_keep, random_state=SEED) if n_nofire_keep > 0 else nofire_df.iloc[:0]\n",
    "\n",
    "    train_df = pd.concat([fire_keep, nofire_keep]).sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "    print(\"\\nTRAIN controlled sampling:\")\n",
    "    print(f\"  fire_total_in_pool   : {n_fire_total}\")\n",
    "    print(f\"  nofire_total_in_pool : {n_nofire_total}\")\n",
    "    print(f\"  fire_kept            : {len(fire_keep)}\")\n",
    "    print(f\"  nofire_kept          : {len(nofire_keep)} (NONFIRE_PER_FIRE={cfg.NONFIRE_PER_FIRE})\")\n",
    "    print(f\"  train_final          : {len(train_df)}\")\n",
    "else:\n",
    "    train_df = train_pool_df.copy()\n",
    "\n",
    "train_paths = train_df[\"path\"].tolist()\n",
    "val_paths   = val_df[\"path\"].tolist()\n",
    "test_paths  = test_df[\"path\"].tolist()\n",
    "\n",
    "# leakage check\n",
    "assert len(set(train_paths)&set(val_paths))==0\n",
    "assert len(set(train_paths)&set(test_paths))==0\n",
    "assert len(set(val_paths)&set(test_paths))==0\n",
    "\n",
    "print(\"\\nFinal used split sizes:\")\n",
    "print(\"  train:\", len(train_paths))\n",
    "print(\"  val  :\", len(val_paths))\n",
    "print(\"  test :\", len(test_paths))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine 2 — Normalization (X only)\n",
    "\n",
    "We compute mean/std per band (13 values each) from TRAIN ONLY:\n",
    "X_norm[c] = (X[c] - mean[c]) / std[c]\n",
    "\n",
    "Mini example:\n",
    "- raw pixel = 820\n",
    "- mean = 600\n",
    "- std = 100\n",
    "- norm = 2.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T19:38:46.504714Z",
     "iopub.status.busy": "2026-01-05T19:38:46.504521Z",
     "iopub.status.idle": "2026-01-05T19:38:46.511138Z",
     "shell.execute_reply": "2026-01-05T19:38:46.510394Z",
     "shell.execute_reply.started": "2026-01-05T19:38:46.504696Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Sen2FireDataset(Dataset):\n",
    "    def __init__(self, paths: List[str], with_label: bool = True):\n",
    "        self.paths = paths\n",
    "        self.with_label = with_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.paths[idx]\n",
    "        with np.load(p) as d:\n",
    "            img12 = d[cfg.X_KEY].astype(np.float32)      # (12,512,512)\n",
    "            aer   = d[cfg.A_KEY].astype(np.float32)[None, ...]  # (1,512,512)\n",
    "            x = np.concatenate([img12, aer], axis=0)     # (13,512,512)\n",
    "\n",
    "            if self.with_label:\n",
    "                y = d[cfg.Y_KEY]\n",
    "                if y.ndim == 2:\n",
    "                    y = y[None, ...]\n",
    "                y = (y > 0).astype(np.float32)\n",
    "                return torch.from_numpy(x), torch.from_numpy(y)\n",
    "            else:\n",
    "                return torch.from_numpy(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T19:38:46.512741Z",
     "iopub.status.busy": "2026-01-05T19:38:46.512511Z",
     "iopub.status.idle": "2026-01-05T19:38:46.527898Z",
     "shell.execute_reply": "2026-01-05T19:38:46.527231Z",
     "shell.execute_reply.started": "2026-01-05T19:38:46.512712Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(Sen2FireDataset(train_paths, with_label=True),\n",
    "                          batch_size=cfg.BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=cfg.NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "val_loader = DataLoader(Sen2FireDataset(val_paths, with_label=True),\n",
    "                        batch_size=cfg.BATCH_SIZE, shuffle=False,\n",
    "                        num_workers=cfg.NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "test_loader = DataLoader(Sen2FireDataset(test_paths, with_label=True),\n",
    "                         batch_size=cfg.BATCH_SIZE, shuffle=False,\n",
    "                         num_workers=cfg.NUM_WORKERS, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T19:38:46.528857Z",
     "iopub.status.busy": "2026-01-05T19:38:46.528645Z",
     "iopub.status.idle": "2026-01-05T19:38:50.495810Z",
     "shell.execute_reply": "2026-01-05T19:38:50.495103Z",
     "shell.execute_reply.started": "2026-01-05T19:38:46.528838Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN_13 len: 13 STD_13 len: 13\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def compute_mean_std(loader, max_batches=50):\n",
    "    mean = torch.zeros(cfg.IN_CHANNELS, device=DEVICE)\n",
    "    var  = torch.zeros(cfg.IN_CHANNELS, device=DEVICE)\n",
    "    n_batches = 0\n",
    "\n",
    "    for bi, (x, y) in enumerate(loader):\n",
    "        if bi >= max_batches:\n",
    "            break\n",
    "        x = x.to(DEVICE)  # (B,C,H,W)\n",
    "        x_ = x.view(x.size(0), cfg.IN_CHANNELS, -1)\n",
    "        mean += x_.mean(dim=(0,2))\n",
    "        var  += x_.var(dim=(0,2), unbiased=False)\n",
    "        n_batches += 1\n",
    "\n",
    "    mean /= max(n_batches, 1)\n",
    "    var  /= max(n_batches, 1)\n",
    "    std = torch.sqrt(var + 1e-6)\n",
    "    return mean.detach().cpu().tolist(), std.detach().cpu().tolist()\n",
    "\n",
    "MEAN_13, STD_13 = compute_mean_std(train_loader, max_batches=50)\n",
    "print(\"MEAN_13 len:\", len(MEAN_13), \"STD_13 len:\", len(STD_13))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T19:38:50.497237Z",
     "iopub.status.busy": "2026-01-05T19:38:50.496968Z",
     "iopub.status.idle": "2026-01-05T19:38:54.795814Z",
     "shell.execute_reply": "2026-01-05T19:38:54.795144Z",
     "shell.execute_reply.started": "2026-01-05T19:38:50.497210Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip -q install segmentation-models-pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T19:38:54.797309Z",
     "iopub.status.busy": "2026-01-05T19:38:54.797039Z",
     "iopub.status.idle": "2026-01-05T19:38:54.802349Z",
     "shell.execute_reply": "2026-01-05T19:38:54.801605Z",
     "shell.execute_reply.started": "2026-01-05T19:38:54.797280Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def normalize_batch(x, mean_13, std_13):\n",
    "    mean_t = torch.tensor(mean_13, device=x.device).view(1, cfg.IN_CHANNELS, 1, 1)\n",
    "    std_t  = torch.tensor(std_13,  device=x.device).view(1, cfg.IN_CHANNELS, 1, 1)\n",
    "    return (x - mean_t) / (std_t + 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEPLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T19:38:54.804189Z",
     "iopub.status.busy": "2026-01-05T19:38:54.803874Z",
     "iopub.status.idle": "2026-01-05T19:39:04.164779Z",
     "shell.execute_reply": "2026-01-05T19:39:04.164235Z",
     "shell.execute_reply.started": "2026-01-05T19:38:54.804169Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046f4a29f6a546cdb42e67302946ee3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/106 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6aeb214eb34151931cefc3c96ac221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/77.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DeepLabV3Plus\n"
     ]
    }
   ],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def build_deeplab(in_channels=13):\n",
    "    model = smp.DeepLabV3Plus(\n",
    "        encoder_name=\"efficientnet-b4\", \n",
    "        encoder_weights=\"imagenet\",\n",
    "        in_channels=in_channels,\n",
    "        classes=1,\n",
    "        activation=None\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build_deeplab(cfg.IN_CHANNELS).to(DEVICE)\n",
    "print(\"Model:\", type(model).__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T13:22:55.213367Z",
     "iopub.status.busy": "2026-01-04T13:22:55.213033Z",
     "iopub.status.idle": "2026-01-04T13:22:55.842041Z",
     "shell.execute_reply": "2026-01-04T13:22:55.841318Z",
     "shell.execute_reply.started": "2026-01-04T13:22:55.213340Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.amp import autocast, GradScaler\n",
    "from sklearn.metrics import average_precision_score\n",
    "import time\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cfg.LR)\n",
    "scaler = GradScaler(enabled=(DEVICE.type == \"cuda\"))\n",
    "\n",
    "def train_one_epoch(model, loader, thr=0.5, eps=1e-6):\n",
    "    model.train()\n",
    "    total_loss_sum = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    total_tp = total_fp = total_fn = total_tn = 0.0\n",
    "    all_probs, all_targets = [], []\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        x = normalize_batch(x, MEAN_13, STD_13)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with autocast(\"cuda\", enabled=(DEVICE.type == \"cuda\")):\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        bs = x.size(0)\n",
    "        total_loss_sum += loss.item() * bs\n",
    "        total_samples += bs\n",
    "\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= thr).float()\n",
    "\n",
    "        total_tp += (preds * y).sum().item()\n",
    "        total_fp += (preds * (1 - y)).sum().item()\n",
    "        total_fn += ((1 - preds) * y).sum().item()\n",
    "        total_tn += ((1 - preds) * (1 - y)).sum().item()\n",
    "\n",
    "        all_probs.append(probs.flatten().detach().cpu())\n",
    "        all_targets.append(y.flatten().detach().cpu())\n",
    "\n",
    "    precision = (total_tp + eps) / (total_tp + total_fp + eps)\n",
    "    recall    = (total_tp + eps) / (total_tp + total_fn + eps)\n",
    "    f1        = (2 * precision * recall) / (precision + recall + eps)\n",
    "    acc       = (total_tp + total_tn + eps) / (\n",
    "        total_tp + total_tn + total_fp + total_fn + eps\n",
    "    )\n",
    "\n",
    "    all_probs = torch.cat(all_probs).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "    auc = average_precision_score(all_targets, all_probs)\n",
    "\n",
    "    loss_global = total_loss_sum / total_samples\n",
    "\n",
    "    return loss_global, precision, recall, f1, acc, auc\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_epoch(model, loader, thr=0.5, eps=1e-6):\n",
    "    model.eval()\n",
    "    total_loss_sum = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    total_tp = total_fp = total_fn = total_tn = 0.0\n",
    "    all_probs, all_targets = [], []\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        x = normalize_batch(x, MEAN_13, STD_13)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        bs = x.size(0)\n",
    "        total_loss_sum += loss.item() * bs\n",
    "        total_samples += bs\n",
    "\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= thr).float()\n",
    "\n",
    "        total_tp += (preds * y).sum().item()\n",
    "        total_fp += (preds * (1 - y)).sum().item()\n",
    "        total_fn += ((1 - preds) * y).sum().item()\n",
    "        total_tn += ((1 - preds) * (1 - y)).sum().item()\n",
    "\n",
    "        all_probs.append(probs.flatten().cpu())\n",
    "        all_targets.append(y.flatten().cpu())\n",
    "\n",
    "    precision = (total_tp + eps) / (total_tp + total_fp + eps)\n",
    "    recall    = (total_tp + eps) / (total_tp + total_fn + eps)\n",
    "    f1        = (2 * precision * recall) / (precision + recall + eps)\n",
    "    acc       = (total_tp + total_tn + eps) / (\n",
    "        total_tp + total_tn + total_fp + total_fn + eps\n",
    "    )\n",
    "\n",
    "    all_probs = torch.cat(all_probs).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "    auc = average_precision_score(all_targets, all_probs)\n",
    "\n",
    "    loss_global = total_loss_sum / total_samples\n",
    "\n",
    "    return loss_global, precision, recall, f1, acc, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T13:23:02.422014Z",
     "iopub.status.busy": "2026-01-04T13:23:02.421309Z",
     "iopub.status.idle": "2026-01-04T15:35:00.137825Z",
     "shell.execute_reply": "2026-01-04T15:35:00.136926Z",
     "shell.execute_reply.started": "2026-01-04T13:23:02.421985Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[unet_basic] Epoch 001 | tr_loss=0.2787 tr_f1=0.0174 tr_acc=0.9346 tr_PRauc=0.0732 || va_loss=0.1667 va_f1=0.0040 va_acc=0.9520 va_PRauc=0.2708 | 400.6s\n",
      "[unet_basic] Epoch 002 | tr_loss=0.1921 tr_f1=0.0322 tr_acc=0.9413 tr_PRauc=0.2466 || va_loss=0.1187 va_f1=0.3036 va_acc=0.9570 va_PRauc=0.4522 | 398.2s\n",
      "[unet_basic] Epoch 003 | tr_loss=0.1787 tr_f1=0.1253 tr_acc=0.9422 tr_PRauc=0.3084 || va_loss=0.1315 va_f1=0.2604 va_acc=0.9537 va_PRauc=0.3854 | 397.5s\n",
      "[unet_basic] Epoch 004 | tr_loss=0.1535 tr_f1=0.3014 tr_acc=0.9461 tr_PRauc=0.4321 || va_loss=0.1246 va_f1=0.3589 va_acc=0.9567 va_PRauc=0.4470 | 397.5s\n",
      "[unet_basic] Epoch 005 | tr_loss=0.1289 tr_f1=0.4866 tr_acc=0.9543 tr_PRauc=0.5793 || va_loss=0.1167 va_f1=0.3626 va_acc=0.9570 va_PRauc=0.4905 | 395.9s\n",
      "[unet_basic] Epoch 006 | tr_loss=0.1054 tr_f1=0.6396 tr_acc=0.9621 tr_PRauc=0.6848 || va_loss=0.1271 va_f1=0.4148 va_acc=0.9545 va_PRauc=0.4399 | 395.6s\n",
      "[unet_basic] Epoch 007 | tr_loss=0.0982 tr_f1=0.6698 tr_acc=0.9665 tr_PRauc=0.7423 || va_loss=0.1028 va_f1=0.6105 va_acc=0.9600 va_PRauc=0.5962 | 395.7s\n",
      "[unet_basic] Epoch 008 | tr_loss=0.0741 tr_f1=0.7764 tr_acc=0.9751 tr_PRauc=0.8325 || va_loss=0.1240 va_f1=0.2585 va_acc=0.9566 va_PRauc=0.5015 | 395.3s\n",
      "[unet_basic] Epoch 009 | tr_loss=0.0600 tr_f1=0.8228 tr_acc=0.9800 tr_PRauc=0.8809 || va_loss=0.1388 va_f1=0.2001 va_acc=0.9533 va_PRauc=0.3915 | 395.5s\n",
      "[unet_basic] Epoch 010 | tr_loss=0.0485 tr_f1=0.8518 tr_acc=0.9829 tr_PRauc=0.9145 || va_loss=0.1009 va_f1=0.4869 va_acc=0.9653 va_PRauc=0.6664 | 393.8s\n",
      "[unet_basic] Epoch 011 | tr_loss=0.0511 tr_f1=0.8426 tr_acc=0.9821 tr_PRauc=0.9100 || va_loss=0.1139 va_f1=0.4704 va_acc=0.9636 va_PRauc=0.6374 | 393.6s\n",
      "[unet_basic] Epoch 012 | tr_loss=0.0445 tr_f1=0.8680 tr_acc=0.9848 tr_PRauc=0.9307 || va_loss=0.1138 va_f1=0.5488 va_acc=0.9673 va_PRauc=0.6723 | 392.9s\n",
      "[unet_basic] Epoch 013 | tr_loss=0.0320 tr_f1=0.9012 tr_acc=0.9883 tr_PRauc=0.9582 || va_loss=0.1017 va_f1=0.5424 va_acc=0.9662 va_PRauc=0.6450 | 395.2s\n",
      "[unet_basic] Epoch 014 | tr_loss=0.0332 tr_f1=0.8998 tr_acc=0.9882 tr_PRauc=0.9555 || va_loss=0.1601 va_f1=0.3844 va_acc=0.9625 va_PRauc=0.6165 | 397.3s\n",
      "[unet_basic] Epoch 015 | tr_loss=0.0288 tr_f1=0.9116 tr_acc=0.9896 tr_PRauc=0.9658 || va_loss=0.0893 va_f1=0.6276 va_acc=0.9712 va_PRauc=0.7286 | 395.0s\n",
      "[unet_basic] Epoch 016 | tr_loss=0.0248 tr_f1=0.9238 tr_acc=0.9910 tr_PRauc=0.9743 || va_loss=0.0990 va_f1=0.5962 va_acc=0.9690 va_PRauc=0.7155 | 391.9s\n",
      "[unet_basic] Epoch 017 | tr_loss=0.0353 tr_f1=0.9004 tr_acc=0.9885 tr_PRauc=0.9555 || va_loss=0.1255 va_f1=0.5021 va_acc=0.9634 va_PRauc=0.5978 | 397.5s\n",
      "[unet_basic] Epoch 018 | tr_loss=0.0259 tr_f1=0.9192 tr_acc=0.9905 tr_PRauc=0.9722 || va_loss=0.1017 va_f1=0.6064 va_acc=0.9704 va_PRauc=0.7652 | 393.4s\n",
      "[unet_basic] Epoch 019 | tr_loss=0.0239 tr_f1=0.9264 tr_acc=0.9913 tr_PRauc=0.9755 || va_loss=0.0926 va_f1=0.6255 va_acc=0.9714 va_PRauc=0.7682 | 395.6s\n",
      "[unet_basic] Epoch 020 | tr_loss=0.0236 tr_f1=0.9269 tr_acc=0.9915 tr_PRauc=0.9774 || va_loss=0.1830 va_f1=0.3867 va_acc=0.9620 va_PRauc=0.5588 | 395.7s\n"
     ]
    }
   ],
   "source": [
    "BEST_PATH = \"/kaggle/working/deeplab-b4.pth\"\n",
    "best_val_f1 = -1\n",
    "\n",
    "import pandas as pd\n",
    "history = []\n",
    "\n",
    "for epoch in range(1, cfg.EPOCHS + 1):\n",
    "    t0 = time.time()\n",
    "\n",
    "    tr_loss, tr_prec, tr_rec, tr_f1, tr_acc, tr_auc = train_one_epoch(model, train_loader)\n",
    "    va_loss, va_prec, va_rec, va_f1, va_acc, va_auc = validate_epoch(model, val_loader, thr=0.5)\n",
    "    elapsed = time.time() - t0\n",
    "\n",
    "    print(\n",
    "        f\"[unet_basic] Epoch {epoch:03d} | \"\n",
    "        f\"tr_loss={tr_loss:.4f} tr_f1={tr_f1:.4f} tr_acc={tr_acc:.4f} tr_PRauc={tr_auc:.4f} || \"\n",
    "        f\"va_loss={va_loss:.4f} va_f1={va_f1:.4f} va_acc={va_acc:.4f} va_PRauc={va_auc:.4f} | \"\n",
    "        f\"{elapsed:.1f}s\"\n",
    "    )\n",
    "\n",
    "    history.append({\n",
    "        \"epoch\": epoch,\n",
    "    \n",
    "        \"tr_loss\": tr_loss,\n",
    "        \"tr_precision\": tr_prec,\n",
    "        \"tr_recall\": tr_rec,\n",
    "        \"tr_f1\": tr_f1,\n",
    "        \"tr_acc\": tr_acc,\n",
    "        \"tr_PRauc\": tr_auc,\n",
    "    \n",
    "        \"va_loss\": va_loss,\n",
    "        \"va_precision\": va_prec,\n",
    "        \"va_recall\": va_rec,\n",
    "        \"va_f1\": va_f1,\n",
    "        \"va_acc\": va_acc,\n",
    "        \"va_PRauc\": va_auc,\n",
    "    \n",
    "        \"seconds\": elapsed\n",
    "    })\n",
    "\n",
    "    if va_f1 > best_val_f1:\n",
    "        torch.save({\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"mean_13\": MEAN_13,\n",
    "            \"std_13\": STD_13,\n",
    "            \"epoch\": epoch,\n",
    "            \"best_val_f1\": best_val_f1,\n",
    "            \"va_auc\": va_auc,\n",
    "        }, BEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T15:56:16.207509Z",
     "iopub.status.busy": "2026-01-04T15:56:16.206822Z",
     "iopub.status.idle": "2026-01-04T15:56:16.251829Z",
     "shell.execute_reply": "2026-01-04T15:56:16.251068Z",
     "shell.execute_reply.started": "2026-01-04T15:56:16.207474Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: /kaggle/working/training_metrics_eff1.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>tr_loss</th>\n",
       "      <th>tr_precision</th>\n",
       "      <th>tr_recall</th>\n",
       "      <th>tr_f1</th>\n",
       "      <th>tr_acc</th>\n",
       "      <th>tr_PRauc</th>\n",
       "      <th>va_loss</th>\n",
       "      <th>va_precision</th>\n",
       "      <th>va_recall</th>\n",
       "      <th>va_f1</th>\n",
       "      <th>va_acc</th>\n",
       "      <th>va_PRauc</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2787</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.9346</td>\n",
       "      <td>0.0732</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2716</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.9520</td>\n",
       "      <td>0.2708</td>\n",
       "      <td>400.5822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.1921</td>\n",
       "      <td>0.5447</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.9413</td>\n",
       "      <td>0.2466</td>\n",
       "      <td>0.1187</td>\n",
       "      <td>0.6742</td>\n",
       "      <td>0.1959</td>\n",
       "      <td>0.3036</td>\n",
       "      <td>0.9570</td>\n",
       "      <td>0.4522</td>\n",
       "      <td>398.1763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.1787</td>\n",
       "      <td>0.5722</td>\n",
       "      <td>0.0704</td>\n",
       "      <td>0.1253</td>\n",
       "      <td>0.9422</td>\n",
       "      <td>0.3084</td>\n",
       "      <td>0.1315</td>\n",
       "      <td>0.5531</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.2604</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.3854</td>\n",
       "      <td>397.4950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.1535</td>\n",
       "      <td>0.6351</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>0.3014</td>\n",
       "      <td>0.9461</td>\n",
       "      <td>0.4321</td>\n",
       "      <td>0.1246</td>\n",
       "      <td>0.6158</td>\n",
       "      <td>0.2533</td>\n",
       "      <td>0.3589</td>\n",
       "      <td>0.9567</td>\n",
       "      <td>0.4470</td>\n",
       "      <td>397.5215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.1289</td>\n",
       "      <td>0.7196</td>\n",
       "      <td>0.3676</td>\n",
       "      <td>0.4866</td>\n",
       "      <td>0.9543</td>\n",
       "      <td>0.5793</td>\n",
       "      <td>0.1167</td>\n",
       "      <td>0.6239</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>0.3626</td>\n",
       "      <td>0.9570</td>\n",
       "      <td>0.4905</td>\n",
       "      <td>395.8892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.1054</td>\n",
       "      <td>0.7263</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.6396</td>\n",
       "      <td>0.9621</td>\n",
       "      <td>0.6848</td>\n",
       "      <td>0.1271</td>\n",
       "      <td>0.5392</td>\n",
       "      <td>0.3371</td>\n",
       "      <td>0.4148</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>0.4399</td>\n",
       "      <td>395.5895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0982</td>\n",
       "      <td>0.7982</td>\n",
       "      <td>0.5770</td>\n",
       "      <td>0.6698</td>\n",
       "      <td>0.9665</td>\n",
       "      <td>0.7423</td>\n",
       "      <td>0.1028</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.6553</td>\n",
       "      <td>0.6105</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.5962</td>\n",
       "      <td>395.6905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0741</td>\n",
       "      <td>0.8252</td>\n",
       "      <td>0.7330</td>\n",
       "      <td>0.7764</td>\n",
       "      <td>0.9751</td>\n",
       "      <td>0.8325</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>0.7076</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>0.2585</td>\n",
       "      <td>0.9566</td>\n",
       "      <td>0.5015</td>\n",
       "      <td>395.3123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.8587</td>\n",
       "      <td>0.7899</td>\n",
       "      <td>0.8228</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.8809</td>\n",
       "      <td>0.1388</td>\n",
       "      <td>0.5553</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.2001</td>\n",
       "      <td>0.9533</td>\n",
       "      <td>0.3915</td>\n",
       "      <td>395.4704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.8676</td>\n",
       "      <td>0.8366</td>\n",
       "      <td>0.8518</td>\n",
       "      <td>0.9829</td>\n",
       "      <td>0.9145</td>\n",
       "      <td>0.1009</td>\n",
       "      <td>0.8302</td>\n",
       "      <td>0.3444</td>\n",
       "      <td>0.4869</td>\n",
       "      <td>0.9653</td>\n",
       "      <td>0.6664</td>\n",
       "      <td>393.8328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0511</td>\n",
       "      <td>0.8714</td>\n",
       "      <td>0.8156</td>\n",
       "      <td>0.8426</td>\n",
       "      <td>0.9821</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>0.1139</td>\n",
       "      <td>0.7755</td>\n",
       "      <td>0.3376</td>\n",
       "      <td>0.4704</td>\n",
       "      <td>0.9636</td>\n",
       "      <td>0.6374</td>\n",
       "      <td>393.5670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>0.8474</td>\n",
       "      <td>0.8680</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9307</td>\n",
       "      <td>0.1138</td>\n",
       "      <td>0.8087</td>\n",
       "      <td>0.4153</td>\n",
       "      <td>0.5488</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.6723</td>\n",
       "      <td>392.9180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.0320</td>\n",
       "      <td>0.8990</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>0.9012</td>\n",
       "      <td>0.9883</td>\n",
       "      <td>0.9582</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.7675</td>\n",
       "      <td>0.4194</td>\n",
       "      <td>0.5424</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>0.6450</td>\n",
       "      <td>395.1558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.9019</td>\n",
       "      <td>0.8978</td>\n",
       "      <td>0.8998</td>\n",
       "      <td>0.9882</td>\n",
       "      <td>0.9555</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.8939</td>\n",
       "      <td>0.2448</td>\n",
       "      <td>0.3844</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.6165</td>\n",
       "      <td>397.2596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.0288</td>\n",
       "      <td>0.9157</td>\n",
       "      <td>0.9076</td>\n",
       "      <td>0.9116</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>0.9658</td>\n",
       "      <td>0.0893</td>\n",
       "      <td>0.8221</td>\n",
       "      <td>0.5075</td>\n",
       "      <td>0.6276</td>\n",
       "      <td>0.9712</td>\n",
       "      <td>0.7286</td>\n",
       "      <td>394.9645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.9208</td>\n",
       "      <td>0.9269</td>\n",
       "      <td>0.9238</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.7915</td>\n",
       "      <td>0.4782</td>\n",
       "      <td>0.5962</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>0.7155</td>\n",
       "      <td>391.9366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.9183</td>\n",
       "      <td>0.8831</td>\n",
       "      <td>0.9004</td>\n",
       "      <td>0.9885</td>\n",
       "      <td>0.9555</td>\n",
       "      <td>0.1255</td>\n",
       "      <td>0.7171</td>\n",
       "      <td>0.3862</td>\n",
       "      <td>0.5021</td>\n",
       "      <td>0.9634</td>\n",
       "      <td>0.5978</td>\n",
       "      <td>397.5494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.0259</td>\n",
       "      <td>0.9192</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9192</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.8351</td>\n",
       "      <td>0.4760</td>\n",
       "      <td>0.6064</td>\n",
       "      <td>0.9704</td>\n",
       "      <td>0.7652</td>\n",
       "      <td>393.4208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.9227</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>0.9264</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>0.8371</td>\n",
       "      <td>0.4993</td>\n",
       "      <td>0.6255</td>\n",
       "      <td>0.9714</td>\n",
       "      <td>0.7682</td>\n",
       "      <td>395.6118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.9334</td>\n",
       "      <td>0.9206</td>\n",
       "      <td>0.9269</td>\n",
       "      <td>0.9915</td>\n",
       "      <td>0.9774</td>\n",
       "      <td>0.1830</td>\n",
       "      <td>0.8477</td>\n",
       "      <td>0.2505</td>\n",
       "      <td>0.3867</td>\n",
       "      <td>0.9620</td>\n",
       "      <td>0.5588</td>\n",
       "      <td>395.7344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  tr_loss  tr_precision  tr_recall   tr_f1  tr_acc  tr_PRauc  \\\n",
       "0       1   0.2787        0.0753     0.0098  0.0174  0.9346    0.0732   \n",
       "1       2   0.1921        0.5447     0.0166  0.0322  0.9413    0.2466   \n",
       "2       3   0.1787        0.5722     0.0704  0.1253  0.9422    0.3084   \n",
       "3       4   0.1535        0.6351     0.1975  0.3014  0.9461    0.4321   \n",
       "4       5   0.1289        0.7196     0.3676  0.4866  0.9543    0.5793   \n",
       "5       6   0.1054        0.7263     0.5714  0.6396  0.9621    0.6848   \n",
       "6       7   0.0982        0.7982     0.5770  0.6698  0.9665    0.7423   \n",
       "7       8   0.0741        0.8252     0.7330  0.7764  0.9751    0.8325   \n",
       "8       9   0.0600        0.8587     0.7899  0.8228  0.9800    0.8809   \n",
       "9      10   0.0485        0.8676     0.8366  0.8518  0.9829    0.9145   \n",
       "10     11   0.0511        0.8714     0.8156  0.8426  0.9821    0.9100   \n",
       "11     12   0.0445        0.8895     0.8474  0.8680  0.9848    0.9307   \n",
       "12     13   0.0320        0.8990     0.9034  0.9012  0.9883    0.9582   \n",
       "13     14   0.0332        0.9019     0.8978  0.8998  0.9882    0.9555   \n",
       "14     15   0.0288        0.9157     0.9076  0.9116  0.9896    0.9658   \n",
       "15     16   0.0248        0.9208     0.9269  0.9238  0.9910    0.9743   \n",
       "16     17   0.0353        0.9183     0.8831  0.9004  0.9885    0.9555   \n",
       "17     18   0.0259        0.9192     0.9193  0.9192  0.9905    0.9722   \n",
       "18     19   0.0239        0.9227     0.9300  0.9264  0.9913    0.9755   \n",
       "19     20   0.0236        0.9334     0.9206  0.9269  0.9915    0.9774   \n",
       "\n",
       "    va_loss  va_precision  va_recall   va_f1  va_acc  va_PRauc   seconds  \n",
       "0    0.1667        0.2716     0.0020  0.0040  0.9520    0.2708  400.5822  \n",
       "1    0.1187        0.6742     0.1959  0.3036  0.9570    0.4522  398.1763  \n",
       "2    0.1315        0.5531     0.1703  0.2604  0.9537    0.3854  397.4950  \n",
       "3    0.1246        0.6158     0.2533  0.3589  0.9567    0.4470  397.5215  \n",
       "4    0.1167        0.6239     0.2556  0.3626  0.9570    0.4905  395.8892  \n",
       "5    0.1271        0.5392     0.3371  0.4148  0.9545    0.4399  395.5895  \n",
       "6    0.1028        0.5714     0.6553  0.6105  0.9600    0.5962  395.6905  \n",
       "7    0.1240        0.7076     0.1581  0.2585  0.9566    0.5015  395.3123  \n",
       "8    0.1388        0.5553     0.1220  0.2001  0.9533    0.3915  395.4704  \n",
       "9    0.1009        0.8302     0.3444  0.4869  0.9653    0.6664  393.8328  \n",
       "10   0.1139        0.7755     0.3376  0.4704  0.9636    0.6374  393.5670  \n",
       "11   0.1138        0.8087     0.4153  0.5488  0.9673    0.6723  392.9180  \n",
       "12   0.1017        0.7675     0.4194  0.5424  0.9662    0.6450  395.1558  \n",
       "13   0.1601        0.8939     0.2448  0.3844  0.9625    0.6165  397.2596  \n",
       "14   0.0893        0.8221     0.5075  0.6276  0.9712    0.7286  394.9645  \n",
       "15   0.0990        0.7915     0.4782  0.5962  0.9690    0.7155  391.9366  \n",
       "16   0.1255        0.7171     0.3862  0.5021  0.9634    0.5978  397.5494  \n",
       "17   0.1017        0.8351     0.4760  0.6064  0.9704    0.7652  393.4208  \n",
       "18   0.0926        0.8371     0.4993  0.6255  0.9714    0.7682  395.6118  \n",
       "19   0.1830        0.8477     0.2505  0.3867  0.9620    0.5588  395.7344  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_history = pd.DataFrame(history)\n",
    "\n",
    "df_history = df_history.round(4)\n",
    "csv_path = \"/kaggle/working/training_metrics_eff1.csv\"\n",
    "df_history.to_csv(csv_path, index=False)\n",
    "print(\"Saved to:\", csv_path)\n",
    "df_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T15:43:35.806535Z",
     "iopub.status.busy": "2026-01-04T15:43:35.805786Z",
     "iopub.status.idle": "2026-01-04T15:46:18.682375Z",
     "shell.execute_reply": "2026-01-04T15:46:18.681470Z",
     "shell.execute_reply.started": "2026-01-04T15:43:35.806498Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen threshold: 0.05\n",
      "Best global F1: 0.521013327039667\n",
      "Top-5 thresholds:\n",
      "0.05 0.521013327039667\n",
      "0.1 0.4976343547287141\n",
      "0.15 0.480017006184065\n",
      "0.2 0.4646291311364695\n",
      "0.25 0.4503687547885739\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def find_best_thr_global_f1(model, loader, grid=None, eps=1e-6):\n",
    "    model.eval()\n",
    "    if grid is None:\n",
    "        grid = np.linspace(0.05, 0.95, 19)\n",
    "\n",
    "    best_thr = None\n",
    "    best_f1 = -1\n",
    "    log = []\n",
    "\n",
    "    for thr in grid:\n",
    "        total_tp = total_fp = total_fn = 0.0\n",
    "\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            x = normalize_batch(x, MEAN_13, STD_13)\n",
    "\n",
    "            logits = model(x)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs >= thr).float()\n",
    "\n",
    "            total_tp += (preds * y).sum().item()\n",
    "            total_fp += (preds * (1 - y)).sum().item()\n",
    "            total_fn += ((1 - preds) * y).sum().item()\n",
    "\n",
    "        precision = (total_tp + eps) / (total_tp + total_fp + eps)\n",
    "        recall    = (total_tp + eps) / (total_tp + total_fn + eps)\n",
    "        f1        = (2 * precision * recall) / (precision + recall + eps)\n",
    "\n",
    "        log.append((float(thr), f1))\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_thr = float(thr)\n",
    "\n",
    "    return best_thr, best_f1, log\n",
    "\n",
    "t_best, best_f1, thr_log = find_best_thr_global_f1(model, val_loader)\n",
    "\n",
    "print(\"Chosen threshold:\", t_best)\n",
    "print(\"Best global F1:\", best_f1)\n",
    "\n",
    "print(\"Top-5 thresholds:\")\n",
    "for thr, f1 in sorted(thr_log, key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print(thr, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T15:49:58.604855Z",
     "iopub.status.busy": "2026-01-04T15:49:58.604245Z",
     "iopub.status.idle": "2026-01-04T15:50:27.233974Z",
     "shell.execute_reply": "2026-01-04T15:50:27.233191Z",
     "shell.execute_reply.started": "2026-01-04T15:49:58.604818Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss   : 0.0674\n",
      "Test Prec   : 0.4625\n",
      "Test Recall : 0.6308\n",
      "Test F1     : 0.5337\n",
      "Test Acc    : 0.9732\n",
      "Test PRauc    : 0.5996\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_prec, test_rec, test_f1, test_acc, test_auc = validate_epoch(\n",
    "    model, test_loader, thr=t_best\n",
    ")\n",
    "\n",
    "print(f\"Test Loss   : {test_loss:.4f}\")\n",
    "print(f\"Test Prec   : {test_prec:.4f}\")\n",
    "print(f\"Test Recall : {test_rec:.4f}\")\n",
    "print(f\"Test F1     : {test_f1:.4f}\")\n",
    "print(f\"Test Acc    : {test_acc:.4f}\")\n",
    "print(f\"Test PRauc  : {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RECALL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T19:39:50.881400Z",
     "iopub.status.busy": "2026-01-05T19:39:50.881116Z",
     "iopub.status.idle": "2026-01-05T19:39:51.969037Z",
     "shell.execute_reply": "2026-01-05T19:39:51.968425Z",
     "shell.execute_reply.started": "2026-01-05T19:39:50.881378Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load(\n",
    "    \"/kaggle/input/deeplab-b4/pytorch/default/1/deeplab-b4.pth\",\n",
    "    map_location=DEVICE,\n",
    "    weights_only=False\n",
    ")\n",
    "model.load_state_dict(ckpt[\"model_state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cfg.EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T19:40:57.140018Z",
     "iopub.status.busy": "2026-01-05T19:40:57.139265Z",
     "iopub.status.idle": "2026-01-05T19:40:57.753457Z",
     "shell.execute_reply": "2026-01-05T19:40:57.752879Z",
     "shell.execute_reply.started": "2026-01-05T19:40:57.139989Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.amp import autocast, GradScaler\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cfg.LR)\n",
    "scaler = GradScaler(enabled=(DEVICE.type == \"cuda\"))\n",
    "\n",
    "def train_one_epoch(model, loader, thr=0.05, eps=1e-6):\n",
    "    model.train()\n",
    "    total_loss_sum = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    total_tp = total_fp = total_fn = total_tn = 0.0\n",
    "    all_probs, all_targets = [], []\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        x = normalize_batch(x, MEAN_13, STD_13)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with autocast(\"cuda\", enabled=(DEVICE.type == \"cuda\")):\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        bs = x.size(0)\n",
    "        total_loss_sum += loss.item() * bs\n",
    "        total_samples += bs\n",
    "\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= thr).float()\n",
    "\n",
    "        total_tp += (preds * y).sum().item()\n",
    "        total_fp += (preds * (1 - y)).sum().item()\n",
    "        total_fn += ((1 - preds) * y).sum().item()\n",
    "        total_tn += ((1 - preds) * (1 - y)).sum().item()\n",
    "\n",
    "        all_probs.append(probs.flatten().detach().cpu())\n",
    "        all_targets.append(y.flatten().detach().cpu())\n",
    "\n",
    "    precision = (total_tp + eps) / (total_tp + total_fp + eps)\n",
    "    recall    = (total_tp + eps) / (total_tp + total_fn + eps)\n",
    "    f1        = (2 * precision * recall) / (precision + recall + eps)\n",
    "    acc       = (total_tp + total_tn + eps) / (\n",
    "        total_tp + total_tn + total_fp + total_fn + eps\n",
    "    )\n",
    "\n",
    "    all_probs = torch.cat(all_probs).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "    auc = average_precision_score(all_targets, all_probs)\n",
    "\n",
    "    loss_global = total_loss_sum / total_samples\n",
    "\n",
    "    return loss_global, precision, recall, f1, acc, auc\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_epoch(model, loader, thr=0.05, eps=1e-6):\n",
    "    model.eval()\n",
    "    total_loss_sum = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    total_tp = total_fp = total_fn = total_tn = 0.0\n",
    "    all_probs, all_targets = [], []\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        x = normalize_batch(x, MEAN_13, STD_13)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        bs = x.size(0)\n",
    "        total_loss_sum += loss.item() * bs\n",
    "        total_samples += bs\n",
    "\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= thr).float()\n",
    "\n",
    "        total_tp += (preds * y).sum().item()\n",
    "        total_fp += (preds * (1 - y)).sum().item()\n",
    "        total_fn += ((1 - preds) * y).sum().item()\n",
    "        total_tn += ((1 - preds) * (1 - y)).sum().item()\n",
    "\n",
    "        all_probs.append(probs.flatten().cpu())\n",
    "        all_targets.append(y.flatten().cpu())\n",
    "\n",
    "    precision = (total_tp + eps) / (total_tp + total_fp + eps)\n",
    "    recall    = (total_tp + eps) / (total_tp + total_fn + eps)\n",
    "    f1        = (2 * precision * recall) / (precision + recall + eps)\n",
    "    acc       = (total_tp + total_tn + eps) / (\n",
    "        total_tp + total_tn + total_fp + total_fn + eps\n",
    "    )\n",
    "\n",
    "    all_probs = torch.cat(all_probs).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "    auc = average_precision_score(all_targets, all_probs)\n",
    "\n",
    "    loss_global = total_loss_sum / total_samples\n",
    "\n",
    "    return loss_global, precision, recall, f1, acc, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T19:41:46.351221Z",
     "iopub.status.busy": "2026-01-05T19:41:46.350727Z",
     "iopub.status.idle": "2026-01-05T21:53:32.796438Z",
     "shell.execute_reply": "2026-01-05T21:53:32.795238Z",
     "shell.execute_reply.started": "2026-01-05T19:41:46.351193Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[unet_basic] Epoch 001 | tr_loss=0.0282 tr_f1=0.8703 tr_acc=0.9830 tr_PRauc=0.9715 || va_loss=0.1165 va_f1=0.6579 va_acc=0.9662 va_PRauc=0.7152 | 392.1s\n",
      "[unet_basic] Epoch 002 | tr_loss=0.0220 tr_f1=0.8763 tr_acc=0.9836 tr_PRauc=0.9805 || va_loss=0.1282 va_f1=0.6580 va_acc=0.9676 va_PRauc=0.7085 | 391.5s\n",
      "[unet_basic] Epoch 003 | tr_loss=0.0241 tr_f1=0.8520 tr_acc=0.9799 tr_PRauc=0.9769 || va_loss=0.1134 va_f1=0.6196 va_acc=0.9588 va_PRauc=0.6562 | 394.7s\n",
      "[unet_basic] Epoch 004 | tr_loss=0.0235 tr_f1=0.8442 tr_acc=0.9785 tr_PRauc=0.9780 || va_loss=0.1180 va_f1=0.6726 va_acc=0.9689 va_PRauc=0.7331 | 393.0s\n",
      "[unet_basic] Epoch 005 | tr_loss=0.0148 tr_f1=0.9081 tr_acc=0.9882 tr_PRauc=0.9906 || va_loss=0.1761 va_f1=0.5800 va_acc=0.9689 va_PRauc=0.7194 | 393.4s\n",
      "[unet_basic] Epoch 006 | tr_loss=0.0124 tr_f1=0.9206 tr_acc=0.9899 tr_PRauc=0.9935 || va_loss=0.1515 va_f1=0.6198 va_acc=0.9686 va_PRauc=0.7009 | 392.6s\n",
      "[unet_basic] Epoch 007 | tr_loss=0.0136 tr_f1=0.9147 tr_acc=0.9891 tr_PRauc=0.9922 || va_loss=0.1451 va_f1=0.6594 va_acc=0.9723 va_PRauc=0.7504 | 395.6s\n",
      "[unet_basic] Epoch 008 | tr_loss=0.0117 tr_f1=0.9271 tr_acc=0.9908 tr_PRauc=0.9940 || va_loss=0.2420 va_f1=0.4315 va_acc=0.9641 va_PRauc=0.7093 | 396.6s\n",
      "[unet_basic] Epoch 009 | tr_loss=0.0112 tr_f1=0.9292 tr_acc=0.9911 tr_PRauc=0.9946 || va_loss=0.2883 va_f1=0.3030 va_acc=0.9585 va_PRauc=0.4987 | 395.3s\n",
      "[unet_basic] Epoch 010 | tr_loss=0.0110 tr_f1=0.9312 tr_acc=0.9913 tr_PRauc=0.9946 || va_loss=0.1712 va_f1=0.6337 va_acc=0.9696 va_PRauc=0.6912 | 397.4s\n",
      "[unet_basic] Epoch 011 | tr_loss=0.0135 tr_f1=0.9138 tr_acc=0.9890 tr_PRauc=0.9919 || va_loss=0.1780 va_f1=0.6024 va_acc=0.9692 va_PRauc=0.6931 | 395.9s\n",
      "[unet_basic] Epoch 012 | tr_loss=0.0134 tr_f1=0.9143 tr_acc=0.9890 tr_PRauc=0.9923 || va_loss=0.2072 va_f1=0.5679 va_acc=0.9696 va_PRauc=0.7501 | 398.1s\n",
      "[unet_basic] Epoch 013 | tr_loss=0.0108 tr_f1=0.9271 tr_acc=0.9908 tr_PRauc=0.9949 || va_loss=0.1554 va_f1=0.6742 va_acc=0.9736 va_PRauc=0.7779 | 394.1s\n",
      "[unet_basic] Epoch 014 | tr_loss=0.0087 tr_f1=0.9416 tr_acc=0.9927 tr_PRauc=0.9967 || va_loss=0.2016 va_f1=0.5827 va_acc=0.9689 va_PRauc=0.7085 | 395.1s\n",
      "[unet_basic] Epoch 015 | tr_loss=0.0078 tr_f1=0.9472 tr_acc=0.9934 tr_PRauc=0.9973 || va_loss=0.1272 va_f1=0.7100 va_acc=0.9739 va_PRauc=0.7723 | 395.9s\n",
      "[unet_basic] Epoch 016 | tr_loss=0.0074 tr_f1=0.9518 tr_acc=0.9941 tr_PRauc=0.9975 || va_loss=0.1724 va_f1=0.6731 va_acc=0.9746 va_PRauc=0.7730 | 398.4s\n",
      "[unet_basic] Epoch 017 | tr_loss=0.0105 tr_f1=0.9399 tr_acc=0.9925 tr_PRauc=0.9953 || va_loss=0.1480 va_f1=0.6496 va_acc=0.9674 va_PRauc=0.7091 | 395.8s\n",
      "[unet_basic] Epoch 018 | tr_loss=0.0081 tr_f1=0.9441 tr_acc=0.9931 tr_PRauc=0.9969 || va_loss=0.1312 va_f1=0.7445 va_acc=0.9770 va_PRauc=0.7976 | 394.4s\n",
      "[unet_basic] Epoch 019 | tr_loss=0.0110 tr_f1=0.9285 tr_acc=0.9910 tr_PRauc=0.9948 || va_loss=0.2057 va_f1=0.5673 va_acc=0.9621 va_PRauc=0.6139 | 393.1s\n",
      "[unet_basic] Epoch 020 | tr_loss=0.0247 tr_f1=0.8761 tr_acc=0.9837 tr_PRauc=0.9764 || va_loss=0.1633 va_f1=0.6682 va_acc=0.9725 va_PRauc=0.7164 | 399.4s\n"
     ]
    }
   ],
   "source": [
    "BEST_PATH = \"/kaggle/working/deeplab_pretrained.pth\"\n",
    "best_val_f1 = -1\n",
    "\n",
    "import pandas as pd\n",
    "history = []\n",
    "\n",
    "for epoch in range(1, cfg.EPOCHS + 1):\n",
    "    t0 = time.time()\n",
    "\n",
    "    tr_loss, tr_prec, tr_rec, tr_f1, tr_acc, tr_auc = train_one_epoch(model, train_loader)\n",
    "    va_loss, va_prec, va_rec, va_f1, va_acc, va_auc = validate_epoch(model, val_loader)\n",
    "    elapsed = time.time() - t0\n",
    "\n",
    "    print(\n",
    "        f\"[unet_basic] Epoch {epoch:03d} | \"\n",
    "        f\"tr_loss={tr_loss:.4f} tr_f1={tr_f1:.4f} tr_acc={tr_acc:.4f} tr_PRauc={tr_auc:.4f} || \"\n",
    "        f\"va_loss={va_loss:.4f} va_f1={va_f1:.4f} va_acc={va_acc:.4f} va_PRauc={va_auc:.4f} | \"\n",
    "        f\"{elapsed:.1f}s\"\n",
    "    )\n",
    "\n",
    "    history.append({\n",
    "        \"epoch\": epoch,\n",
    "    \n",
    "        \"tr_loss\": tr_loss,\n",
    "        \"tr_precision\": tr_prec,\n",
    "        \"tr_recall\": tr_rec,\n",
    "        \"tr_f1\": tr_f1,\n",
    "        \"tr_acc\": tr_acc,\n",
    "        \"tr_PRauc\": tr_auc,\n",
    "    \n",
    "        \"va_loss\": va_loss,\n",
    "        \"va_precision\": va_prec,\n",
    "        \"va_recall\": va_rec,\n",
    "        \"va_f1\": va_f1,\n",
    "        \"va_acc\": va_acc,\n",
    "        \"va_PRauc\": va_auc,\n",
    "    \n",
    "        \"seconds\": elapsed\n",
    "    })\n",
    "\n",
    "    if va_f1 > best_val_f1:\n",
    "        torch.save({\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"mean_13\": MEAN_13,\n",
    "            \"std_13\": STD_13,\n",
    "            \"epoch\": epoch,\n",
    "            \"best_val_f1\": best_val_f1,\n",
    "            \"va_auc\": va_auc,\n",
    "        }, BEST_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T21:53:32.799312Z",
     "iopub.status.busy": "2026-01-05T21:53:32.798944Z",
     "iopub.status.idle": "2026-01-05T21:53:32.854795Z",
     "shell.execute_reply": "2026-01-05T21:53:32.853955Z",
     "shell.execute_reply.started": "2026-01-05T21:53:32.799278Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: /kaggle/working/training_metrics_eff1.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>tr_loss</th>\n",
       "      <th>tr_precision</th>\n",
       "      <th>tr_recall</th>\n",
       "      <th>tr_f1</th>\n",
       "      <th>tr_acc</th>\n",
       "      <th>tr_PRauc</th>\n",
       "      <th>va_loss</th>\n",
       "      <th>va_precision</th>\n",
       "      <th>va_recall</th>\n",
       "      <th>va_f1</th>\n",
       "      <th>va_acc</th>\n",
       "      <th>va_PRauc</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.7888</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>0.8703</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>0.9715</td>\n",
       "      <td>0.1165</td>\n",
       "      <td>0.6376</td>\n",
       "      <td>0.6795</td>\n",
       "      <td>0.6579</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>0.7152</td>\n",
       "      <td>392.0918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.7874</td>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.8763</td>\n",
       "      <td>0.9836</td>\n",
       "      <td>0.9805</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>0.6646</td>\n",
       "      <td>0.6515</td>\n",
       "      <td>0.6580</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.7085</td>\n",
       "      <td>391.4926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.7516</td>\n",
       "      <td>0.9834</td>\n",
       "      <td>0.8520</td>\n",
       "      <td>0.9799</td>\n",
       "      <td>0.9769</td>\n",
       "      <td>0.1134</td>\n",
       "      <td>0.5544</td>\n",
       "      <td>0.7023</td>\n",
       "      <td>0.6196</td>\n",
       "      <td>0.9588</td>\n",
       "      <td>0.6562</td>\n",
       "      <td>394.6945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0235</td>\n",
       "      <td>0.7375</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.8442</td>\n",
       "      <td>0.9785</td>\n",
       "      <td>0.9780</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.6682</td>\n",
       "      <td>0.6726</td>\n",
       "      <td>0.9689</td>\n",
       "      <td>0.7331</td>\n",
       "      <td>393.0280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.8360</td>\n",
       "      <td>0.9937</td>\n",
       "      <td>0.9081</td>\n",
       "      <td>0.9882</td>\n",
       "      <td>0.9906</td>\n",
       "      <td>0.1761</td>\n",
       "      <td>0.8169</td>\n",
       "      <td>0.4496</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>0.9689</td>\n",
       "      <td>0.7194</td>\n",
       "      <td>393.3645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.8567</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>0.9206</td>\n",
       "      <td>0.9899</td>\n",
       "      <td>0.9935</td>\n",
       "      <td>0.1515</td>\n",
       "      <td>0.7370</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>0.6198</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>0.7009</td>\n",
       "      <td>392.6385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.8469</td>\n",
       "      <td>0.9943</td>\n",
       "      <td>0.9147</td>\n",
       "      <td>0.9891</td>\n",
       "      <td>0.9922</td>\n",
       "      <td>0.1451</td>\n",
       "      <td>0.8007</td>\n",
       "      <td>0.5604</td>\n",
       "      <td>0.6594</td>\n",
       "      <td>0.9723</td>\n",
       "      <td>0.7504</td>\n",
       "      <td>395.6485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.8671</td>\n",
       "      <td>0.9962</td>\n",
       "      <td>0.9271</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>0.2420</td>\n",
       "      <td>0.8893</td>\n",
       "      <td>0.2849</td>\n",
       "      <td>0.4315</td>\n",
       "      <td>0.9641</td>\n",
       "      <td>0.7093</td>\n",
       "      <td>396.6417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.8715</td>\n",
       "      <td>0.9952</td>\n",
       "      <td>0.9292</td>\n",
       "      <td>0.9911</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>0.2883</td>\n",
       "      <td>0.7727</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.9585</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>395.3366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.8748</td>\n",
       "      <td>0.9952</td>\n",
       "      <td>0.9312</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>0.1712</td>\n",
       "      <td>0.7476</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.6337</td>\n",
       "      <td>0.9696</td>\n",
       "      <td>0.6912</td>\n",
       "      <td>397.3984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.8461</td>\n",
       "      <td>0.9932</td>\n",
       "      <td>0.9138</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.9919</td>\n",
       "      <td>0.1780</td>\n",
       "      <td>0.7887</td>\n",
       "      <td>0.4873</td>\n",
       "      <td>0.6024</td>\n",
       "      <td>0.9692</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>395.9301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.8462</td>\n",
       "      <td>0.9942</td>\n",
       "      <td>0.9143</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.9923</td>\n",
       "      <td>0.2072</td>\n",
       "      <td>0.8865</td>\n",
       "      <td>0.4178</td>\n",
       "      <td>0.5679</td>\n",
       "      <td>0.9696</td>\n",
       "      <td>0.7501</td>\n",
       "      <td>398.0835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.8676</td>\n",
       "      <td>0.9954</td>\n",
       "      <td>0.9271</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>0.1554</td>\n",
       "      <td>0.8238</td>\n",
       "      <td>0.5705</td>\n",
       "      <td>0.6742</td>\n",
       "      <td>0.9736</td>\n",
       "      <td>0.7779</td>\n",
       "      <td>394.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.8922</td>\n",
       "      <td>0.9969</td>\n",
       "      <td>0.9416</td>\n",
       "      <td>0.9927</td>\n",
       "      <td>0.9967</td>\n",
       "      <td>0.2016</td>\n",
       "      <td>0.8135</td>\n",
       "      <td>0.4539</td>\n",
       "      <td>0.5827</td>\n",
       "      <td>0.9689</td>\n",
       "      <td>0.7085</td>\n",
       "      <td>395.1081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.9020</td>\n",
       "      <td>0.9971</td>\n",
       "      <td>0.9472</td>\n",
       "      <td>0.9934</td>\n",
       "      <td>0.9973</td>\n",
       "      <td>0.1272</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>0.6679</td>\n",
       "      <td>0.7100</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.7723</td>\n",
       "      <td>395.9240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.9102</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>0.9518</td>\n",
       "      <td>0.9941</td>\n",
       "      <td>0.9975</td>\n",
       "      <td>0.1724</td>\n",
       "      <td>0.8743</td>\n",
       "      <td>0.5473</td>\n",
       "      <td>0.6731</td>\n",
       "      <td>0.9746</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>398.3971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.8929</td>\n",
       "      <td>0.9922</td>\n",
       "      <td>0.9399</td>\n",
       "      <td>0.9925</td>\n",
       "      <td>0.9953</td>\n",
       "      <td>0.1480</td>\n",
       "      <td>0.6694</td>\n",
       "      <td>0.6309</td>\n",
       "      <td>0.6496</td>\n",
       "      <td>0.9674</td>\n",
       "      <td>0.7091</td>\n",
       "      <td>395.7861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.8973</td>\n",
       "      <td>0.9960</td>\n",
       "      <td>0.9441</td>\n",
       "      <td>0.9931</td>\n",
       "      <td>0.9969</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.7962</td>\n",
       "      <td>0.6991</td>\n",
       "      <td>0.7445</td>\n",
       "      <td>0.9770</td>\n",
       "      <td>0.7976</td>\n",
       "      <td>394.4499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.8726</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.9285</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>0.9948</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>0.6259</td>\n",
       "      <td>0.5188</td>\n",
       "      <td>0.5673</td>\n",
       "      <td>0.9621</td>\n",
       "      <td>0.6139</td>\n",
       "      <td>393.0731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>0.7951</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>0.8761</td>\n",
       "      <td>0.9837</td>\n",
       "      <td>0.9764</td>\n",
       "      <td>0.1633</td>\n",
       "      <td>0.7902</td>\n",
       "      <td>0.5788</td>\n",
       "      <td>0.6682</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.7164</td>\n",
       "      <td>399.3538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  tr_loss  tr_precision  tr_recall   tr_f1  tr_acc  tr_PRauc  \\\n",
       "0       1   0.0282        0.7888     0.9706  0.8703  0.9830    0.9715   \n",
       "1       2   0.0220        0.7874     0.9877  0.8763  0.9836    0.9805   \n",
       "2       3   0.0241        0.7516     0.9834  0.8520  0.9799    0.9769   \n",
       "3       4   0.0235        0.7375     0.9871  0.8442  0.9785    0.9780   \n",
       "4       5   0.0148        0.8360     0.9937  0.9081  0.9882    0.9906   \n",
       "5       6   0.0124        0.8567     0.9949  0.9206  0.9899    0.9935   \n",
       "6       7   0.0136        0.8469     0.9943  0.9147  0.9891    0.9922   \n",
       "7       8   0.0117        0.8671     0.9962  0.9271  0.9908    0.9940   \n",
       "8       9   0.0112        0.8715     0.9952  0.9292  0.9911    0.9946   \n",
       "9      10   0.0110        0.8748     0.9952  0.9312  0.9913    0.9946   \n",
       "10     11   0.0135        0.8461     0.9932  0.9138  0.9890    0.9919   \n",
       "11     12   0.0134        0.8462     0.9942  0.9143  0.9890    0.9923   \n",
       "12     13   0.0108        0.8676     0.9954  0.9271  0.9908    0.9949   \n",
       "13     14   0.0087        0.8922     0.9969  0.9416  0.9927    0.9967   \n",
       "14     15   0.0078        0.9020     0.9971  0.9472  0.9934    0.9973   \n",
       "15     16   0.0074        0.9102     0.9974  0.9518  0.9941    0.9975   \n",
       "16     17   0.0105        0.8929     0.9922  0.9399  0.9925    0.9953   \n",
       "17     18   0.0081        0.8973     0.9960  0.9441  0.9931    0.9969   \n",
       "18     19   0.0110        0.8726     0.9920  0.9285  0.9910    0.9948   \n",
       "19     20   0.0247        0.7951     0.9755  0.8761  0.9837    0.9764   \n",
       "\n",
       "    va_loss  va_precision  va_recall   va_f1  va_acc  va_PRauc   seconds  \n",
       "0    0.1165        0.6376     0.6795  0.6579  0.9662    0.7152  392.0918  \n",
       "1    0.1282        0.6646     0.6515  0.6580  0.9676    0.7085  391.4926  \n",
       "2    0.1134        0.5544     0.7023  0.6196  0.9588    0.6562  394.6945  \n",
       "3    0.1180        0.6770     0.6682  0.6726  0.9689    0.7331  393.0280  \n",
       "4    0.1761        0.8169     0.4496  0.5800  0.9689    0.7194  393.3645  \n",
       "5    0.1515        0.7370     0.5347  0.6198  0.9686    0.7009  392.6385  \n",
       "6    0.1451        0.8007     0.5604  0.6594  0.9723    0.7504  395.6485  \n",
       "7    0.2420        0.8893     0.2849  0.4315  0.9641    0.7093  396.6417  \n",
       "8    0.2883        0.7727     0.1885  0.3030  0.9585    0.4987  395.3366  \n",
       "9    0.1712        0.7476     0.5500  0.6337  0.9696    0.6912  397.3984  \n",
       "10   0.1780        0.7887     0.4873  0.6024  0.9692    0.6931  395.9301  \n",
       "11   0.2072        0.8865     0.4178  0.5679  0.9696    0.7501  398.0835  \n",
       "12   0.1554        0.8238     0.5705  0.6742  0.9736    0.7779  394.1250  \n",
       "13   0.2016        0.8135     0.4539  0.5827  0.9689    0.7085  395.1081  \n",
       "14   0.1272        0.7579     0.6679  0.7100  0.9739    0.7723  395.9240  \n",
       "15   0.1724        0.8743     0.5473  0.6731  0.9746    0.7730  398.3971  \n",
       "16   0.1480        0.6694     0.6309  0.6496  0.9674    0.7091  395.7861  \n",
       "17   0.1312        0.7962     0.6991  0.7445  0.9770    0.7976  394.4499  \n",
       "18   0.2057        0.6259     0.5188  0.5673  0.9621    0.6139  393.0731  \n",
       "19   0.1633        0.7902     0.5788  0.6682  0.9725    0.7164  399.3538  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_history = pd.DataFrame(history)\n",
    "\n",
    "df_history = df_history.round(4)\n",
    "csv_path = \"/kaggle/working/training_metrics_eff1.csv\"\n",
    "df_history.to_csv(csv_path, index=False)\n",
    "print(\"Saved to:\", csv_path)\n",
    "df_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T21:53:32.856572Z",
     "iopub.status.busy": "2026-01-05T21:53:32.855899Z",
     "iopub.status.idle": "2026-01-05T21:54:03.027505Z",
     "shell.execute_reply": "2026-01-05T21:54:03.026779Z",
     "shell.execute_reply.started": "2026-01-05T21:53:32.856546Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss   : 0.0693\n",
      "Test Prec   : 0.5757\n",
      "Test Recall : 0.6979\n",
      "Test F1     : 0.6309\n",
      "Test Acc    : 0.9802\n",
      "Test PRauc  : 0.6572\n"
     ]
    }
   ],
   "source": [
    "t_best=0.05\n",
    "test_loss, test_prec, test_rec, test_f1, test_acc, test_auc = validate_epoch(\n",
    "    model, test_loader, thr=t_best\n",
    ")\n",
    "\n",
    "print(f\"Test Loss   : {test_loss:.4f}\")\n",
    "print(f\"Test Prec   : {test_prec:.4f}\")\n",
    "print(f\"Test Recall : {test_rec:.4f}\")\n",
    "print(f\"Test F1     : {test_f1:.4f}\")\n",
    "print(f\"Test Acc    : {test_acc:.4f}\")\n",
    "print(f\"Test PRauc  : {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8507641,
     "sourceId": 14342736,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 551707,
     "modelInstanceId": 538416,
     "sourceId": 708904,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
