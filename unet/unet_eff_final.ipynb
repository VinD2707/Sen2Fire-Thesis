{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-03T19:13:41.641663Z",
     "iopub.status.busy": "2026-01-03T19:13:41.640715Z",
     "iopub.status.idle": "2026-01-03T19:13:45.525895Z",
     "shell.execute_reply": "2026-01-03T19:13:45.525157Z",
     "shell.execute_reply.started": "2026-01-03T19:13:41.641627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "DATA_ROOT OK: /kaggle/input/sen2fire/Sen2Fire/Sen2Fire\n"
     ]
    }
   ],
   "source": [
    "import os, glob, random, json\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ----------------------------\n",
    "# Reproducibility\n",
    "# ----------------------------\n",
    "def seed_everything(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "SEED = 24\n",
    "seed_everything(SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "@dataclass\n",
    "class CFG:\n",
    "    DATA_ROOT: str = \"/kaggle/input/sen2fire/Sen2Fire/Sen2Fire\"\n",
    "    SCENES: Tuple[str, ...] = (\"scene1\", \"scene2\", \"scene3\", \"scene4\")\n",
    "    PATCH_EXT: str = \".npz\"\n",
    "\n",
    "    # Global split (VD default)\n",
    "    USE_GLOBAL_SPLIT: bool = True\n",
    "    GLOBAL_TRAIN_RATIO: float = 0.80\n",
    "    GLOBAL_VAL_RATIO: float = 0.10\n",
    "    GLOBAL_TEST_RATIO: float = 0.10\n",
    "    KEEP_VAL_TEST_NATURAL: bool = True\n",
    "\n",
    "    # Keys inside npz\n",
    "    X_KEY: str = \"image\"     # (12,512,512)\n",
    "    A_KEY: str = \"aerosol\"   # (512,512) -> becomes 1 channel\n",
    "    Y_KEY: str = \"label\"     # (512,512)\n",
    "\n",
    "    # Fire patch definition\n",
    "    FIRE_PATCH_MIN_RATIO: float = 0\n",
    "\n",
    "    # Controlled train pool (VD default)\n",
    "    USE_CONTROLLED_POOL: bool = True\n",
    "    POOL_KEEP_FIRE: int = -1\n",
    "    NONFIRE_PER_FIRE: int = 3\n",
    "\n",
    "    # Training config (RAM-safe)\n",
    "    IN_CHANNELS: int = 13\n",
    "    H: int = 512\n",
    "    W: int = 512\n",
    "    BATCH_SIZE: int = 2\n",
    "    NUM_WORKERS: int = 2\n",
    "    LR: float = 1e-4\n",
    "    EPOCHS: int = 20 \n",
    "\n",
    "    VERBOSE: bool = True\n",
    "\n",
    "cfg = CFG()\n",
    "\n",
    "assert abs((cfg.GLOBAL_TRAIN_RATIO + cfg.GLOBAL_VAL_RATIO + cfg.GLOBAL_TEST_RATIO) - 1.0) < 1e-6\n",
    "assert os.path.exists(cfg.DATA_ROOT), f\"DATA_ROOT not found: {cfg.DATA_ROOT}\"\n",
    "print(\"DATA_ROOT OK:\", cfg.DATA_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T19:13:45.527422Z",
     "iopub.status.busy": "2026-01-03T19:13:45.527095Z",
     "iopub.status.idle": "2026-01-03T19:13:45.613084Z",
     "shell.execute_reply": "2026-01-03T19:13:45.612454Z",
     "shell.execute_reply.started": "2026-01-03T19:13:45.527399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene1: 864 patches\n",
      "scene2: 594 patches\n",
      "scene3: 504 patches\n",
      "scene4: 504 patches\n",
      "Total patches: 2466\n"
     ]
    }
   ],
   "source": [
    "def list_scene_files(data_root: str, scene_name: str, ext: str = \".npz\") -> List[str]:\n",
    "    scene_dir = os.path.join(data_root, scene_name)\n",
    "    return sorted(glob.glob(os.path.join(scene_dir, f\"*{ext}\")))\n",
    "\n",
    "scene_to_files = {}\n",
    "total = 0\n",
    "for s in cfg.SCENES:\n",
    "    files = list_scene_files(cfg.DATA_ROOT, s, cfg.PATCH_EXT)\n",
    "    scene_to_files[s] = files\n",
    "    total += len(files)\n",
    "    print(f\"{s}: {len(files)} patches\")\n",
    "\n",
    "print(\"Total patches:\", total)\n",
    "if total == 0:\n",
    "    raise RuntimeError(\"No patch files found. Check DATA_ROOT / PATCH_EXT.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T19:13:46.073794Z",
     "iopub.status.busy": "2026-01-03T19:13:46.073489Z",
     "iopub.status.idle": "2026-01-03T19:13:46.196143Z",
     "shell.execute_reply": "2026-01-03T19:13:46.195532Z",
     "shell.execute_reply.started": "2026-01-03T19:13:46.073760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample file: /kaggle/input/sen2fire/Sen2Fire/Sen2Fire/scene1/scene_1_patch_10_1.npz\n",
      "  -      image: shape=(12, 512, 512), dtype=int16\n",
      "  -    aerosol: shape=(512, 512), dtype=float32\n",
      "  -      label: shape=(512, 512), dtype=uint8\n"
     ]
    }
   ],
   "source": [
    "def inspect_npz(npz_path: str):\n",
    "    with np.load(npz_path) as data:\n",
    "        return {k: (data[k].shape, str(data[k].dtype)) for k in data.keys()}\n",
    "\n",
    "sample_path = scene_to_files[cfg.SCENES[0]][0]\n",
    "print(\"Sample file:\", sample_path)\n",
    "info = inspect_npz(sample_path)\n",
    "for k, (shape, dtype) in info.items():\n",
    "    print(f\"  - {k:>10s}: shape={shape}, dtype={dtype}\")\n",
    "\n",
    "for rk in [cfg.X_KEY, cfg.A_KEY, cfg.Y_KEY]:\n",
    "    if rk not in info:\n",
    "        raise KeyError(f\"Missing key '{rk}' in npz. Found keys: {list(info.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T19:13:48.004922Z",
     "iopub.status.busy": "2026-01-03T19:13:48.004286Z",
     "iopub.status.idle": "2026-01-03T19:14:26.930614Z",
     "shell.execute_reply": "2026-01-03T19:14:26.929886Z",
     "shell.execute_reply.started": "2026-01-03T19:13:48.004891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FULL dataset has_fire distribution:\n",
      "has_fire\n",
      "0    2117\n",
      "1     349\n",
      "Name: count, dtype: int64\n",
      "\n",
      "FULL dataset has_fire ratio:\n",
      "has_fire\n",
      "0    0.858475\n",
      "1    0.141525\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for s, files in scene_to_files.items():\n",
    "    for p in files:\n",
    "        rows.append({\"scene\": s, \"path\": p})\n",
    "manifest = pd.DataFrame(rows)\n",
    "\n",
    "def fire_ratio_from_path(npz_path: str) -> float:\n",
    "    with np.load(npz_path) as data:\n",
    "        y = data[cfg.Y_KEY]\n",
    "        if y.ndim == 3 and y.shape[-1] == 1:\n",
    "            y = y[..., 0]\n",
    "        yb = (y > 0).astype(np.uint8)\n",
    "        return float(yb.mean())\n",
    "\n",
    "fire_ratios = []\n",
    "has_fire = []\n",
    "for p in manifest[\"path\"].tolist():\n",
    "    r = fire_ratio_from_path(p)\n",
    "    fire_ratios.append(r)\n",
    "    has_fire.append(1 if r > cfg.FIRE_PATCH_MIN_RATIO else 0)\n",
    "\n",
    "manifest[\"fire_ratio\"] = fire_ratios\n",
    "manifest[\"has_fire\"] = has_fire\n",
    "\n",
    "print(\"\\nFULL dataset has_fire distribution:\")\n",
    "print(manifest[\"has_fire\"].value_counts().sort_index())\n",
    "print(\"\\nFULL dataset has_fire ratio:\")\n",
    "print(manifest[\"has_fire\"].value_counts(normalize=True).sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T19:14:26.932286Z",
     "iopub.status.busy": "2026-01-03T19:14:26.931977Z",
     "iopub.status.idle": "2026-01-03T19:14:26.955134Z",
     "shell.execute_reply": "2026-01-03T19:14:26.954555Z",
     "shell.execute_reply.started": "2026-01-03T19:14:26.932263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GLOBAL split counts:\n",
      "  Train pool: 1973\n",
      "  Val      : 247\n",
      "  Test     : 246\n",
      "\n",
      "TRAIN controlled sampling:\n",
      "  fire_total_in_pool   : 279\n",
      "  nofire_total_in_pool : 1694\n",
      "  fire_kept            : 279\n",
      "  nofire_kept          : 837 (NONFIRE_PER_FIRE=3)\n",
      "  train_final          : 1116\n",
      "\n",
      "Final used split sizes:\n",
      "  train: 1116\n",
      "  val  : 247\n",
      "  test : 246\n"
     ]
    }
   ],
   "source": [
    "def stratified_split(df, train_ratio, val_ratio, seed=42):\n",
    "    df = df.sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
    "    parts = []\n",
    "    for cls in [0, 1]:\n",
    "        sub = df[df[\"has_fire\"] == cls].copy()\n",
    "        n = len(sub)\n",
    "        n_train = int(round(n * train_ratio))\n",
    "        n_val   = int(round(n * val_ratio))\n",
    "        sub_train = sub.iloc[:n_train]\n",
    "        sub_val   = sub.iloc[n_train:n_train+n_val]\n",
    "        sub_test  = sub.iloc[n_train+n_val:]\n",
    "        parts.append((sub_train, sub_val, sub_test))\n",
    "\n",
    "    train_df = pd.concat([parts[0][0], parts[1][0]]).sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
    "    val_df   = pd.concat([parts[0][1], parts[1][1]]).sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
    "    test_df  = pd.concat([parts[0][2], parts[1][2]]).sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "train_pool_df, val_df, test_df = stratified_split(\n",
    "    manifest,\n",
    "    train_ratio=cfg.GLOBAL_TRAIN_RATIO,\n",
    "    val_ratio=cfg.GLOBAL_VAL_RATIO,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "print(\"\\nGLOBAL split counts:\")\n",
    "print(\"  Train pool:\", len(train_pool_df))\n",
    "print(\"  Val      :\", len(val_df))\n",
    "print(\"  Test     :\", len(test_df))\n",
    "\n",
    "# Controlled pool applies to TRAIN only\n",
    "if cfg.USE_CONTROLLED_POOL:\n",
    "    fire_df   = train_pool_df[train_pool_df[\"has_fire\"] == 1].copy()\n",
    "    nofire_df = train_pool_df[train_pool_df[\"has_fire\"] == 0].copy()\n",
    "\n",
    "    n_fire_total = len(fire_df)\n",
    "    n_nofire_total = len(nofire_df)\n",
    "\n",
    "    n_fire_keep = n_fire_total if cfg.POOL_KEEP_FIRE in (-1, None) else min(cfg.POOL_KEEP_FIRE, n_fire_total)\n",
    "    fire_keep = fire_df.sample(n=n_fire_keep, random_state=SEED) if n_fire_keep > 0 else fire_df.iloc[:0]\n",
    "\n",
    "    n_nofire_keep = min(n_nofire_total, n_fire_keep * int(cfg.NONFIRE_PER_FIRE))\n",
    "    nofire_keep = nofire_df.sample(n=n_nofire_keep, random_state=SEED) if n_nofire_keep > 0 else nofire_df.iloc[:0]\n",
    "\n",
    "    train_df = pd.concat([fire_keep, nofire_keep]).sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "    print(\"\\nTRAIN controlled sampling:\")\n",
    "    print(f\"  fire_total_in_pool   : {n_fire_total}\")\n",
    "    print(f\"  nofire_total_in_pool : {n_nofire_total}\")\n",
    "    print(f\"  fire_kept            : {len(fire_keep)}\")\n",
    "    print(f\"  nofire_kept          : {len(nofire_keep)} (NONFIRE_PER_FIRE={cfg.NONFIRE_PER_FIRE})\")\n",
    "    print(f\"  train_final          : {len(train_df)}\")\n",
    "else:\n",
    "    train_df = train_pool_df.copy()\n",
    "\n",
    "train_paths = train_df[\"path\"].tolist()\n",
    "val_paths   = val_df[\"path\"].tolist()\n",
    "test_paths  = test_df[\"path\"].tolist()\n",
    "\n",
    "# leakage check\n",
    "assert len(set(train_paths)&set(val_paths))==0\n",
    "assert len(set(train_paths)&set(test_paths))==0\n",
    "assert len(set(val_paths)&set(test_paths))==0\n",
    "\n",
    "print(\"\\nFinal used split sizes:\")\n",
    "print(\"  train:\", len(train_paths))\n",
    "print(\"  val  :\", len(val_paths))\n",
    "print(\"  test :\", len(test_paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T19:14:26.956259Z",
     "iopub.status.busy": "2026-01-03T19:14:26.956030Z",
     "iopub.status.idle": "2026-01-03T19:14:26.962239Z",
     "shell.execute_reply": "2026-01-03T19:14:26.961657Z",
     "shell.execute_reply.started": "2026-01-03T19:14:26.956237Z"
    }
   },
   "outputs": [],
   "source": [
    "class Sen2FireDataset(Dataset):\n",
    "    def __init__(self, paths: List[str], with_label: bool = True):\n",
    "        self.paths = paths\n",
    "        self.with_label = with_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.paths[idx]\n",
    "        with np.load(p) as d:\n",
    "            img12 = d[cfg.X_KEY].astype(np.float32)      # (12,512,512)\n",
    "            aer   = d[cfg.A_KEY].astype(np.float32)[None, ...]  # (1,512,512)\n",
    "            x = np.concatenate([img12, aer], axis=0)     # (13,512,512)\n",
    "\n",
    "            if self.with_label:\n",
    "                y = d[cfg.Y_KEY]\n",
    "                if y.ndim == 2:\n",
    "                    y = y[None, ...]\n",
    "                y = (y > 0).astype(np.float32)\n",
    "                return torch.from_numpy(x), torch.from_numpy(y)\n",
    "            else:\n",
    "                return torch.from_numpy(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T19:14:26.963787Z",
     "iopub.status.busy": "2026-01-03T19:14:26.963581Z",
     "iopub.status.idle": "2026-01-03T19:14:26.976031Z",
     "shell.execute_reply": "2026-01-03T19:14:26.975409Z",
     "shell.execute_reply.started": "2026-01-03T19:14:26.963767Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(Sen2FireDataset(train_paths, with_label=True),\n",
    "                          batch_size=cfg.BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=cfg.NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "val_loader = DataLoader(Sen2FireDataset(val_paths, with_label=True),\n",
    "                        batch_size=cfg.BATCH_SIZE, shuffle=False,\n",
    "                        num_workers=cfg.NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "test_loader = DataLoader(Sen2FireDataset(test_paths, with_label=True),\n",
    "                         batch_size=cfg.BATCH_SIZE, shuffle=False,\n",
    "                         num_workers=cfg.NUM_WORKERS, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T19:14:26.977109Z",
     "iopub.status.busy": "2026-01-03T19:14:26.976813Z",
     "iopub.status.idle": "2026-01-03T19:14:31.055539Z",
     "shell.execute_reply": "2026-01-03T19:14:31.054708Z",
     "shell.execute_reply.started": "2026-01-03T19:14:26.977082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN_13 len: 13 STD_13 len: 13\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def compute_mean_std(loader, max_batches=50):\n",
    "    mean = torch.zeros(cfg.IN_CHANNELS, device=DEVICE)\n",
    "    var  = torch.zeros(cfg.IN_CHANNELS, device=DEVICE)\n",
    "    n_batches = 0\n",
    "\n",
    "    for bi, (x, y) in enumerate(loader):\n",
    "        if bi >= max_batches:\n",
    "            break\n",
    "        x = x.to(DEVICE)  # (B,C,H,W)\n",
    "        x_ = x.view(x.size(0), cfg.IN_CHANNELS, -1)\n",
    "        mean += x_.mean(dim=(0,2))\n",
    "        var  += x_.var(dim=(0,2), unbiased=False)\n",
    "        n_batches += 1\n",
    "\n",
    "    mean /= max(n_batches, 1)\n",
    "    var  /= max(n_batches, 1)\n",
    "    std = torch.sqrt(var + 1e-6)\n",
    "    return mean.detach().cpu().tolist(), std.detach().cpu().tolist()\n",
    "\n",
    "MEAN_13, STD_13 = compute_mean_std(train_loader, max_batches=50)\n",
    "print(\"MEAN_13 len:\", len(MEAN_13), \"STD_13 len:\", len(STD_13))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL PREPARATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T19:14:31.057563Z",
     "iopub.status.busy": "2026-01-03T19:14:31.056918Z",
     "iopub.status.idle": "2026-01-03T19:14:35.424173Z",
     "shell.execute_reply": "2026-01-03T19:14:35.423443Z",
     "shell.execute_reply.started": "2026-01-03T19:14:31.057531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip -q install segmentation-models-pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T19:14:35.425826Z",
     "iopub.status.busy": "2026-01-03T19:14:35.425498Z",
     "iopub.status.idle": "2026-01-03T19:14:35.430177Z",
     "shell.execute_reply": "2026-01-03T19:14:35.429718Z",
     "shell.execute_reply.started": "2026-01-03T19:14:35.425786Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_batch(x, mean_13, std_13):\n",
    "    mean_t = torch.tensor(mean_13, device=x.device).view(1, cfg.IN_CHANNELS, 1, 1)\n",
    "    std_t  = torch.tensor(std_13,  device=x.device).view(1, cfg.IN_CHANNELS, 1, 1)\n",
    "    return (x - mean_t) / (std_t + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T19:14:35.431448Z",
     "iopub.status.busy": "2026-01-03T19:14:35.431150Z",
     "iopub.status.idle": "2026-01-03T19:14:45.458390Z",
     "shell.execute_reply": "2026-01-03T19:14:45.457719Z",
     "shell.execute_reply.started": "2026-01-03T19:14:35.431427Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8044f37fc328408d84873de4234dee95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/106 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "596538c91aa94e5cae583ac20bd6d6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/77.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Unet\n"
     ]
    }
   ],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "def build_unet(in_channels=13):\n",
    "    model = smp.Unet(\n",
    "        encoder_name=\"efficientnet-b4\",\n",
    "        encoder_weights=\"imagenet\",\n",
    "        in_channels=in_channels,\n",
    "        classes=1,\n",
    "        activation=None\n",
    "    )\n",
    "    return model\n",
    "    \n",
    "model = build_unet(cfg.IN_CHANNELS).to(DEVICE)\n",
    "print(\"Model:\", type(model).__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T19:14:45.459581Z",
     "iopub.status.busy": "2026-01-03T19:14:45.459273Z",
     "iopub.status.idle": "2026-01-03T19:14:46.101772Z",
     "shell.execute_reply": "2026-01-03T19:14:46.101167Z",
     "shell.execute_reply.started": "2026-01-03T19:14:45.459558Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.amp import autocast, GradScaler\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cfg.LR)\n",
    "scaler = GradScaler(enabled=(DEVICE.type == \"cuda\"))\n",
    "\n",
    "def train_one_epoch(model, loader, thr=0.5, eps=1e-6):\n",
    "    model.train()\n",
    "    total_loss_sum = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    total_tp = total_fp = total_fn = total_tn = 0.0\n",
    "    all_probs, all_targets = [], []\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        x = normalize_batch(x, MEAN_13, STD_13)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with autocast(\"cuda\", enabled=(DEVICE.type == \"cuda\")):\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        bs = x.size(0)\n",
    "        total_loss_sum += loss.item() * bs\n",
    "        total_samples += bs\n",
    "\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= thr).float()\n",
    "\n",
    "        total_tp += (preds * y).sum().item()\n",
    "        total_fp += (preds * (1 - y)).sum().item()\n",
    "        total_fn += ((1 - preds) * y).sum().item()\n",
    "        total_tn += ((1 - preds) * (1 - y)).sum().item()\n",
    "\n",
    "        all_probs.append(probs.flatten().detach().cpu())\n",
    "        all_targets.append(y.flatten().detach().cpu())\n",
    "\n",
    "    precision = (total_tp + eps) / (total_tp + total_fp + eps)\n",
    "    recall    = (total_tp + eps) / (total_tp + total_fn + eps)\n",
    "    f1        = (2 * precision * recall) / (precision + recall + eps)\n",
    "    acc       = (total_tp + total_tn + eps) / (\n",
    "        total_tp + total_tn + total_fp + total_fn + eps\n",
    "    )\n",
    "\n",
    "    all_probs = torch.cat(all_probs).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "    auc = average_precision_score(all_targets, all_probs)\n",
    "\n",
    "    loss_global = total_loss_sum / total_samples\n",
    "\n",
    "    return loss_global, precision, recall, f1, acc, auc\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_epoch(model, loader, thr=0.5, eps=1e-6):\n",
    "    model.eval()\n",
    "    total_loss_sum = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    total_tp = total_fp = total_fn = total_tn = 0.0\n",
    "    all_probs, all_targets = [], []\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        x = normalize_batch(x, MEAN_13, STD_13)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        bs = x.size(0)\n",
    "        total_loss_sum += loss.item() * bs\n",
    "        total_samples += bs\n",
    "\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= thr).float()\n",
    "\n",
    "        total_tp += (preds * y).sum().item()\n",
    "        total_fp += (preds * (1 - y)).sum().item()\n",
    "        total_fn += ((1 - preds) * y).sum().item()\n",
    "        total_tn += ((1 - preds) * (1 - y)).sum().item()\n",
    "\n",
    "        all_probs.append(probs.flatten().cpu())\n",
    "        all_targets.append(y.flatten().cpu())\n",
    "\n",
    "    precision = (total_tp + eps) / (total_tp + total_fp + eps)\n",
    "    recall    = (total_tp + eps) / (total_tp + total_fn + eps)\n",
    "    f1        = (2 * precision * recall) / (precision + recall + eps)\n",
    "    acc       = (total_tp + total_tn + eps) / (\n",
    "        total_tp + total_tn + total_fp + total_fn + eps\n",
    "    )\n",
    "\n",
    "    all_probs = torch.cat(all_probs).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "    auc = average_precision_score(all_targets, all_probs)\n",
    "\n",
    "    loss_global = total_loss_sum / total_samples\n",
    "\n",
    "    return loss_global, precision, recall, f1, acc, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T14:48:44.301312Z",
     "iopub.status.busy": "2026-01-03T14:48:44.300992Z",
     "iopub.status.idle": "2026-01-03T16:36:00.925700Z",
     "shell.execute_reply": "2026-01-03T16:36:00.925014Z",
     "shell.execute_reply.started": "2026-01-03T14:48:44.301286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[unet_basic] Epoch 001 | tr_loss=0.1889 tr_f1=0.1420 tr_acc=0.9428 tr_PRauc=0.2755 || va_loss=0.1381 va_f1=0.0651 va_acc=0.9519 va_PRauc=0.3289 | 326.0s\n",
      "[unet_basic] Epoch 002 | tr_loss=0.1639 tr_f1=0.3168 tr_acc=0.9467 tr_PRauc=0.4100 || va_loss=0.1232 va_f1=0.0018 va_acc=0.9522 va_PRauc=0.4055 | 324.8s\n",
      "[unet_basic] Epoch 003 | tr_loss=0.1356 tr_f1=0.4874 tr_acc=0.9551 tr_PRauc=0.5765 || va_loss=0.1477 va_f1=0.0000 va_acc=0.9522 va_PRauc=0.3395 | 325.0s\n",
      "[unet_basic] Epoch 004 | tr_loss=0.1011 tr_f1=0.6632 tr_acc=0.9653 tr_PRauc=0.7327 || va_loss=0.1086 va_f1=0.0798 va_acc=0.9539 va_PRauc=0.6033 | 323.2s\n",
      "[unet_basic] Epoch 005 | tr_loss=0.0822 tr_f1=0.7421 tr_acc=0.9721 tr_PRauc=0.8072 || va_loss=0.1484 va_f1=0.0000 va_acc=0.9522 va_PRauc=0.5431 | 323.6s\n",
      "[unet_basic] Epoch 006 | tr_loss=0.0665 tr_f1=0.7983 tr_acc=0.9774 tr_PRauc=0.8634 || va_loss=0.1328 va_f1=0.0000 va_acc=0.9522 va_PRauc=0.6381 | 323.4s\n",
      "[unet_basic] Epoch 007 | tr_loss=0.0569 tr_f1=0.8356 tr_acc=0.9813 tr_PRauc=0.8944 || va_loss=0.1106 va_f1=0.3046 va_acc=0.9592 va_PRauc=0.6277 | 322.1s\n",
      "[unet_basic] Epoch 008 | tr_loss=0.0497 tr_f1=0.8533 tr_acc=0.9831 tr_PRauc=0.9135 || va_loss=0.1192 va_f1=0.1756 va_acc=0.9566 va_PRauc=0.7063 | 324.6s\n",
      "[unet_basic] Epoch 009 | tr_loss=0.0411 tr_f1=0.8801 tr_acc=0.9861 tr_PRauc=0.9351 || va_loss=0.0982 va_f1=0.4932 va_acc=0.9656 va_PRauc=0.6908 | 323.9s\n",
      "[unet_basic] Epoch 010 | tr_loss=0.0340 tr_f1=0.8989 tr_acc=0.9882 tr_PRauc=0.9565 || va_loss=0.1098 va_f1=0.4278 va_acc=0.9638 va_PRauc=0.7042 | 320.1s\n",
      "[unet_basic] Epoch 011 | tr_loss=0.0425 tr_f1=0.8700 tr_acc=0.9849 tr_PRauc=0.9306 || va_loss=0.1273 va_f1=0.3035 va_acc=0.9599 va_PRauc=0.6679 | 320.2s\n",
      "[unet_basic] Epoch 012 | tr_loss=0.0292 tr_f1=0.9100 tr_acc=0.9894 tr_PRauc=0.9635 || va_loss=0.1288 va_f1=0.3595 va_acc=0.9610 va_PRauc=0.6768 | 321.1s\n",
      "[unet_basic] Epoch 013 | tr_loss=0.0248 tr_f1=0.9247 tr_acc=0.9911 tr_PRauc=0.9732 || va_loss=0.0953 va_f1=0.6315 va_acc=0.9716 va_PRauc=0.7490 | 318.8s\n",
      "[unet_basic] Epoch 014 | tr_loss=0.0282 tr_f1=0.9142 tr_acc=0.9899 tr_PRauc=0.9672 || va_loss=0.1071 va_f1=0.5798 va_acc=0.9691 va_PRauc=0.7131 | 320.3s\n",
      "[unet_basic] Epoch 015 | tr_loss=0.0326 tr_f1=0.9052 tr_acc=0.9889 tr_PRauc=0.9596 || va_loss=0.1418 va_f1=0.4313 va_acc=0.9643 va_PRauc=0.6807 | 319.1s\n",
      "[unet_basic] Epoch 016 | tr_loss=0.0344 tr_f1=0.9022 tr_acc=0.9886 tr_PRauc=0.9572 || va_loss=0.0918 va_f1=0.6768 va_acc=0.9703 va_PRauc=0.6923 | 318.3s\n",
      "[unet_basic] Epoch 017 | tr_loss=0.0368 tr_f1=0.8939 tr_acc=0.9877 tr_PRauc=0.9509 || va_loss=0.1136 va_f1=0.5730 va_acc=0.9700 va_PRauc=0.7651 | 318.6s\n",
      "[unet_basic] Epoch 018 | tr_loss=0.0208 tr_f1=0.9359 tr_acc=0.9925 tr_PRauc=0.9817 || va_loss=0.1090 va_f1=0.5632 va_acc=0.9691 va_PRauc=0.7526 | 319.5s\n",
      "[unet_basic] Epoch 019 | tr_loss=0.0189 tr_f1=0.9421 tr_acc=0.9932 tr_PRauc=0.9848 || va_loss=0.1125 va_f1=0.5091 va_acc=0.9673 va_PRauc=0.7702 | 320.1s\n",
      "[unet_basic] Epoch 020 | tr_loss=0.0154 tr_f1=0.9527 tr_acc=0.9944 tr_PRauc=0.9898 || va_loss=0.1087 va_f1=0.6326 va_acc=0.9726 va_PRauc=0.7659 | 319.8s\n"
     ]
    }
   ],
   "source": [
    "BEST_PATH = \"/kaggle/working/efficientb4.pth\"\n",
    "best_val_f1 = -1\n",
    "\n",
    "import pandas as pd\n",
    "history = []\n",
    "\n",
    "for epoch in range(1, cfg.EPOCHS + 1):\n",
    "    t0 = time.time()\n",
    "\n",
    "    tr_loss, tr_prec, tr_rec, tr_f1, tr_acc, tr_auc = train_one_epoch(model, train_loader)\n",
    "    va_loss, va_prec, va_rec, va_f1, va_acc, va_auc = validate_epoch(model, val_loader, thr=0.5)\n",
    "    elapsed = time.time() - t0\n",
    "\n",
    "    print(\n",
    "        f\"[unet_basic] Epoch {epoch:03d} | \"\n",
    "        f\"tr_loss={tr_loss:.4f} tr_f1={tr_f1:.4f} tr_acc={tr_acc:.4f} tr_PRauc={tr_auc:.4f} || \"\n",
    "        f\"va_loss={va_loss:.4f} va_f1={va_f1:.4f} va_acc={va_acc:.4f} va_PRauc={va_auc:.4f} | \"\n",
    "        f\"{elapsed:.1f}s\"\n",
    "    )\n",
    "\n",
    "    history.append({\n",
    "        \"epoch\": epoch,\n",
    "    \n",
    "        \"tr_loss\": tr_loss,\n",
    "        \"tr_precision\": tr_prec,\n",
    "        \"tr_recall\": tr_rec,\n",
    "        \"tr_f1\": tr_f1,\n",
    "        \"tr_acc\": tr_acc,\n",
    "        \"tr_PRauc\": tr_auc,\n",
    "    \n",
    "        \"va_loss\": va_loss,\n",
    "        \"va_precision\": va_prec,\n",
    "        \"va_recall\": va_rec,\n",
    "        \"va_f1\": va_f1,\n",
    "        \"va_acc\": va_acc,\n",
    "        \"va_PRauc\": va_auc,\n",
    "    \n",
    "        \"seconds\": elapsed\n",
    "    })\n",
    "\n",
    "    if va_f1 > best_val_f1:\n",
    "        torch.save({\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"mean_13\": MEAN_13,\n",
    "            \"std_13\": STD_13,\n",
    "            \"epoch\": epoch,\n",
    "            \"best_val_f1\": best_val_f1,\n",
    "            \"va_auc\": va_auc,\n",
    "        }, BEST_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T16:38:23.348464Z",
     "iopub.status.busy": "2026-01-03T16:38:23.347762Z",
     "iopub.status.idle": "2026-01-03T16:38:23.387567Z",
     "shell.execute_reply": "2026-01-03T16:38:23.387014Z",
     "shell.execute_reply.started": "2026-01-03T16:38:23.348428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: /kaggle/working/training_metrics_eff1.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>tr_loss</th>\n",
       "      <th>tr_precision</th>\n",
       "      <th>tr_recall</th>\n",
       "      <th>tr_f1</th>\n",
       "      <th>tr_acc</th>\n",
       "      <th>tr_PRauc</th>\n",
       "      <th>va_loss</th>\n",
       "      <th>va_precision</th>\n",
       "      <th>va_recall</th>\n",
       "      <th>va_f1</th>\n",
       "      <th>va_acc</th>\n",
       "      <th>va_PRauc</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1889</td>\n",
       "      <td>0.6055</td>\n",
       "      <td>0.0805</td>\n",
       "      <td>0.1420</td>\n",
       "      <td>0.9428</td>\n",
       "      <td>0.2755</td>\n",
       "      <td>0.1381</td>\n",
       "      <td>0.4598</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.0651</td>\n",
       "      <td>0.9519</td>\n",
       "      <td>0.3289</td>\n",
       "      <td>326.0277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.1639</td>\n",
       "      <td>0.6474</td>\n",
       "      <td>0.2097</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.9467</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>0.1232</td>\n",
       "      <td>0.7221</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.9522</td>\n",
       "      <td>0.4055</td>\n",
       "      <td>324.7601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.1356</td>\n",
       "      <td>0.7453</td>\n",
       "      <td>0.3621</td>\n",
       "      <td>0.4874</td>\n",
       "      <td>0.9551</td>\n",
       "      <td>0.5765</td>\n",
       "      <td>0.1477</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9522</td>\n",
       "      <td>0.3395</td>\n",
       "      <td>324.9510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.1011</td>\n",
       "      <td>0.7751</td>\n",
       "      <td>0.5795</td>\n",
       "      <td>0.6632</td>\n",
       "      <td>0.9653</td>\n",
       "      <td>0.7327</td>\n",
       "      <td>0.1086</td>\n",
       "      <td>0.8705</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.0798</td>\n",
       "      <td>0.9539</td>\n",
       "      <td>0.6033</td>\n",
       "      <td>323.1811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0822</td>\n",
       "      <td>0.8130</td>\n",
       "      <td>0.6825</td>\n",
       "      <td>0.7421</td>\n",
       "      <td>0.9721</td>\n",
       "      <td>0.8072</td>\n",
       "      <td>0.1484</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9522</td>\n",
       "      <td>0.5431</td>\n",
       "      <td>323.6256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0665</td>\n",
       "      <td>0.8429</td>\n",
       "      <td>0.7582</td>\n",
       "      <td>0.7983</td>\n",
       "      <td>0.9774</td>\n",
       "      <td>0.8634</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9522</td>\n",
       "      <td>0.6381</td>\n",
       "      <td>323.4198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0569</td>\n",
       "      <td>0.8666</td>\n",
       "      <td>0.8068</td>\n",
       "      <td>0.8356</td>\n",
       "      <td>0.9813</td>\n",
       "      <td>0.8944</td>\n",
       "      <td>0.1106</td>\n",
       "      <td>0.8246</td>\n",
       "      <td>0.1868</td>\n",
       "      <td>0.3046</td>\n",
       "      <td>0.9592</td>\n",
       "      <td>0.6277</td>\n",
       "      <td>322.1071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0497</td>\n",
       "      <td>0.8725</td>\n",
       "      <td>0.8349</td>\n",
       "      <td>0.8533</td>\n",
       "      <td>0.9831</td>\n",
       "      <td>0.9135</td>\n",
       "      <td>0.1192</td>\n",
       "      <td>0.9612</td>\n",
       "      <td>0.0966</td>\n",
       "      <td>0.1756</td>\n",
       "      <td>0.9566</td>\n",
       "      <td>0.7063</td>\n",
       "      <td>324.6199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0411</td>\n",
       "      <td>0.8916</td>\n",
       "      <td>0.8690</td>\n",
       "      <td>0.8801</td>\n",
       "      <td>0.9861</td>\n",
       "      <td>0.9351</td>\n",
       "      <td>0.0982</td>\n",
       "      <td>0.8344</td>\n",
       "      <td>0.3501</td>\n",
       "      <td>0.4932</td>\n",
       "      <td>0.9656</td>\n",
       "      <td>0.6908</td>\n",
       "      <td>323.9097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0340</td>\n",
       "      <td>0.9098</td>\n",
       "      <td>0.8882</td>\n",
       "      <td>0.8989</td>\n",
       "      <td>0.9882</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.8758</td>\n",
       "      <td>0.2830</td>\n",
       "      <td>0.4278</td>\n",
       "      <td>0.9638</td>\n",
       "      <td>0.7042</td>\n",
       "      <td>320.1268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.8829</td>\n",
       "      <td>0.8576</td>\n",
       "      <td>0.8700</td>\n",
       "      <td>0.9849</td>\n",
       "      <td>0.9306</td>\n",
       "      <td>0.1273</td>\n",
       "      <td>0.8980</td>\n",
       "      <td>0.1826</td>\n",
       "      <td>0.3035</td>\n",
       "      <td>0.9599</td>\n",
       "      <td>0.6679</td>\n",
       "      <td>320.2104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.9113</td>\n",
       "      <td>0.9088</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>0.9894</td>\n",
       "      <td>0.9635</td>\n",
       "      <td>0.1288</td>\n",
       "      <td>0.8406</td>\n",
       "      <td>0.2287</td>\n",
       "      <td>0.3595</td>\n",
       "      <td>0.9610</td>\n",
       "      <td>0.6768</td>\n",
       "      <td>321.1205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.9264</td>\n",
       "      <td>0.9229</td>\n",
       "      <td>0.9247</td>\n",
       "      <td>0.9911</td>\n",
       "      <td>0.9732</td>\n",
       "      <td>0.0953</td>\n",
       "      <td>0.8327</td>\n",
       "      <td>0.5086</td>\n",
       "      <td>0.6315</td>\n",
       "      <td>0.9716</td>\n",
       "      <td>0.7490</td>\n",
       "      <td>318.8185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.9181</td>\n",
       "      <td>0.9104</td>\n",
       "      <td>0.9142</td>\n",
       "      <td>0.9899</td>\n",
       "      <td>0.9672</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>0.8300</td>\n",
       "      <td>0.4455</td>\n",
       "      <td>0.5798</td>\n",
       "      <td>0.9691</td>\n",
       "      <td>0.7131</td>\n",
       "      <td>320.2609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.9141</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>0.9052</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.9596</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.9046</td>\n",
       "      <td>0.2832</td>\n",
       "      <td>0.4313</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.6807</td>\n",
       "      <td>319.0644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.9102</td>\n",
       "      <td>0.8943</td>\n",
       "      <td>0.9022</td>\n",
       "      <td>0.9886</td>\n",
       "      <td>0.9572</td>\n",
       "      <td>0.0918</td>\n",
       "      <td>0.7061</td>\n",
       "      <td>0.6499</td>\n",
       "      <td>0.6768</td>\n",
       "      <td>0.9703</td>\n",
       "      <td>0.6923</td>\n",
       "      <td>318.2682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.9082</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.8939</td>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9509</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.8974</td>\n",
       "      <td>0.4209</td>\n",
       "      <td>0.5730</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.7651</td>\n",
       "      <td>318.5994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.9392</td>\n",
       "      <td>0.9327</td>\n",
       "      <td>0.9359</td>\n",
       "      <td>0.9925</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>0.1090</td>\n",
       "      <td>0.8688</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.5632</td>\n",
       "      <td>0.9691</td>\n",
       "      <td>0.7526</td>\n",
       "      <td>319.4516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.9467</td>\n",
       "      <td>0.9377</td>\n",
       "      <td>0.9421</td>\n",
       "      <td>0.9932</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.9010</td>\n",
       "      <td>0.3547</td>\n",
       "      <td>0.5091</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.7702</td>\n",
       "      <td>320.0552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.9520</td>\n",
       "      <td>0.9535</td>\n",
       "      <td>0.9527</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>0.9898</td>\n",
       "      <td>0.1087</td>\n",
       "      <td>0.8795</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.6326</td>\n",
       "      <td>0.9726</td>\n",
       "      <td>0.7659</td>\n",
       "      <td>319.7536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  tr_loss  tr_precision  tr_recall   tr_f1  tr_acc  tr_PRauc  \\\n",
       "0       1   0.1889        0.6055     0.0805  0.1420  0.9428    0.2755   \n",
       "1       2   0.1639        0.6474     0.2097  0.3168  0.9467    0.4100   \n",
       "2       3   0.1356        0.7453     0.3621  0.4874  0.9551    0.5765   \n",
       "3       4   0.1011        0.7751     0.5795  0.6632  0.9653    0.7327   \n",
       "4       5   0.0822        0.8130     0.6825  0.7421  0.9721    0.8072   \n",
       "5       6   0.0665        0.8429     0.7582  0.7983  0.9774    0.8634   \n",
       "6       7   0.0569        0.8666     0.8068  0.8356  0.9813    0.8944   \n",
       "7       8   0.0497        0.8725     0.8349  0.8533  0.9831    0.9135   \n",
       "8       9   0.0411        0.8916     0.8690  0.8801  0.9861    0.9351   \n",
       "9      10   0.0340        0.9098     0.8882  0.8989  0.9882    0.9565   \n",
       "10     11   0.0425        0.8829     0.8576  0.8700  0.9849    0.9306   \n",
       "11     12   0.0292        0.9113     0.9088  0.9100  0.9894    0.9635   \n",
       "12     13   0.0248        0.9264     0.9229  0.9247  0.9911    0.9732   \n",
       "13     14   0.0282        0.9181     0.9104  0.9142  0.9899    0.9672   \n",
       "14     15   0.0326        0.9141     0.8964  0.9052  0.9889    0.9596   \n",
       "15     16   0.0344        0.9102     0.8943  0.9022  0.9886    0.9572   \n",
       "16     17   0.0368        0.9082     0.8800  0.8939  0.9877    0.9509   \n",
       "17     18   0.0208        0.9392     0.9327  0.9359  0.9925    0.9817   \n",
       "18     19   0.0189        0.9467     0.9377  0.9421  0.9932    0.9848   \n",
       "19     20   0.0154        0.9520     0.9535  0.9527  0.9944    0.9898   \n",
       "\n",
       "    va_loss  va_precision  va_recall   va_f1  va_acc  va_PRauc   seconds  \n",
       "0    0.1381        0.4598     0.0350  0.0651  0.9519    0.3289  326.0277  \n",
       "1    0.1232        0.7221     0.0009  0.0018  0.9522    0.4055  324.7601  \n",
       "2    0.1477        1.0000     0.0000  0.0000  0.9522    0.3395  324.9510  \n",
       "3    0.1086        0.8705     0.0418  0.0798  0.9539    0.6033  323.1811  \n",
       "4    0.1484        1.0000     0.0000  0.0000  0.9522    0.5431  323.6256  \n",
       "5    0.1328        0.0000     0.0000  0.0000  0.9522    0.6381  323.4198  \n",
       "6    0.1106        0.8246     0.1868  0.3046  0.9592    0.6277  322.1071  \n",
       "7    0.1192        0.9612     0.0966  0.1756  0.9566    0.7063  324.6199  \n",
       "8    0.0982        0.8344     0.3501  0.4932  0.9656    0.6908  323.9097  \n",
       "9    0.1098        0.8758     0.2830  0.4278  0.9638    0.7042  320.1268  \n",
       "10   0.1273        0.8980     0.1826  0.3035  0.9599    0.6679  320.2104  \n",
       "11   0.1288        0.8406     0.2287  0.3595  0.9610    0.6768  321.1205  \n",
       "12   0.0953        0.8327     0.5086  0.6315  0.9716    0.7490  318.8185  \n",
       "13   0.1071        0.8300     0.4455  0.5798  0.9691    0.7131  320.2609  \n",
       "14   0.1418        0.9046     0.2832  0.4313  0.9643    0.6807  319.0644  \n",
       "15   0.0918        0.7061     0.6499  0.6768  0.9703    0.6923  318.2682  \n",
       "16   0.1136        0.8974     0.4209  0.5730  0.9700    0.7651  318.5994  \n",
       "17   0.1090        0.8688     0.4166  0.5632  0.9691    0.7526  319.4516  \n",
       "18   0.1125        0.9010     0.3547  0.5091  0.9673    0.7702  320.0552  \n",
       "19   0.1087        0.8795     0.4939  0.6326  0.9726    0.7659  319.7536  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_history = pd.DataFrame(history)\n",
    "\n",
    "df_history = df_history.round(4)\n",
    "csv_path = \"/kaggle/working/training_metrics_eff1.csv\"\n",
    "df_history.to_csv(csv_path, index=False)\n",
    "print(\"Saved to:\", csv_path)\n",
    "df_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T08:57:35.058984Z",
     "iopub.status.busy": "2026-02-01T08:57:35.058484Z",
     "iopub.status.idle": "2026-02-01T08:57:36.735259Z",
     "shell.execute_reply": "2026-02-01T08:57:36.734664Z",
     "shell.execute_reply.started": "2026-02-01T08:57:35.058953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load(\n",
    "    \"/kaggle/input/efficient-b4/pytorch/default/1/efficientb4.pth\",\n",
    "    map_location=DEVICE,\n",
    "    weights_only=False  # biar load semua, bukan cuma weights\n",
    ")\n",
    "model.load_state_dict(ckpt[\"model_state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T09:08:49.850938Z",
     "iopub.status.busy": "2026-02-01T09:08:49.850139Z",
     "iopub.status.idle": "2026-02-01T10:26:12.616018Z",
     "shell.execute_reply": "2026-02-01T10:26:12.615148Z",
     "shell.execute_reply.started": "2026-02-01T09:08:49.850902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[unet_basic] Epoch 001 | tr_loss=0.0198 tr_f1=0.9372 tr_acc=0.9926 tr_PRauc=0.9830 || va_loss=0.1082 va_f1=0.6155 va_acc=0.9716 va_PRauc=0.7554 | 228.1s\n",
      "[unet_basic] Epoch 002 | tr_loss=0.0178 tr_f1=0.9434 tr_acc=0.9934 tr_PRauc=0.9857 || va_loss=0.1306 va_f1=0.5201 va_acc=0.9670 va_PRauc=0.7195 | 227.6s\n",
      "[unet_basic] Epoch 003 | tr_loss=0.0184 tr_f1=0.9446 tr_acc=0.9935 tr_PRauc=0.9851 || va_loss=0.0923 va_f1=0.6457 va_acc=0.9731 va_PRauc=0.7824 | 231.4s\n",
      "[unet_basic] Epoch 004 | tr_loss=0.0183 tr_f1=0.9443 tr_acc=0.9935 tr_PRauc=0.9856 || va_loss=0.0940 va_f1=0.6545 va_acc=0.9739 va_PRauc=0.7833 | 229.7s\n",
      "[unet_basic] Epoch 005 | tr_loss=0.0160 tr_f1=0.9507 tr_acc=0.9942 tr_PRauc=0.9884 || va_loss=0.0937 va_f1=0.6320 va_acc=0.9721 va_PRauc=0.7763 | 229.8s\n",
      "[unet_basic] Epoch 006 | tr_loss=0.0116 tr_f1=0.9626 tr_acc=0.9956 tr_PRauc=0.9941 || va_loss=0.1002 va_f1=0.6977 va_acc=0.9764 va_PRauc=0.8088 | 230.5s\n",
      "[unet_basic] Epoch 007 | tr_loss=0.0096 tr_f1=0.9682 tr_acc=0.9963 tr_PRauc=0.9960 || va_loss=0.1393 va_f1=0.5376 va_acc=0.9691 va_PRauc=0.7855 | 233.1s\n",
      "[unet_basic] Epoch 008 | tr_loss=0.0104 tr_f1=0.9673 tr_acc=0.9962 tr_PRauc=0.9953 || va_loss=0.1331 va_f1=0.5719 va_acc=0.9706 va_PRauc=0.8041 | 232.7s\n",
      "[unet_basic] Epoch 009 | tr_loss=0.0091 tr_f1=0.9702 tr_acc=0.9965 tr_PRauc=0.9963 || va_loss=0.1125 va_f1=0.6319 va_acc=0.9730 va_PRauc=0.8051 | 230.9s\n",
      "[unet_basic] Epoch 010 | tr_loss=0.0107 tr_f1=0.9661 tr_acc=0.9960 tr_PRauc=0.9943 || va_loss=0.1341 va_f1=0.6123 va_acc=0.9716 va_PRauc=0.7679 | 235.1s\n",
      "[unet_basic] Epoch 011 | tr_loss=0.0127 tr_f1=0.9613 tr_acc=0.9955 tr_PRauc=0.9925 || va_loss=0.1754 va_f1=0.3627 va_acc=0.9620 va_PRauc=0.6958 | 232.9s\n",
      "[unet_basic] Epoch 012 | tr_loss=0.0122 tr_f1=0.9622 tr_acc=0.9956 tr_PRauc=0.9933 || va_loss=0.0955 va_f1=0.6920 va_acc=0.9752 va_PRauc=0.7531 | 234.9s\n",
      "[unet_basic] Epoch 013 | tr_loss=0.0122 tr_f1=0.9616 tr_acc=0.9955 tr_PRauc=0.9930 || va_loss=0.1844 va_f1=0.4957 va_acc=0.9670 va_PRauc=0.7170 | 232.2s\n",
      "[unet_basic] Epoch 014 | tr_loss=0.0080 tr_f1=0.9739 tr_acc=0.9969 tr_PRauc=0.9971 || va_loss=0.1437 va_f1=0.6366 va_acc=0.9729 va_PRauc=0.7550 | 232.6s\n",
      "[unet_basic] Epoch 015 | tr_loss=0.0080 tr_f1=0.9742 tr_acc=0.9970 tr_PRauc=0.9971 || va_loss=0.1199 va_f1=0.6890 va_acc=0.9758 va_PRauc=0.7896 | 234.5s\n",
      "[unet_basic] Epoch 016 | tr_loss=0.0085 tr_f1=0.9733 tr_acc=0.9969 tr_PRauc=0.9968 || va_loss=0.1385 va_f1=0.6715 va_acc=0.9752 va_PRauc=0.7890 | 233.1s\n",
      "[unet_basic] Epoch 017 | tr_loss=0.0069 tr_f1=0.9774 tr_acc=0.9973 tr_PRauc=0.9979 || va_loss=0.1267 va_f1=0.6774 va_acc=0.9757 va_PRauc=0.7857 | 231.9s\n",
      "[unet_basic] Epoch 018 | tr_loss=0.0069 tr_f1=0.9772 tr_acc=0.9973 tr_PRauc=0.9979 || va_loss=0.1581 va_f1=0.6017 va_acc=0.9716 va_PRauc=0.7602 | 234.1s\n",
      "[unet_basic] Epoch 019 | tr_loss=0.0067 tr_f1=0.9779 tr_acc=0.9974 tr_PRauc=0.9980 || va_loss=0.1558 va_f1=0.5937 va_acc=0.9713 va_PRauc=0.7670 | 233.2s\n",
      "[unet_basic] Epoch 020 | tr_loss=0.0065 tr_f1=0.9782 tr_acc=0.9974 tr_PRauc=0.9981 || va_loss=0.1470 va_f1=0.6136 va_acc=0.9722 va_PRauc=0.7844 | 233.7s\n"
     ]
    }
   ],
   "source": [
    "BEST_PATH = \"/kaggle/working/efficientb4_pretrained.pth\"\n",
    "best_val_f1 = -1\n",
    "\n",
    "import pandas as pd\n",
    "history = []\n",
    "\n",
    "for epoch in range(1, cfg.EPOCHS + 1):\n",
    "    t0 = time.time()\n",
    "\n",
    "    tr_loss, tr_prec, tr_rec, tr_f1, tr_acc, tr_auc = train_one_epoch(model, train_loader,thr=0.5)\n",
    "    va_loss, va_prec, va_rec, va_f1, va_acc, va_auc = validate_epoch(model, val_loader, thr=0.5)\n",
    "    elapsed = time.time() - t0\n",
    "\n",
    "    print(\n",
    "        f\"[unet_basic] Epoch {epoch:03d} | \"\n",
    "        f\"tr_loss={tr_loss:.4f} tr_f1={tr_f1:.4f} tr_acc={tr_acc:.4f} tr_PRauc={tr_auc:.4f} || \"\n",
    "        f\"va_loss={va_loss:.4f} va_f1={va_f1:.4f} va_acc={va_acc:.4f} va_PRauc={va_auc:.4f} | \"\n",
    "        f\"{elapsed:.1f}s\"\n",
    "    )\n",
    "\n",
    "    history.append({\n",
    "        \"epoch\": epoch,\n",
    "    \n",
    "        \"tr_loss\": tr_loss,\n",
    "        \"tr_precision\": tr_prec,\n",
    "        \"tr_recall\": tr_rec,\n",
    "        \"tr_f1\": tr_f1,\n",
    "        \"tr_acc\": tr_acc,\n",
    "        \"tr_PRauc\": tr_auc,\n",
    "    \n",
    "        \"va_loss\": va_loss,\n",
    "        \"va_precision\": va_prec,\n",
    "        \"va_recall\": va_rec,\n",
    "        \"va_f1\": va_f1,\n",
    "        \"va_acc\": va_acc,\n",
    "        \"va_PRauc\": va_auc,\n",
    "    \n",
    "        \"seconds\": elapsed\n",
    "    })\n",
    "\n",
    "    if va_f1 > best_val_f1:\n",
    "        best_val_f1 = va_f1\n",
    "        torch.save({\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"mean_13\": MEAN_13,\n",
    "            \"std_13\": STD_13,\n",
    "            \"epoch\": epoch,\n",
    "            \"best_val_f1\": best_val_f1,\n",
    "            \"va_auc\": va_auc,\n",
    "        }, BEST_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T11:00:42.313250Z",
     "iopub.status.busy": "2026-02-01T11:00:42.312619Z",
     "iopub.status.idle": "2026-02-01T11:00:42.360578Z",
     "shell.execute_reply": "2026-02-01T11:00:42.359887Z",
     "shell.execute_reply.started": "2026-02-01T11:00:42.313217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: /kaggle/working/training_metrics_eff_pretrained.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>tr_loss</th>\n",
       "      <th>tr_precision</th>\n",
       "      <th>tr_recall</th>\n",
       "      <th>tr_f1</th>\n",
       "      <th>tr_acc</th>\n",
       "      <th>tr_PRauc</th>\n",
       "      <th>va_loss</th>\n",
       "      <th>va_precision</th>\n",
       "      <th>va_recall</th>\n",
       "      <th>va_f1</th>\n",
       "      <th>va_acc</th>\n",
       "      <th>va_PRauc</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.9423</td>\n",
       "      <td>0.9321</td>\n",
       "      <td>0.9372</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>0.1082</td>\n",
       "      <td>0.8711</td>\n",
       "      <td>0.4758</td>\n",
       "      <td>0.6155</td>\n",
       "      <td>0.9716</td>\n",
       "      <td>0.7554</td>\n",
       "      <td>228.1279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.9456</td>\n",
       "      <td>0.9413</td>\n",
       "      <td>0.9434</td>\n",
       "      <td>0.9934</td>\n",
       "      <td>0.9857</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>0.3741</td>\n",
       "      <td>0.5201</td>\n",
       "      <td>0.9670</td>\n",
       "      <td>0.7195</td>\n",
       "      <td>227.5578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9427</td>\n",
       "      <td>0.9446</td>\n",
       "      <td>0.9935</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>0.0923</td>\n",
       "      <td>0.8715</td>\n",
       "      <td>0.5129</td>\n",
       "      <td>0.6457</td>\n",
       "      <td>0.9731</td>\n",
       "      <td>0.7824</td>\n",
       "      <td>231.3830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.9496</td>\n",
       "      <td>0.9390</td>\n",
       "      <td>0.9443</td>\n",
       "      <td>0.9935</td>\n",
       "      <td>0.9856</td>\n",
       "      <td>0.0940</td>\n",
       "      <td>0.8929</td>\n",
       "      <td>0.5165</td>\n",
       "      <td>0.6545</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.7833</td>\n",
       "      <td>229.6803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.9544</td>\n",
       "      <td>0.9470</td>\n",
       "      <td>0.9507</td>\n",
       "      <td>0.9942</td>\n",
       "      <td>0.9884</td>\n",
       "      <td>0.0937</td>\n",
       "      <td>0.8538</td>\n",
       "      <td>0.5017</td>\n",
       "      <td>0.6320</td>\n",
       "      <td>0.9721</td>\n",
       "      <td>0.7763</td>\n",
       "      <td>229.8185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>0.9627</td>\n",
       "      <td>0.9626</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>0.9941</td>\n",
       "      <td>0.1002</td>\n",
       "      <td>0.9003</td>\n",
       "      <td>0.5695</td>\n",
       "      <td>0.6977</td>\n",
       "      <td>0.9764</td>\n",
       "      <td>0.8088</td>\n",
       "      <td>230.5392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>0.9683</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>0.9963</td>\n",
       "      <td>0.9960</td>\n",
       "      <td>0.1393</td>\n",
       "      <td>0.9457</td>\n",
       "      <td>0.3756</td>\n",
       "      <td>0.5376</td>\n",
       "      <td>0.9691</td>\n",
       "      <td>0.7855</td>\n",
       "      <td>233.1362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.9709</td>\n",
       "      <td>0.9636</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.9962</td>\n",
       "      <td>0.9953</td>\n",
       "      <td>0.1331</td>\n",
       "      <td>0.9453</td>\n",
       "      <td>0.4099</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>0.8041</td>\n",
       "      <td>232.6790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>0.9697</td>\n",
       "      <td>0.9702</td>\n",
       "      <td>0.9965</td>\n",
       "      <td>0.9963</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.9062</td>\n",
       "      <td>0.4851</td>\n",
       "      <td>0.6319</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.8051</td>\n",
       "      <td>230.9003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.9678</td>\n",
       "      <td>0.9645</td>\n",
       "      <td>0.9661</td>\n",
       "      <td>0.9960</td>\n",
       "      <td>0.9943</td>\n",
       "      <td>0.1341</td>\n",
       "      <td>0.8841</td>\n",
       "      <td>0.4684</td>\n",
       "      <td>0.6123</td>\n",
       "      <td>0.9716</td>\n",
       "      <td>0.7679</td>\n",
       "      <td>235.0706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9578</td>\n",
       "      <td>0.9613</td>\n",
       "      <td>0.9955</td>\n",
       "      <td>0.9925</td>\n",
       "      <td>0.1754</td>\n",
       "      <td>0.9153</td>\n",
       "      <td>0.2262</td>\n",
       "      <td>0.3627</td>\n",
       "      <td>0.9620</td>\n",
       "      <td>0.6958</td>\n",
       "      <td>232.9004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.9647</td>\n",
       "      <td>0.9597</td>\n",
       "      <td>0.9622</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>0.9933</td>\n",
       "      <td>0.0955</td>\n",
       "      <td>0.8499</td>\n",
       "      <td>0.5836</td>\n",
       "      <td>0.6920</td>\n",
       "      <td>0.9752</td>\n",
       "      <td>0.7531</td>\n",
       "      <td>234.9104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.9639</td>\n",
       "      <td>0.9593</td>\n",
       "      <td>0.9616</td>\n",
       "      <td>0.9955</td>\n",
       "      <td>0.9930</td>\n",
       "      <td>0.1844</td>\n",
       "      <td>0.9211</td>\n",
       "      <td>0.3391</td>\n",
       "      <td>0.4957</td>\n",
       "      <td>0.9670</td>\n",
       "      <td>0.7170</td>\n",
       "      <td>232.2419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>0.9734</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9969</td>\n",
       "      <td>0.9971</td>\n",
       "      <td>0.1437</td>\n",
       "      <td>0.8882</td>\n",
       "      <td>0.4961</td>\n",
       "      <td>0.6366</td>\n",
       "      <td>0.9729</td>\n",
       "      <td>0.7550</td>\n",
       "      <td>232.5877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>0.9729</td>\n",
       "      <td>0.9742</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>0.9971</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>0.8954</td>\n",
       "      <td>0.5599</td>\n",
       "      <td>0.6890</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.7896</td>\n",
       "      <td>234.4784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.9764</td>\n",
       "      <td>0.9702</td>\n",
       "      <td>0.9733</td>\n",
       "      <td>0.9969</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.9133</td>\n",
       "      <td>0.5309</td>\n",
       "      <td>0.6715</td>\n",
       "      <td>0.9752</td>\n",
       "      <td>0.7890</td>\n",
       "      <td>233.1299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.9788</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.9774</td>\n",
       "      <td>0.9973</td>\n",
       "      <td>0.9979</td>\n",
       "      <td>0.1267</td>\n",
       "      <td>0.9298</td>\n",
       "      <td>0.5328</td>\n",
       "      <td>0.6774</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.7857</td>\n",
       "      <td>231.8865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.9782</td>\n",
       "      <td>0.9763</td>\n",
       "      <td>0.9772</td>\n",
       "      <td>0.9973</td>\n",
       "      <td>0.9979</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>0.9158</td>\n",
       "      <td>0.4480</td>\n",
       "      <td>0.6017</td>\n",
       "      <td>0.9716</td>\n",
       "      <td>0.7602</td>\n",
       "      <td>234.0664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.9792</td>\n",
       "      <td>0.9765</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>0.1558</td>\n",
       "      <td>0.9224</td>\n",
       "      <td>0.4377</td>\n",
       "      <td>0.5937</td>\n",
       "      <td>0.9713</td>\n",
       "      <td>0.7670</td>\n",
       "      <td>233.1553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.9791</td>\n",
       "      <td>0.9774</td>\n",
       "      <td>0.9782</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>0.1470</td>\n",
       "      <td>0.9177</td>\n",
       "      <td>0.4609</td>\n",
       "      <td>0.6136</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>0.7844</td>\n",
       "      <td>233.6900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  tr_loss  tr_precision  tr_recall   tr_f1  tr_acc  tr_PRauc  \\\n",
       "0       1   0.0198        0.9423     0.9321  0.9372  0.9926    0.9830   \n",
       "1       2   0.0178        0.9456     0.9413  0.9434  0.9934    0.9857   \n",
       "2       3   0.0184        0.9465     0.9427  0.9446  0.9935    0.9851   \n",
       "3       4   0.0183        0.9496     0.9390  0.9443  0.9935    0.9856   \n",
       "4       5   0.0160        0.9544     0.9470  0.9507  0.9942    0.9884   \n",
       "5       6   0.0116        0.9625     0.9627  0.9626  0.9956    0.9941   \n",
       "6       7   0.0096        0.9682     0.9683  0.9682  0.9963    0.9960   \n",
       "7       8   0.0104        0.9709     0.9636  0.9673  0.9962    0.9953   \n",
       "8       9   0.0091        0.9706     0.9697  0.9702  0.9965    0.9963   \n",
       "9      10   0.0107        0.9678     0.9645  0.9661  0.9960    0.9943   \n",
       "10     11   0.0127        0.9649     0.9578  0.9613  0.9955    0.9925   \n",
       "11     12   0.0122        0.9647     0.9597  0.9622  0.9956    0.9933   \n",
       "12     13   0.0122        0.9639     0.9593  0.9616  0.9955    0.9930   \n",
       "13     14   0.0080        0.9743     0.9734  0.9739  0.9969    0.9971   \n",
       "14     15   0.0080        0.9755     0.9729  0.9742  0.9970    0.9971   \n",
       "15     16   0.0085        0.9764     0.9702  0.9733  0.9969    0.9968   \n",
       "16     17   0.0069        0.9788     0.9761  0.9774  0.9973    0.9979   \n",
       "17     18   0.0069        0.9782     0.9763  0.9772  0.9973    0.9979   \n",
       "18     19   0.0067        0.9792     0.9765  0.9779  0.9974    0.9980   \n",
       "19     20   0.0065        0.9791     0.9774  0.9782  0.9974    0.9981   \n",
       "\n",
       "    va_loss  va_precision  va_recall   va_f1  va_acc  va_PRauc   seconds  \n",
       "0    0.1082        0.8711     0.4758  0.6155  0.9716    0.7554  228.1279  \n",
       "1    0.1306        0.8531     0.3741  0.5201  0.9670    0.7195  227.5578  \n",
       "2    0.0923        0.8715     0.5129  0.6457  0.9731    0.7824  231.3830  \n",
       "3    0.0940        0.8929     0.5165  0.6545  0.9739    0.7833  229.6803  \n",
       "4    0.0937        0.8538     0.5017  0.6320  0.9721    0.7763  229.8185  \n",
       "5    0.1002        0.9003     0.5695  0.6977  0.9764    0.8088  230.5392  \n",
       "6    0.1393        0.9457     0.3756  0.5376  0.9691    0.7855  233.1362  \n",
       "7    0.1331        0.9453     0.4099  0.5719  0.9706    0.8041  232.6790  \n",
       "8    0.1125        0.9062     0.4851  0.6319  0.9730    0.8051  230.9003  \n",
       "9    0.1341        0.8841     0.4684  0.6123  0.9716    0.7679  235.0706  \n",
       "10   0.1754        0.9153     0.2262  0.3627  0.9620    0.6958  232.9004  \n",
       "11   0.0955        0.8499     0.5836  0.6920  0.9752    0.7531  234.9104  \n",
       "12   0.1844        0.9211     0.3391  0.4957  0.9670    0.7170  232.2419  \n",
       "13   0.1437        0.8882     0.4961  0.6366  0.9729    0.7550  232.5877  \n",
       "14   0.1199        0.8954     0.5599  0.6890  0.9758    0.7896  234.4784  \n",
       "15   0.1385        0.9133     0.5309  0.6715  0.9752    0.7890  233.1299  \n",
       "16   0.1267        0.9298     0.5328  0.6774  0.9757    0.7857  231.8865  \n",
       "17   0.1581        0.9158     0.4480  0.6017  0.9716    0.7602  234.0664  \n",
       "18   0.1558        0.9224     0.4377  0.5937  0.9713    0.7670  233.1553  \n",
       "19   0.1470        0.9177     0.4609  0.6136  0.9722    0.7844  233.6900  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_history = pd.DataFrame(history)\n",
    "\n",
    "df_history = df_history.round(4)\n",
    "csv_path = \"/kaggle/working/training_metrics_eff_pretrained.csv\"\n",
    "df_history.to_csv(csv_path, index=False)\n",
    "print(\"Saved to:\", csv_path)\n",
    "df_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T11:02:32.433880Z",
     "iopub.status.busy": "2026-02-01T11:02:32.433498Z",
     "iopub.status.idle": "2026-02-01T11:03:01.210062Z",
     "shell.execute_reply": "2026-02-01T11:03:01.209186Z",
     "shell.execute_reply.started": "2026-02-01T11:02:32.433829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss   : 0.0532\n",
      "Test Prec   : 0.9031\n",
      "Test Recall : 0.6518\n",
      "Test F1     : 0.7571\n",
      "Test Acc    : 0.9899\n",
      "Test PRauc  : 0.8185\n",
      "threshold   : 0.50\n"
     ]
    }
   ],
   "source": [
    "t_best = 0.5\n",
    "test_loss, test_prec, test_rec, test_f1, test_acc, test_auc = validate_epoch(\n",
    "    model, test_loader, thr=t_best\n",
    ")\n",
    "\n",
    "print(f\"Test Loss   : {test_loss:.4f}\")\n",
    "print(f\"Test Prec   : {test_prec:.4f}\")\n",
    "print(f\"Test Recall : {test_rec:.4f}\")\n",
    "print(f\"Test F1     : {test_f1:.4f}\")\n",
    "print(f\"Test Acc    : {test_acc:.4f}\")\n",
    "print(f\"Test PRauc  : {test_auc:.4f}\")\n",
    "print(f\"threshold   : {t_best:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T11:03:55.330100Z",
     "iopub.status.busy": "2026-02-01T11:03:55.329278Z",
     "iopub.status.idle": "2026-02-01T11:06:28.724559Z",
     "shell.execute_reply": "2026-02-01T11:06:28.723587Z",
     "shell.execute_reply.started": "2026-02-01T11:03:55.330065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen threshold: 0.05\n",
      "Best global F1: 0.7392240273337137\n",
      "Top-5 thresholds:\n",
      "0.05 0.7392240273337137\n",
      "0.1 0.7151314054501176\n",
      "0.15 0.6990625098157347\n",
      "0.2 0.686029707327796\n",
      "0.25 0.6739252907299398\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def find_best_thr_global_f1(model, loader, grid=None, eps=1e-6):\n",
    "    model.eval()\n",
    "    if grid is None:\n",
    "        grid = np.linspace(0.05, 0.95, 19)\n",
    "\n",
    "    best_thr = None\n",
    "    best_f1 = -1\n",
    "    log = []\n",
    "\n",
    "    for thr in grid:\n",
    "        total_tp = total_fp = total_fn = 0.0\n",
    "\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            x = normalize_batch(x, MEAN_13, STD_13)\n",
    "\n",
    "            logits = model(x)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs >= thr).float()\n",
    "\n",
    "            total_tp += (preds * y).sum().item()\n",
    "            total_fp += (preds * (1 - y)).sum().item()\n",
    "            total_fn += ((1 - preds) * y).sum().item()\n",
    "\n",
    "        precision = (total_tp + eps) / (total_tp + total_fp + eps)\n",
    "        recall    = (total_tp + eps) / (total_tp + total_fn + eps)\n",
    "        f1        = (2 * precision * recall) / (precision + recall + eps)\n",
    "\n",
    "        log.append((float(thr), f1))\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_thr = float(thr)\n",
    "\n",
    "    return best_thr, best_f1, log\n",
    "\n",
    "t_best, best_f1, thr_log = find_best_thr_global_f1(model, val_loader)\n",
    "\n",
    "print(\"Chosen threshold:\", t_best)\n",
    "print(\"Best global F1:\", best_f1)\n",
    "\n",
    "print(\"Top-5 thresholds:\")\n",
    "for thr, f1 in sorted(thr_log, key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print(thr, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T11:01:18.694237Z",
     "iopub.status.busy": "2026-02-01T11:01:18.693603Z",
     "iopub.status.idle": "2026-02-01T11:01:49.311023Z",
     "shell.execute_reply": "2026-02-01T11:01:49.310218Z",
     "shell.execute_reply.started": "2026-02-01T11:01:18.694205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss   : 0.0532\n",
      "Test Prec   : 0.8229\n",
      "Test Recall : 0.7718\n",
      "Test F1     : 0.7965\n",
      "Test Acc    : 0.9904\n",
      "Test PRauc  : 0.8185\n",
      "threshold   : 0.05\n"
     ]
    }
   ],
   "source": [
    "t_best = 0.05\n",
    "test_loss, test_prec, test_rec, test_f1, test_acc, test_auc = validate_epoch(\n",
    "    model, test_loader, thr=t_best\n",
    ")\n",
    "\n",
    "print(f\"Test Loss   : {test_loss:.4f}\")\n",
    "print(f\"Test Prec   : {test_prec:.4f}\")\n",
    "print(f\"Test Recall : {test_rec:.4f}\")\n",
    "print(f\"Test F1     : {test_f1:.4f}\")\n",
    "print(f\"Test Acc    : {test_acc:.4f}\")\n",
    "print(f\"Test PRauc  : {test_auc:.4f}\")\n",
    "print(f\"threshold   : {t_best:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8507641,
     "sourceId": 14342736,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 551018,
     "modelInstanceId": 537667,
     "sourceId": 708024,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
